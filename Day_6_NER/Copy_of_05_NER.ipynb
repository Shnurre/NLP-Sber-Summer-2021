{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 05_NER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fba9f742dcb84454addbb34fb0d7cddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_07feea8e29c64fb2ac988e2184f0c5b3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_56f9e2f0b8b94bd58537e2da7576b46b",
              "IPY_MODEL_0b45402a21644664871f907ad4bd57b7"
            ]
          }
        },
        "07feea8e29c64fb2ac988e2184f0c5b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "56f9e2f0b8b94bd58537e2da7576b46b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2f10c6c8f44344dc90ae21ef9220c2e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 150,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 150,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_927dc4179a134b368da529fb0435eeaf"
          }
        },
        "0b45402a21644664871f907ad4bd57b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d2f9cdcfa2f4eda87a7e784f8183240",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 150/150 [05:30&lt;00:00,  2.76s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee5f0b0d687b41f9b09dfea1e56b79c6"
          }
        },
        "2f10c6c8f44344dc90ae21ef9220c2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "927dc4179a134b368da529fb0435eeaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d2f9cdcfa2f4eda87a7e784f8183240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee5f0b0d687b41f9b09dfea1e56b79c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgaeEy67Kvfz",
        "colab_type": "code",
        "outputId": "e55b01c8-3ac1-4252-aa18-c47c2bc73aa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile requirements.txt\n",
        "torch\n",
        "numpy\n",
        "pandas\n",
        "scikit-learn\n",
        "razdel\n",
        "ipymarkup"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHX5WftcK-Gu",
        "colab_type": "code",
        "outputId": "47f919fe-a6a3-45d8-8db1-42ac8f146ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!pip install --upgrade -r requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.17.4)\n",
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.25.3)\n",
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/d0/860c4f6a7027e00acff373d9f5327f4ae3ed5872234b3cbdd7bcb52e5eff/scikit_learn-0.22-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 49.7MB/s \n",
            "\u001b[?25hCollecting razdel\n",
            "  Downloading https://files.pythonhosted.org/packages/cf/f0/664eb27854d7de7c3605b5cd2a155cf069143fb00902ac479325bf1a98b7/razdel-0.4.0-py2.py3-none-any.whl\n",
            "Collecting ipymarkup\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/29/eaa1bcf649d6333dea829c05577c67f881d0555b6d77c1da72afda5c847d/ipymarkup-0.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: intervaltree==2.1.0 in /usr/local/lib/python3.6/dist-packages (from ipymarkup->-r requirements.txt (line 6)) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->-r requirements.txt (line 3)) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: sortedcontainers in /usr/local/lib/python3.6/dist-packages (from intervaltree==2.1.0->ipymarkup->-r requirements.txt (line 6)) (2.1.0)\n",
            "Installing collected packages: scikit-learn, razdel, ipymarkup\n",
            "  Found existing installation: scikit-learn 0.21.3\n",
            "    Uninstalling scikit-learn-0.21.3:\n",
            "      Successfully uninstalled scikit-learn-0.21.3\n",
            "Successfully installed ipymarkup-0.5.0 razdel-0.4.0 scikit-learn-0.22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_b9CuuzhS-i",
        "colab_type": "text"
      },
      "source": [
        "Новый день - новый датасет!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC3lrynfPTNY",
        "colab_type": "code",
        "outputId": "fb80f0d6-0930-439e-e477-9151ea50a7c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget http://ai-center.botik.ru/Airec/ai-resources/Persons-1000.zip\n",
        "!unzip Persons-1000.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-17 08:04:14--  http://ai-center.botik.ru/Airec/ai-resources/Persons-1000.zip\n",
            "Resolving ai-center.botik.ru (ai-center.botik.ru)... 95.129.138.2\n",
            "Connecting to ai-center.botik.ru (ai-center.botik.ru)|95.129.138.2|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3363777 (3.2M) [application/zip]\n",
            "Saving to: ‘Persons-1000.zip’\n",
            "\n",
            "Persons-1000.zip    100%[===================>]   3.21M  2.65MB/s    in 1.2s    \n",
            "\n",
            "2019-12-17 08:04:16 (2.65 MB/s) - ‘Persons-1000.zip’ saved [3363777/3363777]\n",
            "\n",
            "Archive:  Persons-1000.zip\n",
            "   creating: Persons-1000/\n",
            "   creating: Persons-1000/collection/\n",
            "   creating: Persons-1000/collection/001/\n",
            "  inflating: Persons-1000/collection/001/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/001/text.txt  \n",
            "   creating: Persons-1000/collection/002/\n",
            "  inflating: Persons-1000/collection/002/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/002/text.txt  \n",
            "   creating: Persons-1000/collection/003/\n",
            " extracting: Persons-1000/collection/003/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/003/text.txt  \n",
            "   creating: Persons-1000/collection/004/\n",
            "  inflating: Persons-1000/collection/004/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/004/text.txt  \n",
            "   creating: Persons-1000/collection/005/\n",
            "  inflating: Persons-1000/collection/005/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/005/text.txt  \n",
            "   creating: Persons-1000/collection/006/\n",
            " extracting: Persons-1000/collection/006/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/006/text.txt  \n",
            "   creating: Persons-1000/collection/007/\n",
            "  inflating: Persons-1000/collection/007/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/007/text.txt  \n",
            "   creating: Persons-1000/collection/008/\n",
            "  inflating: Persons-1000/collection/008/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/008/text.txt  \n",
            "   creating: Persons-1000/collection/009/\n",
            "  inflating: Persons-1000/collection/009/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/009/text.txt  \n",
            "   creating: Persons-1000/collection/010/\n",
            "  inflating: Persons-1000/collection/010/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/010/text.txt  \n",
            "   creating: Persons-1000/collection/011/\n",
            "  inflating: Persons-1000/collection/011/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/011/text.txt  \n",
            "   creating: Persons-1000/collection/012/\n",
            "  inflating: Persons-1000/collection/012/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/012/text.txt  \n",
            "   creating: Persons-1000/collection/013/\n",
            "  inflating: Persons-1000/collection/013/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/013/text.txt  \n",
            "   creating: Persons-1000/collection/014/\n",
            "  inflating: Persons-1000/collection/014/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/014/text.txt  \n",
            "   creating: Persons-1000/collection/015 (!)/\n",
            "  inflating: Persons-1000/collection/015 (!)/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/015 (!)/text.txt  \n",
            "   creating: Persons-1000/collection/016/\n",
            "  inflating: Persons-1000/collection/016/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/016/text.txt  \n",
            "   creating: Persons-1000/collection/017/\n",
            "  inflating: Persons-1000/collection/017/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/017/text.txt  \n",
            "   creating: Persons-1000/collection/018/\n",
            "  inflating: Persons-1000/collection/018/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/018/text.txt  \n",
            "   creating: Persons-1000/collection/019/\n",
            "  inflating: Persons-1000/collection/019/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/019/text.txt  \n",
            "   creating: Persons-1000/collection/020/\n",
            "  inflating: Persons-1000/collection/020/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/020/text.txt  \n",
            "   creating: Persons-1000/collection/021/\n",
            "  inflating: Persons-1000/collection/021/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/021/text.txt  \n",
            "   creating: Persons-1000/collection/022/\n",
            "  inflating: Persons-1000/collection/022/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/022/text.txt  \n",
            "   creating: Persons-1000/collection/023/\n",
            "  inflating: Persons-1000/collection/023/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/023/text.txt  \n",
            "   creating: Persons-1000/collection/025/\n",
            "  inflating: Persons-1000/collection/025/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/025/text.txt  \n",
            "   creating: Persons-1000/collection/026/\n",
            "  inflating: Persons-1000/collection/026/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/026/text.txt  \n",
            "   creating: Persons-1000/collection/027/\n",
            "  inflating: Persons-1000/collection/027/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/027/text.txt  \n",
            "   creating: Persons-1000/collection/028/\n",
            "  inflating: Persons-1000/collection/028/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/028/text.txt  \n",
            "   creating: Persons-1000/collection/029/\n",
            "  inflating: Persons-1000/collection/029/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/029/text.txt  \n",
            "   creating: Persons-1000/collection/030/\n",
            "  inflating: Persons-1000/collection/030/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/030/text.txt  \n",
            "   creating: Persons-1000/collection/031/\n",
            "  inflating: Persons-1000/collection/031/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/031/text.txt  \n",
            "   creating: Persons-1000/collection/032/\n",
            "  inflating: Persons-1000/collection/032/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/032/text.txt  \n",
            "   creating: Persons-1000/collection/033/\n",
            "  inflating: Persons-1000/collection/033/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/033/text.txt  \n",
            "   creating: Persons-1000/collection/034/\n",
            "  inflating: Persons-1000/collection/034/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/034/text.txt  \n",
            "   creating: Persons-1000/collection/035/\n",
            "  inflating: Persons-1000/collection/035/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/035/text.txt  \n",
            "   creating: Persons-1000/collection/036/\n",
            "  inflating: Persons-1000/collection/036/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/036/text.txt  \n",
            "   creating: Persons-1000/collection/037/\n",
            "  inflating: Persons-1000/collection/037/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/037/text.txt  \n",
            "   creating: Persons-1000/collection/038/\n",
            "  inflating: Persons-1000/collection/038/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/038/text.txt  \n",
            "   creating: Persons-1000/collection/039/\n",
            "  inflating: Persons-1000/collection/039/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/039/text.txt  \n",
            "   creating: Persons-1000/collection/03_12_12a/\n",
            "  inflating: Persons-1000/collection/03_12_12a/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/03_12_12a/text.txt  \n",
            "   creating: Persons-1000/collection/03_12_12b/\n",
            "  inflating: Persons-1000/collection/03_12_12b/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/03_12_12b/text.txt  \n",
            "   creating: Persons-1000/collection/03_12_12c/\n",
            "  inflating: Persons-1000/collection/03_12_12c/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/03_12_12c/text.txt  \n",
            "   creating: Persons-1000/collection/03_12_12d/\n",
            "  inflating: Persons-1000/collection/03_12_12d/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/03_12_12d/text.txt  \n",
            "   creating: Persons-1000/collection/03_12_12g/\n",
            " extracting: Persons-1000/collection/03_12_12g/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/03_12_12g/text.txt  \n",
            "   creating: Persons-1000/collection/03_12_12h/\n",
            "  inflating: Persons-1000/collection/03_12_12h/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/03_12_12h/text.txt  \n",
            "   creating: Persons-1000/collection/040/\n",
            "  inflating: Persons-1000/collection/040/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/040/text.txt  \n",
            "   creating: Persons-1000/collection/041/\n",
            "  inflating: Persons-1000/collection/041/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/041/text.txt  \n",
            "   creating: Persons-1000/collection/042/\n",
            "  inflating: Persons-1000/collection/042/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/042/text.txt  \n",
            "   creating: Persons-1000/collection/043/\n",
            "  inflating: Persons-1000/collection/043/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/043/text.txt  \n",
            "   creating: Persons-1000/collection/044/\n",
            "  inflating: Persons-1000/collection/044/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/044/text.txt  \n",
            "   creating: Persons-1000/collection/045/\n",
            "  inflating: Persons-1000/collection/045/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/045/text.txt  \n",
            "   creating: Persons-1000/collection/046/\n",
            "  inflating: Persons-1000/collection/046/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/046/text.txt  \n",
            "   creating: Persons-1000/collection/047/\n",
            "  inflating: Persons-1000/collection/047/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/047/text.txt  \n",
            "   creating: Persons-1000/collection/048/\n",
            "  inflating: Persons-1000/collection/048/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/048/text.txt  \n",
            "   creating: Persons-1000/collection/049/\n",
            "  inflating: Persons-1000/collection/049/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/049/text.txt  \n",
            "   creating: Persons-1000/collection/04_02_13a_abdulatipov/\n",
            "  inflating: Persons-1000/collection/04_02_13a_abdulatipov/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/04_02_13a_abdulatipov/text.txt  \n",
            "   creating: Persons-1000/collection/04_03_13a_sorokin/\n",
            "  inflating: Persons-1000/collection/04_03_13a_sorokin/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/04_03_13a_sorokin/text.txt  \n",
            "   creating: Persons-1000/collection/04_12_12b/\n",
            "  inflating: Persons-1000/collection/04_12_12b/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/04_12_12b/text.txt  \n",
            "   creating: Persons-1000/collection/04_12_12d/\n",
            "  inflating: Persons-1000/collection/04_12_12d/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/04_12_12d/text.txt  \n",
            "   creating: Persons-1000/collection/04_12_12f/\n",
            "  inflating: Persons-1000/collection/04_12_12f/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/04_12_12f/text.txt  \n",
            "   creating: Persons-1000/collection/04_12_12g/\n",
            "  inflating: Persons-1000/collection/04_12_12g/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/04_12_12g/text.txt  \n",
            "   creating: Persons-1000/collection/04_12_12h_corr/\n",
            "  inflating: Persons-1000/collection/04_12_12h_corr/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/04_12_12h_corr/text.txt  \n",
            "   creating: Persons-1000/collection/050/\n",
            "  inflating: Persons-1000/collection/050/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/050/text.txt  \n",
            "   creating: Persons-1000/collection/051/\n",
            "  inflating: Persons-1000/collection/051/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/051/text.txt  \n",
            "   creating: Persons-1000/collection/052/\n",
            "  inflating: Persons-1000/collection/052/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/052/text.txt  \n",
            "   creating: Persons-1000/collection/053/\n",
            "  inflating: Persons-1000/collection/053/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/053/text.txt  \n",
            "   creating: Persons-1000/collection/054/\n",
            "  inflating: Persons-1000/collection/054/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/054/text.txt  \n",
            "   creating: Persons-1000/collection/055/\n",
            "  inflating: Persons-1000/collection/055/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/055/text.txt  \n",
            "   creating: Persons-1000/collection/056/\n",
            "  inflating: Persons-1000/collection/056/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/056/text.txt  \n",
            "   creating: Persons-1000/collection/057/\n",
            "  inflating: Persons-1000/collection/057/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/057/text.txt  \n",
            "   creating: Persons-1000/collection/058/\n",
            "  inflating: Persons-1000/collection/058/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/058/text.txt  \n",
            "   creating: Persons-1000/collection/059/\n",
            "  inflating: Persons-1000/collection/059/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/059/text.txt  \n",
            "   creating: Persons-1000/collection/060/\n",
            "  inflating: Persons-1000/collection/060/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/060/text.txt  \n",
            "   creating: Persons-1000/collection/061/\n",
            "  inflating: Persons-1000/collection/061/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/061/text.txt  \n",
            "   creating: Persons-1000/collection/062/\n",
            "  inflating: Persons-1000/collection/062/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/062/text.txt  \n",
            "   creating: Persons-1000/collection/063/\n",
            "  inflating: Persons-1000/collection/063/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/063/text.txt  \n",
            "   creating: Persons-1000/collection/064/\n",
            "  inflating: Persons-1000/collection/064/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/064/text.txt  \n",
            "   creating: Persons-1000/collection/065/\n",
            "  inflating: Persons-1000/collection/065/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/065/text.txt  \n",
            "   creating: Persons-1000/collection/066/\n",
            "  inflating: Persons-1000/collection/066/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/066/text.txt  \n",
            "   creating: Persons-1000/collection/067/\n",
            "  inflating: Persons-1000/collection/067/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/067/text.txt  \n",
            "   creating: Persons-1000/collection/068/\n",
            "  inflating: Persons-1000/collection/068/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/068/text.txt  \n",
            "   creating: Persons-1000/collection/069/\n",
            "  inflating: Persons-1000/collection/069/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/069/text.txt  \n",
            "   creating: Persons-1000/collection/070/\n",
            "  inflating: Persons-1000/collection/070/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/070/text.txt  \n",
            "   creating: Persons-1000/collection/071/\n",
            "  inflating: Persons-1000/collection/071/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/071/text.txt  \n",
            "   creating: Persons-1000/collection/072/\n",
            "  inflating: Persons-1000/collection/072/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/072/text.txt  \n",
            "   creating: Persons-1000/collection/073/\n",
            "  inflating: Persons-1000/collection/073/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/073/text.txt  \n",
            "   creating: Persons-1000/collection/074/\n",
            "  inflating: Persons-1000/collection/074/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/074/text.txt  \n",
            "   creating: Persons-1000/collection/075/\n",
            "  inflating: Persons-1000/collection/075/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/075/text.txt  \n",
            "   creating: Persons-1000/collection/076/\n",
            "  inflating: Persons-1000/collection/076/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/076/text.txt  \n",
            "   creating: Persons-1000/collection/077/\n",
            "  inflating: Persons-1000/collection/077/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/077/text.txt  \n",
            "   creating: Persons-1000/collection/078/\n",
            "  inflating: Persons-1000/collection/078/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/078/text.txt  \n",
            "   creating: Persons-1000/collection/079/\n",
            "  inflating: Persons-1000/collection/079/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/079/text.txt  \n",
            "   creating: Persons-1000/collection/080/\n",
            "  inflating: Persons-1000/collection/080/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/080/text.txt  \n",
            "   creating: Persons-1000/collection/081/\n",
            "  inflating: Persons-1000/collection/081/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/081/text.txt  \n",
            "   creating: Persons-1000/collection/082/\n",
            "  inflating: Persons-1000/collection/082/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/082/text.txt  \n",
            "   creating: Persons-1000/collection/083/\n",
            "  inflating: Persons-1000/collection/083/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/083/text.txt  \n",
            "   creating: Persons-1000/collection/084/\n",
            "  inflating: Persons-1000/collection/084/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/084/text.txt  \n",
            "   creating: Persons-1000/collection/085/\n",
            "  inflating: Persons-1000/collection/085/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/085/text.txt  \n",
            "   creating: Persons-1000/collection/086/\n",
            "  inflating: Persons-1000/collection/086/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/086/text.txt  \n",
            "   creating: Persons-1000/collection/087/\n",
            "  inflating: Persons-1000/collection/087/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/087/text.txt  \n",
            "   creating: Persons-1000/collection/088/\n",
            "  inflating: Persons-1000/collection/088/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/088/text.txt  \n",
            "   creating: Persons-1000/collection/089/\n",
            "  inflating: Persons-1000/collection/089/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/089/text.txt  \n",
            "   creating: Persons-1000/collection/090/\n",
            "  inflating: Persons-1000/collection/090/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/090/text.txt  \n",
            "   creating: Persons-1000/collection/091/\n",
            "  inflating: Persons-1000/collection/091/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/091/text.txt  \n",
            "   creating: Persons-1000/collection/092/\n",
            "  inflating: Persons-1000/collection/092/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/092/text.txt  \n",
            "   creating: Persons-1000/collection/093/\n",
            "  inflating: Persons-1000/collection/093/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/093/text.txt  \n",
            "   creating: Persons-1000/collection/094/\n",
            "  inflating: Persons-1000/collection/094/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/094/text.txt  \n",
            "   creating: Persons-1000/collection/095/\n",
            "  inflating: Persons-1000/collection/095/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/095/text.txt  \n",
            "   creating: Persons-1000/collection/096/\n",
            "  inflating: Persons-1000/collection/096/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/096/text.txt  \n",
            "   creating: Persons-1000/collection/097/\n",
            "  inflating: Persons-1000/collection/097/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/097/text.txt  \n",
            "   creating: Persons-1000/collection/098/\n",
            "  inflating: Persons-1000/collection/098/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/098/text.txt  \n",
            "   creating: Persons-1000/collection/099/\n",
            "  inflating: Persons-1000/collection/099/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/099/text.txt  \n",
            "   creating: Persons-1000/collection/09_01_13/\n",
            "  inflating: Persons-1000/collection/09_01_13/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/09_01_13/text.txt  \n",
            "   creating: Persons-1000/collection/09_01_13a/\n",
            "  inflating: Persons-1000/collection/09_01_13a/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/09_01_13a/text.txt  \n",
            "   creating: Persons-1000/collection/09_01_13c/\n",
            "  inflating: Persons-1000/collection/09_01_13c/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/09_01_13c/text.txt  \n",
            "   creating: Persons-1000/collection/09_01_13d/\n",
            "  inflating: Persons-1000/collection/09_01_13d/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/09_01_13d/text.txt  \n",
            "   creating: Persons-1000/collection/09_01_13e/\n",
            "  inflating: Persons-1000/collection/09_01_13e/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/09_01_13e/text.txt  \n",
            "   creating: Persons-1000/collection/09_01_13h/\n",
            "  inflating: Persons-1000/collection/09_01_13h/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/09_01_13h/text.txt  \n",
            "   creating: Persons-1000/collection/09_01_13i/\n",
            "  inflating: Persons-1000/collection/09_01_13i/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/09_01_13i/text.txt  \n",
            "   creating: Persons-1000/collection/100/\n",
            "  inflating: Persons-1000/collection/100/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/100/text.txt  \n",
            "   creating: Persons-1000/collection/1000/\n",
            "  inflating: Persons-1000/collection/1000/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1000/text.txt  \n",
            "   creating: Persons-1000/collection/1001/\n",
            "  inflating: Persons-1000/collection/1001/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1001/text.txt  \n",
            "   creating: Persons-1000/collection/1002/\n",
            "  inflating: Persons-1000/collection/1002/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1002/text.txt  \n",
            "   creating: Persons-1000/collection/1003/\n",
            "  inflating: Persons-1000/collection/1003/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1003/text.txt  \n",
            "   creating: Persons-1000/collection/1004/\n",
            "  inflating: Persons-1000/collection/1004/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1004/text.txt  \n",
            "   creating: Persons-1000/collection/1005/\n",
            "  inflating: Persons-1000/collection/1005/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1005/text.txt  \n",
            "   creating: Persons-1000/collection/1006/\n",
            "  inflating: Persons-1000/collection/1006/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1006/text.txt  \n",
            "   creating: Persons-1000/collection/1007/\n",
            "  inflating: Persons-1000/collection/1007/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1007/text.txt  \n",
            "   creating: Persons-1000/collection/1008/\n",
            "  inflating: Persons-1000/collection/1008/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1008/text.txt  \n",
            "   creating: Persons-1000/collection/1009/\n",
            "  inflating: Persons-1000/collection/1009/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1009/text.txt  \n",
            "   creating: Persons-1000/collection/101/\n",
            "  inflating: Persons-1000/collection/101/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/101/text.txt  \n",
            "   creating: Persons-1000/collection/1010/\n",
            "  inflating: Persons-1000/collection/1010/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1010/text.txt  \n",
            "   creating: Persons-1000/collection/1011/\n",
            "  inflating: Persons-1000/collection/1011/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1011/text.txt  \n",
            "   creating: Persons-1000/collection/1012/\n",
            "  inflating: Persons-1000/collection/1012/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1012/text.txt  \n",
            "   creating: Persons-1000/collection/1013/\n",
            "  inflating: Persons-1000/collection/1013/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1013/text.txt  \n",
            "   creating: Persons-1000/collection/1014/\n",
            "  inflating: Persons-1000/collection/1014/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1014/text.txt  \n",
            "   creating: Persons-1000/collection/1015/\n",
            "  inflating: Persons-1000/collection/1015/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1015/text.txt  \n",
            "   creating: Persons-1000/collection/1016/\n",
            "  inflating: Persons-1000/collection/1016/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1016/text.txt  \n",
            "   creating: Persons-1000/collection/1017/\n",
            "  inflating: Persons-1000/collection/1017/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1017/text.txt  \n",
            "   creating: Persons-1000/collection/1018/\n",
            "  inflating: Persons-1000/collection/1018/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1018/text.txt  \n",
            "   creating: Persons-1000/collection/1019/\n",
            "  inflating: Persons-1000/collection/1019/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1019/text.txt  \n",
            "   creating: Persons-1000/collection/102/\n",
            "  inflating: Persons-1000/collection/102/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/102/text.txt  \n",
            "   creating: Persons-1000/collection/1020/\n",
            "  inflating: Persons-1000/collection/1020/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1020/text.txt  \n",
            "   creating: Persons-1000/collection/1021/\n",
            "  inflating: Persons-1000/collection/1021/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1021/text.txt  \n",
            "   creating: Persons-1000/collection/1022/\n",
            "  inflating: Persons-1000/collection/1022/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1022/text.txt  \n",
            "   creating: Persons-1000/collection/1023/\n",
            "  inflating: Persons-1000/collection/1023/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1023/text.txt  \n",
            "   creating: Persons-1000/collection/1024/\n",
            "  inflating: Persons-1000/collection/1024/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1024/text.txt  \n",
            "   creating: Persons-1000/collection/1025/\n",
            "  inflating: Persons-1000/collection/1025/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1025/text.txt  \n",
            "   creating: Persons-1000/collection/1026/\n",
            "  inflating: Persons-1000/collection/1026/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1026/text.txt  \n",
            "   creating: Persons-1000/collection/1027/\n",
            "  inflating: Persons-1000/collection/1027/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1027/text.txt  \n",
            "   creating: Persons-1000/collection/1028/\n",
            "  inflating: Persons-1000/collection/1028/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1028/text.txt  \n",
            "   creating: Persons-1000/collection/1029/\n",
            "  inflating: Persons-1000/collection/1029/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1029/text.txt  \n",
            "   creating: Persons-1000/collection/103/\n",
            "  inflating: Persons-1000/collection/103/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/103/text.txt  \n",
            "   creating: Persons-1000/collection/1030/\n",
            "  inflating: Persons-1000/collection/1030/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1030/text.txt  \n",
            "   creating: Persons-1000/collection/1031/\n",
            "  inflating: Persons-1000/collection/1031/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1031/text.txt  \n",
            "   creating: Persons-1000/collection/1032/\n",
            "  inflating: Persons-1000/collection/1032/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1032/text.txt  \n",
            "   creating: Persons-1000/collection/1033/\n",
            "  inflating: Persons-1000/collection/1033/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1033/text.txt  \n",
            "   creating: Persons-1000/collection/1034/\n",
            "  inflating: Persons-1000/collection/1034/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1034/text.txt  \n",
            "   creating: Persons-1000/collection/1035/\n",
            "  inflating: Persons-1000/collection/1035/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1035/text.txt  \n",
            "   creating: Persons-1000/collection/1036/\n",
            "  inflating: Persons-1000/collection/1036/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1036/text.txt  \n",
            "   creating: Persons-1000/collection/1037/\n",
            "  inflating: Persons-1000/collection/1037/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1037/text.txt  \n",
            "   creating: Persons-1000/collection/1038/\n",
            "  inflating: Persons-1000/collection/1038/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1038/text.txt  \n",
            "   creating: Persons-1000/collection/1039/\n",
            "  inflating: Persons-1000/collection/1039/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1039/text.txt  \n",
            "   creating: Persons-1000/collection/104/\n",
            "  inflating: Persons-1000/collection/104/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/104/text.txt  \n",
            "   creating: Persons-1000/collection/1040/\n",
            "  inflating: Persons-1000/collection/1040/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1040/text.txt  \n",
            "   creating: Persons-1000/collection/1041/\n",
            "  inflating: Persons-1000/collection/1041/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1041/text.txt  \n",
            "   creating: Persons-1000/collection/1042/\n",
            "  inflating: Persons-1000/collection/1042/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1042/text.txt  \n",
            "   creating: Persons-1000/collection/1043/\n",
            "  inflating: Persons-1000/collection/1043/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1043/text.txt  \n",
            "   creating: Persons-1000/collection/1044/\n",
            "  inflating: Persons-1000/collection/1044/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1044/text.txt  \n",
            "   creating: Persons-1000/collection/1045/\n",
            "  inflating: Persons-1000/collection/1045/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1045/text.txt  \n",
            "   creating: Persons-1000/collection/1046/\n",
            "  inflating: Persons-1000/collection/1046/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1046/text.txt  \n",
            "   creating: Persons-1000/collection/1047/\n",
            "  inflating: Persons-1000/collection/1047/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1047/text.txt  \n",
            "   creating: Persons-1000/collection/1048/\n",
            "  inflating: Persons-1000/collection/1048/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1048/text.txt  \n",
            "   creating: Persons-1000/collection/1049/\n",
            "  inflating: Persons-1000/collection/1049/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1049/text.txt  \n",
            "   creating: Persons-1000/collection/105/\n",
            "  inflating: Persons-1000/collection/105/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/105/text.txt  \n",
            "   creating: Persons-1000/collection/1050/\n",
            "  inflating: Persons-1000/collection/1050/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1050/text.txt  \n",
            "   creating: Persons-1000/collection/106/\n",
            "  inflating: Persons-1000/collection/106/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/106/text.txt  \n",
            "   creating: Persons-1000/collection/107/\n",
            "  inflating: Persons-1000/collection/107/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/107/text.txt  \n",
            "   creating: Persons-1000/collection/108/\n",
            "  inflating: Persons-1000/collection/108/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/108/text.txt  \n",
            "   creating: Persons-1000/collection/109/\n",
            "  inflating: Persons-1000/collection/109/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/109/text.txt  \n",
            "   creating: Persons-1000/collection/10_01_13a/\n",
            "  inflating: Persons-1000/collection/10_01_13a/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/10_01_13a/text.txt  \n",
            "   creating: Persons-1000/collection/10_01_13d/\n",
            "  inflating: Persons-1000/collection/10_01_13d/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/10_01_13d/text.txt  \n",
            "   creating: Persons-1000/collection/10_01_13i/\n",
            "  inflating: Persons-1000/collection/10_01_13i/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/10_01_13i/text.txt  \n",
            "   creating: Persons-1000/collection/110/\n",
            "  inflating: Persons-1000/collection/110/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/110/text.txt  \n",
            "   creating: Persons-1000/collection/1100/\n",
            "  inflating: Persons-1000/collection/1100/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1100/text.txt  \n",
            "   creating: Persons-1000/collection/1101/\n",
            "  inflating: Persons-1000/collection/1101/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1101/text.txt  \n",
            "   creating: Persons-1000/collection/1102/\n",
            "  inflating: Persons-1000/collection/1102/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1102/text.txt  \n",
            "   creating: Persons-1000/collection/1103/\n",
            "  inflating: Persons-1000/collection/1103/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1103/text.txt  \n",
            "   creating: Persons-1000/collection/1104/\n",
            "  inflating: Persons-1000/collection/1104/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1104/text.txt  \n",
            "   creating: Persons-1000/collection/1105/\n",
            "  inflating: Persons-1000/collection/1105/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1105/text.txt  \n",
            "   creating: Persons-1000/collection/1106/\n",
            "  inflating: Persons-1000/collection/1106/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1106/text.txt  \n",
            "   creating: Persons-1000/collection/1107/\n",
            "  inflating: Persons-1000/collection/1107/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1107/text.txt  \n",
            "   creating: Persons-1000/collection/1108/\n",
            "  inflating: Persons-1000/collection/1108/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1108/text.txt  \n",
            "   creating: Persons-1000/collection/1109/\n",
            "  inflating: Persons-1000/collection/1109/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1109/text.txt  \n",
            "   creating: Persons-1000/collection/111/\n",
            "  inflating: Persons-1000/collection/111/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/111/text.txt  \n",
            "   creating: Persons-1000/collection/1110/\n",
            "  inflating: Persons-1000/collection/1110/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1110/text.txt  \n",
            "   creating: Persons-1000/collection/1111/\n",
            "  inflating: Persons-1000/collection/1111/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1111/text.txt  \n",
            "   creating: Persons-1000/collection/1112/\n",
            "  inflating: Persons-1000/collection/1112/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1112/text.txt  \n",
            "   creating: Persons-1000/collection/1113/\n",
            "  inflating: Persons-1000/collection/1113/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1113/text.txt  \n",
            "   creating: Persons-1000/collection/1114/\n",
            "  inflating: Persons-1000/collection/1114/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1114/text.txt  \n",
            "   creating: Persons-1000/collection/1115/\n",
            "  inflating: Persons-1000/collection/1115/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1115/text.txt  \n",
            "   creating: Persons-1000/collection/1116/\n",
            "  inflating: Persons-1000/collection/1116/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1116/text.txt  \n",
            "   creating: Persons-1000/collection/1117/\n",
            "  inflating: Persons-1000/collection/1117/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1117/text.txt  \n",
            "   creating: Persons-1000/collection/1118/\n",
            "  inflating: Persons-1000/collection/1118/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1118/text.txt  \n",
            "   creating: Persons-1000/collection/1119/\n",
            "  inflating: Persons-1000/collection/1119/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1119/text.txt  \n",
            "   creating: Persons-1000/collection/112/\n",
            "  inflating: Persons-1000/collection/112/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/112/text.txt  \n",
            "   creating: Persons-1000/collection/1120/\n",
            "  inflating: Persons-1000/collection/1120/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1120/text.txt  \n",
            "   creating: Persons-1000/collection/1121/\n",
            "  inflating: Persons-1000/collection/1121/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1121/text.txt  \n",
            "   creating: Persons-1000/collection/1122/\n",
            "  inflating: Persons-1000/collection/1122/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1122/text.txt  \n",
            "   creating: Persons-1000/collection/1123/\n",
            "  inflating: Persons-1000/collection/1123/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1123/text.txt  \n",
            "   creating: Persons-1000/collection/1124/\n",
            "  inflating: Persons-1000/collection/1124/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1124/text.txt  \n",
            "   creating: Persons-1000/collection/1125/\n",
            "  inflating: Persons-1000/collection/1125/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1125/text.txt  \n",
            "   creating: Persons-1000/collection/1126/\n",
            "  inflating: Persons-1000/collection/1126/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1126/text.txt  \n",
            "   creating: Persons-1000/collection/1127/\n",
            "  inflating: Persons-1000/collection/1127/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1127/text.txt  \n",
            "   creating: Persons-1000/collection/1128/\n",
            "  inflating: Persons-1000/collection/1128/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1128/text.txt  \n",
            "   creating: Persons-1000/collection/113/\n",
            "  inflating: Persons-1000/collection/113/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/113/text.txt  \n",
            "   creating: Persons-1000/collection/1130/\n",
            "  inflating: Persons-1000/collection/1130/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1130/text.txt  \n",
            "   creating: Persons-1000/collection/1131/\n",
            "  inflating: Persons-1000/collection/1131/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1131/text.txt  \n",
            "   creating: Persons-1000/collection/1132/\n",
            "  inflating: Persons-1000/collection/1132/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1132/text.txt  \n",
            "   creating: Persons-1000/collection/1133/\n",
            "  inflating: Persons-1000/collection/1133/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1133/text.txt  \n",
            "   creating: Persons-1000/collection/1134/\n",
            "  inflating: Persons-1000/collection/1134/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1134/text.txt  \n",
            "   creating: Persons-1000/collection/1135/\n",
            "  inflating: Persons-1000/collection/1135/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1135/text.txt  \n",
            "   creating: Persons-1000/collection/1136/\n",
            "  inflating: Persons-1000/collection/1136/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1136/text.txt  \n",
            "   creating: Persons-1000/collection/1137/\n",
            "  inflating: Persons-1000/collection/1137/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1137/text.txt  \n",
            "   creating: Persons-1000/collection/1138/\n",
            "  inflating: Persons-1000/collection/1138/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1138/text.txt  \n",
            "   creating: Persons-1000/collection/1139/\n",
            "  inflating: Persons-1000/collection/1139/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1139/text.txt  \n",
            "   creating: Persons-1000/collection/114/\n",
            "  inflating: Persons-1000/collection/114/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/114/text.txt  \n",
            "   creating: Persons-1000/collection/1140/\n",
            "  inflating: Persons-1000/collection/1140/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1140/text.txt  \n",
            "   creating: Persons-1000/collection/1141/\n",
            "  inflating: Persons-1000/collection/1141/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1141/text.txt  \n",
            "   creating: Persons-1000/collection/1142/\n",
            "  inflating: Persons-1000/collection/1142/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1142/text.txt  \n",
            "   creating: Persons-1000/collection/1143/\n",
            "  inflating: Persons-1000/collection/1143/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1143/text.txt  \n",
            "   creating: Persons-1000/collection/1144/\n",
            "  inflating: Persons-1000/collection/1144/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1144/text.txt  \n",
            "   creating: Persons-1000/collection/1145/\n",
            "  inflating: Persons-1000/collection/1145/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1145/text.txt  \n",
            "   creating: Persons-1000/collection/1146/\n",
            "  inflating: Persons-1000/collection/1146/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1146/text.txt  \n",
            "   creating: Persons-1000/collection/1147/\n",
            "  inflating: Persons-1000/collection/1147/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1147/text.txt  \n",
            "   creating: Persons-1000/collection/1148/\n",
            "  inflating: Persons-1000/collection/1148/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1148/text.txt  \n",
            "   creating: Persons-1000/collection/1149/\n",
            "  inflating: Persons-1000/collection/1149/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1149/text.txt  \n",
            "   creating: Persons-1000/collection/115/\n",
            "  inflating: Persons-1000/collection/115/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/115/text.txt  \n",
            "   creating: Persons-1000/collection/1150/\n",
            "  inflating: Persons-1000/collection/1150/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1150/text.txt  \n",
            "   creating: Persons-1000/collection/1151/\n",
            "  inflating: Persons-1000/collection/1151/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1151/text.txt  \n",
            "   creating: Persons-1000/collection/1152/\n",
            "  inflating: Persons-1000/collection/1152/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1152/text.txt  \n",
            "   creating: Persons-1000/collection/1153/\n",
            "  inflating: Persons-1000/collection/1153/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1153/text.txt  \n",
            "   creating: Persons-1000/collection/1154/\n",
            "  inflating: Persons-1000/collection/1154/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1154/text.txt  \n",
            "   creating: Persons-1000/collection/1155/\n",
            "  inflating: Persons-1000/collection/1155/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1155/text.txt  \n",
            "   creating: Persons-1000/collection/1156/\n",
            "  inflating: Persons-1000/collection/1156/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1156/text.txt  \n",
            "   creating: Persons-1000/collection/1157/\n",
            "  inflating: Persons-1000/collection/1157/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1157/text.txt  \n",
            "   creating: Persons-1000/collection/1158/\n",
            "  inflating: Persons-1000/collection/1158/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1158/text.txt  \n",
            "   creating: Persons-1000/collection/1159/\n",
            "  inflating: Persons-1000/collection/1159/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1159/text.txt  \n",
            "   creating: Persons-1000/collection/116/\n",
            "  inflating: Persons-1000/collection/116/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/116/text.txt  \n",
            "   creating: Persons-1000/collection/1160/\n",
            "  inflating: Persons-1000/collection/1160/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1160/text.txt  \n",
            "   creating: Persons-1000/collection/1161/\n",
            "  inflating: Persons-1000/collection/1161/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1161/text.txt  \n",
            "   creating: Persons-1000/collection/1162/\n",
            "  inflating: Persons-1000/collection/1162/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1162/text.txt  \n",
            "   creating: Persons-1000/collection/1163/\n",
            "  inflating: Persons-1000/collection/1163/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1163/text.txt  \n",
            "   creating: Persons-1000/collection/1164/\n",
            "  inflating: Persons-1000/collection/1164/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1164/text.txt  \n",
            "   creating: Persons-1000/collection/1165/\n",
            "  inflating: Persons-1000/collection/1165/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1165/text.txt  \n",
            "   creating: Persons-1000/collection/1166/\n",
            "  inflating: Persons-1000/collection/1166/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1166/text.txt  \n",
            "   creating: Persons-1000/collection/1167/\n",
            "  inflating: Persons-1000/collection/1167/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1167/text.txt  \n",
            "   creating: Persons-1000/collection/1168/\n",
            "  inflating: Persons-1000/collection/1168/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1168/text.txt  \n",
            "   creating: Persons-1000/collection/1169/\n",
            "  inflating: Persons-1000/collection/1169/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1169/text.txt  \n",
            "   creating: Persons-1000/collection/117/\n",
            "  inflating: Persons-1000/collection/117/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/117/text.txt  \n",
            "   creating: Persons-1000/collection/1170/\n",
            "  inflating: Persons-1000/collection/1170/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1170/text.txt  \n",
            "   creating: Persons-1000/collection/1171/\n",
            "  inflating: Persons-1000/collection/1171/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1171/text.txt  \n",
            "   creating: Persons-1000/collection/1172/\n",
            "  inflating: Persons-1000/collection/1172/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1172/text.txt  \n",
            "   creating: Persons-1000/collection/1173/\n",
            "  inflating: Persons-1000/collection/1173/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1173/text.txt  \n",
            "   creating: Persons-1000/collection/1174/\n",
            "  inflating: Persons-1000/collection/1174/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1174/text.txt  \n",
            "   creating: Persons-1000/collection/1175/\n",
            "  inflating: Persons-1000/collection/1175/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1175/text.txt  \n",
            "   creating: Persons-1000/collection/1176/\n",
            "  inflating: Persons-1000/collection/1176/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1176/text.txt  \n",
            "   creating: Persons-1000/collection/1177/\n",
            "  inflating: Persons-1000/collection/1177/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1177/text.txt  \n",
            "   creating: Persons-1000/collection/1178/\n",
            "  inflating: Persons-1000/collection/1178/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1178/text.txt  \n",
            "   creating: Persons-1000/collection/1179/\n",
            "  inflating: Persons-1000/collection/1179/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1179/text.txt  \n",
            "   creating: Persons-1000/collection/118/\n",
            "  inflating: Persons-1000/collection/118/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/118/text.txt  \n",
            "   creating: Persons-1000/collection/1180/\n",
            "  inflating: Persons-1000/collection/1180/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1180/text.txt  \n",
            "   creating: Persons-1000/collection/1181/\n",
            "  inflating: Persons-1000/collection/1181/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1181/text.txt  \n",
            "   creating: Persons-1000/collection/1182/\n",
            "  inflating: Persons-1000/collection/1182/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1182/text.txt  \n",
            "   creating: Persons-1000/collection/1183/\n",
            "  inflating: Persons-1000/collection/1183/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1183/text.txt  \n",
            "   creating: Persons-1000/collection/1184/\n",
            "  inflating: Persons-1000/collection/1184/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1184/text.txt  \n",
            "   creating: Persons-1000/collection/1185/\n",
            "  inflating: Persons-1000/collection/1185/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1185/text.txt  \n",
            "   creating: Persons-1000/collection/1186/\n",
            "  inflating: Persons-1000/collection/1186/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1186/text.txt  \n",
            "   creating: Persons-1000/collection/1187/\n",
            "  inflating: Persons-1000/collection/1187/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1187/text.txt  \n",
            "   creating: Persons-1000/collection/1188/\n",
            "  inflating: Persons-1000/collection/1188/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1188/text.txt  \n",
            "   creating: Persons-1000/collection/1189/\n",
            "  inflating: Persons-1000/collection/1189/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1189/text.txt  \n",
            "   creating: Persons-1000/collection/119/\n",
            "  inflating: Persons-1000/collection/119/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/119/text.txt  \n",
            "   creating: Persons-1000/collection/1190/\n",
            "  inflating: Persons-1000/collection/1190/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1190/text.txt  \n",
            "   creating: Persons-1000/collection/1191/\n",
            "  inflating: Persons-1000/collection/1191/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1191/text.txt  \n",
            "   creating: Persons-1000/collection/1192/\n",
            "  inflating: Persons-1000/collection/1192/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1192/text.txt  \n",
            "   creating: Persons-1000/collection/1193/\n",
            "  inflating: Persons-1000/collection/1193/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1193/text.txt  \n",
            "   creating: Persons-1000/collection/1194/\n",
            "  inflating: Persons-1000/collection/1194/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1194/text.txt  \n",
            "   creating: Persons-1000/collection/1195/\n",
            "  inflating: Persons-1000/collection/1195/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1195/text.txt  \n",
            "   creating: Persons-1000/collection/1196/\n",
            "  inflating: Persons-1000/collection/1196/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1196/text.txt  \n",
            "   creating: Persons-1000/collection/1197/\n",
            "  inflating: Persons-1000/collection/1197/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1197/text.txt  \n",
            "   creating: Persons-1000/collection/1198/\n",
            "  inflating: Persons-1000/collection/1198/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1198/text.txt  \n",
            "   creating: Persons-1000/collection/1199/\n",
            "  inflating: Persons-1000/collection/1199/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1199/text.txt  \n",
            "   creating: Persons-1000/collection/11_01_13b/\n",
            "  inflating: Persons-1000/collection/11_01_13b/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/11_01_13b/text.txt  \n",
            "   creating: Persons-1000/collection/11_01_13e/\n",
            "  inflating: Persons-1000/collection/11_01_13e/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/11_01_13e/text.txt  \n",
            "   creating: Persons-1000/collection/120/\n",
            "  inflating: Persons-1000/collection/120/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/120/text.txt  \n",
            "   creating: Persons-1000/collection/1200/\n",
            "  inflating: Persons-1000/collection/1200/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/1200/text.txt  \n",
            "   creating: Persons-1000/collection/121/\n",
            "  inflating: Persons-1000/collection/121/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/121/text.txt  \n",
            "   creating: Persons-1000/collection/122/\n",
            "  inflating: Persons-1000/collection/122/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/122/text.txt  \n",
            "   creating: Persons-1000/collection/123/\n",
            "  inflating: Persons-1000/collection/123/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/123/text.txt  \n",
            "   creating: Persons-1000/collection/124/\n",
            "  inflating: Persons-1000/collection/124/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/124/text.txt  \n",
            "   creating: Persons-1000/collection/125/\n",
            "  inflating: Persons-1000/collection/125/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/125/text.txt  \n",
            "   creating: Persons-1000/collection/126/\n",
            "  inflating: Persons-1000/collection/126/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/126/text.txt  \n",
            "   creating: Persons-1000/collection/127/\n",
            "  inflating: Persons-1000/collection/127/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/127/text.txt  \n",
            "   creating: Persons-1000/collection/128/\n",
            "  inflating: Persons-1000/collection/128/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/128/text.txt  \n",
            "   creating: Persons-1000/collection/129/\n",
            "  inflating: Persons-1000/collection/129/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/129/text.txt  \n",
            "   creating: Persons-1000/collection/130/\n",
            "  inflating: Persons-1000/collection/130/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/130/text.txt  \n",
            "   creating: Persons-1000/collection/131/\n",
            "  inflating: Persons-1000/collection/131/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/131/text.txt  \n",
            "   creating: Persons-1000/collection/132/\n",
            "  inflating: Persons-1000/collection/132/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/132/text.txt  \n",
            "   creating: Persons-1000/collection/133/\n",
            "  inflating: Persons-1000/collection/133/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/133/text.txt  \n",
            "   creating: Persons-1000/collection/134/\n",
            "  inflating: Persons-1000/collection/134/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/134/text.txt  \n",
            "   creating: Persons-1000/collection/135/\n",
            "  inflating: Persons-1000/collection/135/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/135/text.txt  \n",
            "   creating: Persons-1000/collection/136/\n",
            "  inflating: Persons-1000/collection/136/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/136/text.txt  \n",
            "   creating: Persons-1000/collection/137/\n",
            "  inflating: Persons-1000/collection/137/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/137/text.txt  \n",
            "   creating: Persons-1000/collection/138/\n",
            "  inflating: Persons-1000/collection/138/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/138/text.txt  \n",
            "   creating: Persons-1000/collection/139/\n",
            "  inflating: Persons-1000/collection/139/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/139/text.txt  \n",
            "   creating: Persons-1000/collection/140/\n",
            "  inflating: Persons-1000/collection/140/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/140/text.txt  \n",
            "   creating: Persons-1000/collection/141/\n",
            "  inflating: Persons-1000/collection/141/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/141/text.txt  \n",
            "   creating: Persons-1000/collection/142/\n",
            "  inflating: Persons-1000/collection/142/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/142/text.txt  \n",
            "   creating: Persons-1000/collection/143/\n",
            "  inflating: Persons-1000/collection/143/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/143/text.txt  \n",
            "   creating: Persons-1000/collection/144/\n",
            "  inflating: Persons-1000/collection/144/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/144/text.txt  \n",
            "   creating: Persons-1000/collection/145/\n",
            "  inflating: Persons-1000/collection/145/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/145/text.txt  \n",
            "   creating: Persons-1000/collection/146/\n",
            "  inflating: Persons-1000/collection/146/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/146/text.txt  \n",
            "   creating: Persons-1000/collection/147/\n",
            "  inflating: Persons-1000/collection/147/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/147/text.txt  \n",
            "   creating: Persons-1000/collection/148/\n",
            " extracting: Persons-1000/collection/148/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/148/text.txt  \n",
            "   creating: Persons-1000/collection/149/\n",
            "  inflating: Persons-1000/collection/149/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/149/text.txt  \n",
            "   creating: Persons-1000/collection/14_01_13c/\n",
            "  inflating: Persons-1000/collection/14_01_13c/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/14_01_13c/text.txt  \n",
            "   creating: Persons-1000/collection/14_01_13g/\n",
            "  inflating: Persons-1000/collection/14_01_13g/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/14_01_13g/text.txt  \n",
            "   creating: Persons-1000/collection/14_01_13i/\n",
            "  inflating: Persons-1000/collection/14_01_13i/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/14_01_13i/text.txt  \n",
            "   creating: Persons-1000/collection/150/\n",
            "  inflating: Persons-1000/collection/150/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/150/text.txt  \n",
            "   creating: Persons-1000/collection/151/\n",
            "  inflating: Persons-1000/collection/151/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/151/text.txt  \n",
            "   creating: Persons-1000/collection/152/\n",
            "  inflating: Persons-1000/collection/152/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/152/text.txt  \n",
            "   creating: Persons-1000/collection/153/\n",
            "  inflating: Persons-1000/collection/153/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/153/text.txt  \n",
            "   creating: Persons-1000/collection/154/\n",
            "  inflating: Persons-1000/collection/154/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/154/text.txt  \n",
            "   creating: Persons-1000/collection/155/\n",
            "  inflating: Persons-1000/collection/155/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/155/text.txt  \n",
            "   creating: Persons-1000/collection/156/\n",
            "  inflating: Persons-1000/collection/156/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/156/text.txt  \n",
            "   creating: Persons-1000/collection/157/\n",
            "  inflating: Persons-1000/collection/157/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/157/text.txt  \n",
            "   creating: Persons-1000/collection/158/\n",
            "  inflating: Persons-1000/collection/158/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/158/text.txt  \n",
            "   creating: Persons-1000/collection/159/\n",
            "  inflating: Persons-1000/collection/159/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/159/text.txt  \n",
            "   creating: Persons-1000/collection/15_01_13a/\n",
            "  inflating: Persons-1000/collection/15_01_13a/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/15_01_13a/text.txt  \n",
            "   creating: Persons-1000/collection/15_01_13b/\n",
            "  inflating: Persons-1000/collection/15_01_13b/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/15_01_13b/text.txt  \n",
            "   creating: Persons-1000/collection/15_01_13e/\n",
            "  inflating: Persons-1000/collection/15_01_13e/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/15_01_13e/text.txt  \n",
            "   creating: Persons-1000/collection/15_01_13f/\n",
            "  inflating: Persons-1000/collection/15_01_13f/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/15_01_13f/text.txt  \n",
            "   creating: Persons-1000/collection/160/\n",
            "  inflating: Persons-1000/collection/160/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/160/text.txt  \n",
            "   creating: Persons-1000/collection/161/\n",
            "  inflating: Persons-1000/collection/161/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/161/text.txt  \n",
            "   creating: Persons-1000/collection/162/\n",
            "  inflating: Persons-1000/collection/162/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/162/text.txt  \n",
            "   creating: Persons-1000/collection/163/\n",
            "  inflating: Persons-1000/collection/163/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/163/text.txt  \n",
            "   creating: Persons-1000/collection/164/\n",
            "  inflating: Persons-1000/collection/164/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/164/text.txt  \n",
            "   creating: Persons-1000/collection/165/\n",
            "  inflating: Persons-1000/collection/165/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/165/text.txt  \n",
            "   creating: Persons-1000/collection/166/\n",
            "  inflating: Persons-1000/collection/166/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/166/text.txt  \n",
            "   creating: Persons-1000/collection/167/\n",
            "  inflating: Persons-1000/collection/167/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/167/text.txt  \n",
            "   creating: Persons-1000/collection/168/\n",
            "  inflating: Persons-1000/collection/168/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/168/text.txt  \n",
            "   creating: Persons-1000/collection/169/\n",
            "  inflating: Persons-1000/collection/169/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/169/text.txt  \n",
            "   creating: Persons-1000/collection/170/\n",
            "  inflating: Persons-1000/collection/170/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/170/text.txt  \n",
            "   creating: Persons-1000/collection/171/\n",
            "  inflating: Persons-1000/collection/171/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/171/text.txt  \n",
            "   creating: Persons-1000/collection/172/\n",
            "  inflating: Persons-1000/collection/172/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/172/text.txt  \n",
            "   creating: Persons-1000/collection/173/\n",
            "  inflating: Persons-1000/collection/173/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/173/text.txt  \n",
            "   creating: Persons-1000/collection/174/\n",
            "  inflating: Persons-1000/collection/174/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/174/text.txt  \n",
            "   creating: Persons-1000/collection/175/\n",
            "  inflating: Persons-1000/collection/175/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/175/text.txt  \n",
            "   creating: Persons-1000/collection/176/\n",
            "  inflating: Persons-1000/collection/176/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/176/text.txt  \n",
            "   creating: Persons-1000/collection/177/\n",
            "  inflating: Persons-1000/collection/177/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/177/text.txt  \n",
            "   creating: Persons-1000/collection/178/\n",
            "  inflating: Persons-1000/collection/178/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/178/text.txt  \n",
            "   creating: Persons-1000/collection/179/\n",
            "  inflating: Persons-1000/collection/179/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/179/text.txt  \n",
            "   creating: Persons-1000/collection/180/\n",
            "  inflating: Persons-1000/collection/180/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/180/text.txt  \n",
            "   creating: Persons-1000/collection/181/\n",
            "  inflating: Persons-1000/collection/181/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/181/text.txt  \n",
            "   creating: Persons-1000/collection/182/\n",
            "  inflating: Persons-1000/collection/182/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/182/text.txt  \n",
            "   creating: Persons-1000/collection/183/\n",
            "  inflating: Persons-1000/collection/183/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/183/text.txt  \n",
            "   creating: Persons-1000/collection/184/\n",
            "  inflating: Persons-1000/collection/184/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/184/text.txt  \n",
            "   creating: Persons-1000/collection/185/\n",
            "  inflating: Persons-1000/collection/185/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/185/text.txt  \n",
            "   creating: Persons-1000/collection/186/\n",
            "  inflating: Persons-1000/collection/186/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/186/text.txt  \n",
            "   creating: Persons-1000/collection/187/\n",
            "  inflating: Persons-1000/collection/187/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/187/text.txt  \n",
            "   creating: Persons-1000/collection/188/\n",
            "  inflating: Persons-1000/collection/188/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/188/text.txt  \n",
            "   creating: Persons-1000/collection/189/\n",
            "  inflating: Persons-1000/collection/189/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/189/text.txt  \n",
            "   creating: Persons-1000/collection/190/\n",
            "  inflating: Persons-1000/collection/190/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/190/text.txt  \n",
            "   creating: Persons-1000/collection/191/\n",
            "  inflating: Persons-1000/collection/191/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/191/text.txt  \n",
            "   creating: Persons-1000/collection/192/\n",
            " extracting: Persons-1000/collection/192/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/192/text.txt  \n",
            "   creating: Persons-1000/collection/193/\n",
            "  inflating: Persons-1000/collection/193/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/193/text.txt  \n",
            "   creating: Persons-1000/collection/194/\n",
            "  inflating: Persons-1000/collection/194/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/194/text.txt  \n",
            "   creating: Persons-1000/collection/195/\n",
            "  inflating: Persons-1000/collection/195/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/195/text.txt  \n",
            "   creating: Persons-1000/collection/196/\n",
            "  inflating: Persons-1000/collection/196/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/196/text.txt  \n",
            "   creating: Persons-1000/collection/197/\n",
            "  inflating: Persons-1000/collection/197/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/197/text.txt  \n",
            "   creating: Persons-1000/collection/198/\n",
            "  inflating: Persons-1000/collection/198/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/198/text.txt  \n",
            "   creating: Persons-1000/collection/199/\n",
            "  inflating: Persons-1000/collection/199/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/199/text.txt  \n",
            "   creating: Persons-1000/collection/19_11_12d/\n",
            "  inflating: Persons-1000/collection/19_11_12d/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/19_11_12d/text.txt  \n",
            "   creating: Persons-1000/collection/19_11_12h/\n",
            "  inflating: Persons-1000/collection/19_11_12h/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/19_11_12h/text.txt  \n",
            "   creating: Persons-1000/collection/200/\n",
            "  inflating: Persons-1000/collection/200/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/200/text.txt  \n",
            "   creating: Persons-1000/collection/2001/\n",
            "  inflating: Persons-1000/collection/2001/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2001/text.txt  \n",
            "   creating: Persons-1000/collection/2002/\n",
            "  inflating: Persons-1000/collection/2002/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2002/text.txt  \n",
            "   creating: Persons-1000/collection/2003/\n",
            "  inflating: Persons-1000/collection/2003/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2003/text.txt  \n",
            "   creating: Persons-1000/collection/2004/\n",
            "  inflating: Persons-1000/collection/2004/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2004/text.txt  \n",
            "   creating: Persons-1000/collection/2005/\n",
            "  inflating: Persons-1000/collection/2005/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2005/text.txt  \n",
            "   creating: Persons-1000/collection/2006/\n",
            "  inflating: Persons-1000/collection/2006/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2006/text.txt  \n",
            "   creating: Persons-1000/collection/2007/\n",
            "  inflating: Persons-1000/collection/2007/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2007/text.txt  \n",
            "   creating: Persons-1000/collection/2008/\n",
            "  inflating: Persons-1000/collection/2008/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2008/text.txt  \n",
            "   creating: Persons-1000/collection/2009/\n",
            "  inflating: Persons-1000/collection/2009/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2009/text.txt  \n",
            "   creating: Persons-1000/collection/201/\n",
            "  inflating: Persons-1000/collection/201/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/201/text.txt  \n",
            "   creating: Persons-1000/collection/2010/\n",
            "  inflating: Persons-1000/collection/2010/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2010/text.txt  \n",
            "   creating: Persons-1000/collection/2011/\n",
            "  inflating: Persons-1000/collection/2011/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2011/text.txt  \n",
            "   creating: Persons-1000/collection/2012/\n",
            "  inflating: Persons-1000/collection/2012/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2012/text.txt  \n",
            "   creating: Persons-1000/collection/2013/\n",
            "  inflating: Persons-1000/collection/2013/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2013/text.txt  \n",
            "   creating: Persons-1000/collection/2014/\n",
            "  inflating: Persons-1000/collection/2014/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2014/text.txt  \n",
            "   creating: Persons-1000/collection/2015/\n",
            "  inflating: Persons-1000/collection/2015/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2015/text.txt  \n",
            "   creating: Persons-1000/collection/2016/\n",
            "  inflating: Persons-1000/collection/2016/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2016/text.txt  \n",
            "   creating: Persons-1000/collection/2017/\n",
            "  inflating: Persons-1000/collection/2017/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2017/text.txt  \n",
            "   creating: Persons-1000/collection/2018/\n",
            "  inflating: Persons-1000/collection/2018/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2018/text.txt  \n",
            "   creating: Persons-1000/collection/2019/\n",
            "  inflating: Persons-1000/collection/2019/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2019/text.txt  \n",
            "   creating: Persons-1000/collection/202/\n",
            "  inflating: Persons-1000/collection/202/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/202/text.txt  \n",
            "   creating: Persons-1000/collection/2020/\n",
            "  inflating: Persons-1000/collection/2020/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2020/text.txt  \n",
            "   creating: Persons-1000/collection/2021/\n",
            "  inflating: Persons-1000/collection/2021/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2021/text.txt  \n",
            "   creating: Persons-1000/collection/2022/\n",
            "  inflating: Persons-1000/collection/2022/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2022/text.txt  \n",
            "   creating: Persons-1000/collection/2023/\n",
            "  inflating: Persons-1000/collection/2023/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2023/text.txt  \n",
            "   creating: Persons-1000/collection/2024/\n",
            "  inflating: Persons-1000/collection/2024/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2024/text.txt  \n",
            "   creating: Persons-1000/collection/2025/\n",
            "  inflating: Persons-1000/collection/2025/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2025/text.txt  \n",
            "   creating: Persons-1000/collection/2026/\n",
            "  inflating: Persons-1000/collection/2026/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2026/text.txt  \n",
            "   creating: Persons-1000/collection/2027/\n",
            "  inflating: Persons-1000/collection/2027/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2027/text.txt  \n",
            "   creating: Persons-1000/collection/2028/\n",
            "  inflating: Persons-1000/collection/2028/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2028/text.txt  \n",
            "   creating: Persons-1000/collection/2029/\n",
            "  inflating: Persons-1000/collection/2029/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2029/text.txt  \n",
            "   creating: Persons-1000/collection/203/\n",
            "  inflating: Persons-1000/collection/203/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/203/text.txt  \n",
            "   creating: Persons-1000/collection/2030/\n",
            "  inflating: Persons-1000/collection/2030/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2030/text.txt  \n",
            "   creating: Persons-1000/collection/2031/\n",
            "  inflating: Persons-1000/collection/2031/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2031/text.txt  \n",
            "   creating: Persons-1000/collection/2032/\n",
            "  inflating: Persons-1000/collection/2032/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2032/text.txt  \n",
            "   creating: Persons-1000/collection/2034/\n",
            "  inflating: Persons-1000/collection/2034/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2034/text.txt  \n",
            "   creating: Persons-1000/collection/2035/\n",
            "  inflating: Persons-1000/collection/2035/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2035/text.txt  \n",
            "   creating: Persons-1000/collection/2036/\n",
            "  inflating: Persons-1000/collection/2036/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2036/text.txt  \n",
            "   creating: Persons-1000/collection/2037/\n",
            "  inflating: Persons-1000/collection/2037/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2037/text.txt  \n",
            "   creating: Persons-1000/collection/2038/\n",
            "  inflating: Persons-1000/collection/2038/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2038/text.txt  \n",
            "   creating: Persons-1000/collection/2039/\n",
            "  inflating: Persons-1000/collection/2039/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2039/text.txt  \n",
            "   creating: Persons-1000/collection/204/\n",
            "  inflating: Persons-1000/collection/204/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/204/text.txt  \n",
            "   creating: Persons-1000/collection/2040/\n",
            "  inflating: Persons-1000/collection/2040/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2040/text.txt  \n",
            "   creating: Persons-1000/collection/2041/\n",
            "  inflating: Persons-1000/collection/2041/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2041/text.txt  \n",
            "   creating: Persons-1000/collection/2042/\n",
            "  inflating: Persons-1000/collection/2042/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2042/text.txt  \n",
            "   creating: Persons-1000/collection/2043/\n",
            "  inflating: Persons-1000/collection/2043/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2043/text.txt  \n",
            "   creating: Persons-1000/collection/2044/\n",
            "  inflating: Persons-1000/collection/2044/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2044/text.txt  \n",
            "   creating: Persons-1000/collection/2045/\n",
            "  inflating: Persons-1000/collection/2045/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2045/text.txt  \n",
            "   creating: Persons-1000/collection/2046/\n",
            "  inflating: Persons-1000/collection/2046/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2046/text.txt  \n",
            "   creating: Persons-1000/collection/2047/\n",
            "  inflating: Persons-1000/collection/2047/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2047/text.txt  \n",
            "   creating: Persons-1000/collection/2048/\n",
            "  inflating: Persons-1000/collection/2048/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2048/text.txt  \n",
            "   creating: Persons-1000/collection/2049/\n",
            "  inflating: Persons-1000/collection/2049/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2049/text.txt  \n",
            "   creating: Persons-1000/collection/205/\n",
            "  inflating: Persons-1000/collection/205/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/205/text.txt  \n",
            "   creating: Persons-1000/collection/2050/\n",
            "  inflating: Persons-1000/collection/2050/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/2050/text.txt  \n",
            "   creating: Persons-1000/collection/206/\n",
            "  inflating: Persons-1000/collection/206/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/206/text.txt  \n",
            "   creating: Persons-1000/collection/207/\n",
            "  inflating: Persons-1000/collection/207/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/207/text.txt  \n",
            "   creating: Persons-1000/collection/208/\n",
            "  inflating: Persons-1000/collection/208/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/208/text.txt  \n",
            "   creating: Persons-1000/collection/209/\n",
            "  inflating: Persons-1000/collection/209/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/209/text.txt  \n",
            "   creating: Persons-1000/collection/20_11_12a/\n",
            "  inflating: Persons-1000/collection/20_11_12a/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/20_11_12a/text.txt  \n",
            "   creating: Persons-1000/collection/20_11_12b/\n",
            "  inflating: Persons-1000/collection/20_11_12b/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/20_11_12b/text.txt  \n",
            "   creating: Persons-1000/collection/20_11_12c/\n",
            "  inflating: Persons-1000/collection/20_11_12c/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/20_11_12c/text.txt  \n",
            "   creating: Persons-1000/collection/20_11_12d/\n",
            "  inflating: Persons-1000/collection/20_11_12d/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/20_11_12d/text.txt  \n",
            "   creating: Persons-1000/collection/20_11_12i/\n",
            "  inflating: Persons-1000/collection/20_11_12i/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/20_11_12i/text.txt  \n",
            "   creating: Persons-1000/collection/210/\n",
            "  inflating: Persons-1000/collection/210/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/210/text.txt  \n",
            "   creating: Persons-1000/collection/211/\n",
            "  inflating: Persons-1000/collection/211/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/211/text.txt  \n",
            "   creating: Persons-1000/collection/212/\n",
            "  inflating: Persons-1000/collection/212/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/212/text.txt  \n",
            "   creating: Persons-1000/collection/213/\n",
            "  inflating: Persons-1000/collection/213/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/213/text.txt  \n",
            "   creating: Persons-1000/collection/214/\n",
            "  inflating: Persons-1000/collection/214/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/214/text.txt  \n",
            "   creating: Persons-1000/collection/215/\n",
            "  inflating: Persons-1000/collection/215/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/215/text.txt  \n",
            "   creating: Persons-1000/collection/216/\n",
            "  inflating: Persons-1000/collection/216/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/216/text.txt  \n",
            "   creating: Persons-1000/collection/217/\n",
            "  inflating: Persons-1000/collection/217/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/217/text.txt  \n",
            "   creating: Persons-1000/collection/218/\n",
            "  inflating: Persons-1000/collection/218/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/218/text.txt  \n",
            "   creating: Persons-1000/collection/219/\n",
            "  inflating: Persons-1000/collection/219/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/219/text.txt  \n",
            "   creating: Persons-1000/collection/21_11_12c/\n",
            "  inflating: Persons-1000/collection/21_11_12c/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/21_11_12c/text.txt  \n",
            "   creating: Persons-1000/collection/21_11_12h/\n",
            "  inflating: Persons-1000/collection/21_11_12h/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/21_11_12h/text.txt  \n",
            "   creating: Persons-1000/collection/21_11_12i/\n",
            "  inflating: Persons-1000/collection/21_11_12i/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/21_11_12i/text.txt  \n",
            "   creating: Persons-1000/collection/21_11_12j/\n",
            "  inflating: Persons-1000/collection/21_11_12j/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/21_11_12j/text.txt  \n",
            "   creating: Persons-1000/collection/220/\n",
            "  inflating: Persons-1000/collection/220/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/220/text.txt  \n",
            "   creating: Persons-1000/collection/221/\n",
            "  inflating: Persons-1000/collection/221/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/221/text.txt  \n",
            "   creating: Persons-1000/collection/222/\n",
            "  inflating: Persons-1000/collection/222/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/222/text.txt  \n",
            "   creating: Persons-1000/collection/223/\n",
            "  inflating: Persons-1000/collection/223/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/223/text.txt  \n",
            "   creating: Persons-1000/collection/224/\n",
            "  inflating: Persons-1000/collection/224/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/224/text.txt  \n",
            "   creating: Persons-1000/collection/225/\n",
            "  inflating: Persons-1000/collection/225/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/225/text.txt  \n",
            "   creating: Persons-1000/collection/226/\n",
            "  inflating: Persons-1000/collection/226/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/226/text.txt  \n",
            "   creating: Persons-1000/collection/227/\n",
            "  inflating: Persons-1000/collection/227/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/227/text.txt  \n",
            "   creating: Persons-1000/collection/228/\n",
            "  inflating: Persons-1000/collection/228/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/228/text.txt  \n",
            "   creating: Persons-1000/collection/229/\n",
            "  inflating: Persons-1000/collection/229/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/229/text.txt  \n",
            "   creating: Persons-1000/collection/22_11_12a/\n",
            "  inflating: Persons-1000/collection/22_11_12a/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/22_11_12a/text.txt  \n",
            "   creating: Persons-1000/collection/22_11_12c/\n",
            "  inflating: Persons-1000/collection/22_11_12c/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/22_11_12c/text.txt  \n",
            "   creating: Persons-1000/collection/22_11_12d/\n",
            "  inflating: Persons-1000/collection/22_11_12d/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/22_11_12d/text.txt  \n",
            "   creating: Persons-1000/collection/22_11_12g/\n",
            "  inflating: Persons-1000/collection/22_11_12g/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/22_11_12g/text.txt  \n",
            "   creating: Persons-1000/collection/22_11_12h/\n",
            "  inflating: Persons-1000/collection/22_11_12h/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/22_11_12h/text.txt  \n",
            "   creating: Persons-1000/collection/22_11_12i/\n",
            "  inflating: Persons-1000/collection/22_11_12i/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/22_11_12i/text.txt  \n",
            "   creating: Persons-1000/collection/22_11_12j/\n",
            "  inflating: Persons-1000/collection/22_11_12j/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/22_11_12j/text.txt  \n",
            "   creating: Persons-1000/collection/230/\n",
            "  inflating: Persons-1000/collection/230/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/230/text.txt  \n",
            "   creating: Persons-1000/collection/231/\n",
            "  inflating: Persons-1000/collection/231/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/231/text.txt  \n",
            "   creating: Persons-1000/collection/232/\n",
            "  inflating: Persons-1000/collection/232/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/232/text.txt  \n",
            "   creating: Persons-1000/collection/233/\n",
            "  inflating: Persons-1000/collection/233/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/233/text.txt  \n",
            "   creating: Persons-1000/collection/234/\n",
            "  inflating: Persons-1000/collection/234/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/234/text.txt  \n",
            "   creating: Persons-1000/collection/235/\n",
            "  inflating: Persons-1000/collection/235/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/235/text.txt  \n",
            "   creating: Persons-1000/collection/236/\n",
            "  inflating: Persons-1000/collection/236/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/236/text.txt  \n",
            "   creating: Persons-1000/collection/237/\n",
            "  inflating: Persons-1000/collection/237/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/237/text.txt  \n",
            "   creating: Persons-1000/collection/238/\n",
            "  inflating: Persons-1000/collection/238/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/238/text.txt  \n",
            "   creating: Persons-1000/collection/239/\n",
            "  inflating: Persons-1000/collection/239/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/239/text.txt  \n",
            "   creating: Persons-1000/collection/23_11_12a/\n",
            "  inflating: Persons-1000/collection/23_11_12a/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/23_11_12a/text.txt  \n",
            "   creating: Persons-1000/collection/23_11_12b/\n",
            "  inflating: Persons-1000/collection/23_11_12b/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/23_11_12b/text.txt  \n",
            "   creating: Persons-1000/collection/23_11_12c/\n",
            "  inflating: Persons-1000/collection/23_11_12c/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/23_11_12c/text.txt  \n",
            "   creating: Persons-1000/collection/23_11_12d/\n",
            "  inflating: Persons-1000/collection/23_11_12d/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/23_11_12d/text.txt  \n",
            "   creating: Persons-1000/collection/23_11_12e/\n",
            "  inflating: Persons-1000/collection/23_11_12e/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/23_11_12e/text.txt  \n",
            "   creating: Persons-1000/collection/23_11_12f/\n",
            "  inflating: Persons-1000/collection/23_11_12f/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/23_11_12f/text.txt  \n",
            "   creating: Persons-1000/collection/240/\n",
            "  inflating: Persons-1000/collection/240/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/240/text.txt  \n",
            "   creating: Persons-1000/collection/241/\n",
            "  inflating: Persons-1000/collection/241/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/241/text.txt  \n",
            "   creating: Persons-1000/collection/242/\n",
            "  inflating: Persons-1000/collection/242/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/242/text.txt  \n",
            "   creating: Persons-1000/collection/243/\n",
            "  inflating: Persons-1000/collection/243/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/243/text.txt  \n",
            "   creating: Persons-1000/collection/244/\n",
            "  inflating: Persons-1000/collection/244/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/244/text.txt  \n",
            "   creating: Persons-1000/collection/245/\n",
            "  inflating: Persons-1000/collection/245/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/245/text.txt  \n",
            "   creating: Persons-1000/collection/246/\n",
            "  inflating: Persons-1000/collection/246/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/246/text.txt  \n",
            "   creating: Persons-1000/collection/247/\n",
            "  inflating: Persons-1000/collection/247/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/247/text.txt  \n",
            "   creating: Persons-1000/collection/248/\n",
            "  inflating: Persons-1000/collection/248/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/248/text.txt  \n",
            "   creating: Persons-1000/collection/249/\n",
            "  inflating: Persons-1000/collection/249/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/249/text.txt  \n",
            "   creating: Persons-1000/collection/250/\n",
            "  inflating: Persons-1000/collection/250/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/250/text.txt  \n",
            "   creating: Persons-1000/collection/251/\n",
            "  inflating: Persons-1000/collection/251/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/251/text.txt  \n",
            "   creating: Persons-1000/collection/252/\n",
            "  inflating: Persons-1000/collection/252/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/252/text.txt  \n",
            "   creating: Persons-1000/collection/253/\n",
            "  inflating: Persons-1000/collection/253/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/253/text.txt  \n",
            "   creating: Persons-1000/collection/254/\n",
            "  inflating: Persons-1000/collection/254/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/254/text.txt  \n",
            "   creating: Persons-1000/collection/255/\n",
            "  inflating: Persons-1000/collection/255/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/255/text.txt  \n",
            "   creating: Persons-1000/collection/256/\n",
            "  inflating: Persons-1000/collection/256/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/256/text.txt  \n",
            "   creating: Persons-1000/collection/257/\n",
            "  inflating: Persons-1000/collection/257/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/257/text.txt  \n",
            "   creating: Persons-1000/collection/258/\n",
            "  inflating: Persons-1000/collection/258/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/258/text.txt  \n",
            "   creating: Persons-1000/collection/259/\n",
            "  inflating: Persons-1000/collection/259/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/259/text.txt  \n",
            "   creating: Persons-1000/collection/25_12_12a/\n",
            "  inflating: Persons-1000/collection/25_12_12a/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/25_12_12a/text.txt  \n",
            "   creating: Persons-1000/collection/25_12_12c/\n",
            "  inflating: Persons-1000/collection/25_12_12c/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/25_12_12c/text.txt  \n",
            "   creating: Persons-1000/collection/25_12_12d/\n",
            "  inflating: Persons-1000/collection/25_12_12d/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/25_12_12d/text.txt  \n",
            "   creating: Persons-1000/collection/25_12_12e/\n",
            "  inflating: Persons-1000/collection/25_12_12e/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/25_12_12e/text.txt  \n",
            "   creating: Persons-1000/collection/260/\n",
            "  inflating: Persons-1000/collection/260/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/260/text.txt  \n",
            "   creating: Persons-1000/collection/261/\n",
            "  inflating: Persons-1000/collection/261/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/261/text.txt  \n",
            "   creating: Persons-1000/collection/262/\n",
            "  inflating: Persons-1000/collection/262/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/262/text.txt  \n",
            "   creating: Persons-1000/collection/263/\n",
            "  inflating: Persons-1000/collection/263/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/263/text.txt  \n",
            "   creating: Persons-1000/collection/264/\n",
            "  inflating: Persons-1000/collection/264/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/264/text.txt  \n",
            "   creating: Persons-1000/collection/265/\n",
            "  inflating: Persons-1000/collection/265/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/265/text.txt  \n",
            "   creating: Persons-1000/collection/266/\n",
            "  inflating: Persons-1000/collection/266/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/266/text.txt  \n",
            "   creating: Persons-1000/collection/267/\n",
            "  inflating: Persons-1000/collection/267/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/267/text.txt  \n",
            "   creating: Persons-1000/collection/268/\n",
            "  inflating: Persons-1000/collection/268/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/268/text.txt  \n",
            "   creating: Persons-1000/collection/269/\n",
            "  inflating: Persons-1000/collection/269/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/269/text.txt  \n",
            "   creating: Persons-1000/collection/26_11_12b/\n",
            "  inflating: Persons-1000/collection/26_11_12b/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/26_11_12b/text.txt  \n",
            "   creating: Persons-1000/collection/26_11_12c/\n",
            "  inflating: Persons-1000/collection/26_11_12c/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/26_11_12c/text.txt  \n",
            "   creating: Persons-1000/collection/26_11_12e/\n",
            "  inflating: Persons-1000/collection/26_11_12e/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/26_11_12e/text.txt  \n",
            "   creating: Persons-1000/collection/26_11_12f/\n",
            "  inflating: Persons-1000/collection/26_11_12f/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/26_11_12f/text.txt  \n",
            "   creating: Persons-1000/collection/270/\n",
            "  inflating: Persons-1000/collection/270/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/270/text.txt  \n",
            "   creating: Persons-1000/collection/271/\n",
            "  inflating: Persons-1000/collection/271/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/271/text.txt  \n",
            "   creating: Persons-1000/collection/272/\n",
            "  inflating: Persons-1000/collection/272/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/272/text.txt  \n",
            "   creating: Persons-1000/collection/273/\n",
            "  inflating: Persons-1000/collection/273/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/273/text.txt  \n",
            "   creating: Persons-1000/collection/274/\n",
            "  inflating: Persons-1000/collection/274/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/274/text.txt  \n",
            "   creating: Persons-1000/collection/275/\n",
            "  inflating: Persons-1000/collection/275/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/275/text.txt  \n",
            "   creating: Persons-1000/collection/276/\n",
            "  inflating: Persons-1000/collection/276/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/276/text.txt  \n",
            "   creating: Persons-1000/collection/277/\n",
            "  inflating: Persons-1000/collection/277/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/277/text.txt  \n",
            "   creating: Persons-1000/collection/278/\n",
            "  inflating: Persons-1000/collection/278/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/278/text.txt  \n",
            "   creating: Persons-1000/collection/279/\n",
            "  inflating: Persons-1000/collection/279/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/279/text.txt  \n",
            "   creating: Persons-1000/collection/27_11_12a/\n",
            "  inflating: Persons-1000/collection/27_11_12a/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/27_11_12a/text.txt  \n",
            "   creating: Persons-1000/collection/27_11_12c/\n",
            "  inflating: Persons-1000/collection/27_11_12c/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/27_11_12c/text.txt  \n",
            "   creating: Persons-1000/collection/27_11_12d/\n",
            "  inflating: Persons-1000/collection/27_11_12d/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/27_11_12d/text.txt  \n",
            "   creating: Persons-1000/collection/27_11_12e/\n",
            "  inflating: Persons-1000/collection/27_11_12e/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/27_11_12e/text.txt  \n",
            "   creating: Persons-1000/collection/27_11_12j/\n",
            "  inflating: Persons-1000/collection/27_11_12j/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/27_11_12j/text.txt  \n",
            "   creating: Persons-1000/collection/280/\n",
            "  inflating: Persons-1000/collection/280/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/280/text.txt  \n",
            "   creating: Persons-1000/collection/281/\n",
            "  inflating: Persons-1000/collection/281/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/281/text.txt  \n",
            "   creating: Persons-1000/collection/282/\n",
            "  inflating: Persons-1000/collection/282/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/282/text.txt  \n",
            "   creating: Persons-1000/collection/283/\n",
            "  inflating: Persons-1000/collection/283/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/283/text.txt  \n",
            "   creating: Persons-1000/collection/284/\n",
            "  inflating: Persons-1000/collection/284/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/284/text.txt  \n",
            "   creating: Persons-1000/collection/285/\n",
            "  inflating: Persons-1000/collection/285/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/285/text.txt  \n",
            "   creating: Persons-1000/collection/286/\n",
            "  inflating: Persons-1000/collection/286/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/286/text.txt  \n",
            "   creating: Persons-1000/collection/287/\n",
            "  inflating: Persons-1000/collection/287/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/287/text.txt  \n",
            "   creating: Persons-1000/collection/288/\n",
            "  inflating: Persons-1000/collection/288/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/288/text.txt  \n",
            "   creating: Persons-1000/collection/289/\n",
            "  inflating: Persons-1000/collection/289/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/289/text.txt  \n",
            "   creating: Persons-1000/collection/28_11_12a/\n",
            "  inflating: Persons-1000/collection/28_11_12a/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/28_11_12a/text.txt  \n",
            "   creating: Persons-1000/collection/28_11_12f/\n",
            "  inflating: Persons-1000/collection/28_11_12f/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/28_11_12f/text.txt  \n",
            "   creating: Persons-1000/collection/28_11_12g/\n",
            "  inflating: Persons-1000/collection/28_11_12g/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/28_11_12g/text.txt  \n",
            "   creating: Persons-1000/collection/28_11_12h/\n",
            "  inflating: Persons-1000/collection/28_11_12h/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/28_11_12h/text.txt  \n",
            "   creating: Persons-1000/collection/28_11_12i/\n",
            "  inflating: Persons-1000/collection/28_11_12i/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/28_11_12i/text.txt  \n",
            "   creating: Persons-1000/collection/28_11_12j/\n",
            "  inflating: Persons-1000/collection/28_11_12j/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/28_11_12j/text.txt  \n",
            "   creating: Persons-1000/collection/290/\n",
            "  inflating: Persons-1000/collection/290/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/290/text.txt  \n",
            "   creating: Persons-1000/collection/291/\n",
            "  inflating: Persons-1000/collection/291/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/291/text.txt  \n",
            "   creating: Persons-1000/collection/292/\n",
            "  inflating: Persons-1000/collection/292/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/292/text.txt  \n",
            "   creating: Persons-1000/collection/293/\n",
            "  inflating: Persons-1000/collection/293/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/293/text.txt  \n",
            "   creating: Persons-1000/collection/294/\n",
            "  inflating: Persons-1000/collection/294/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/294/text.txt  \n",
            "   creating: Persons-1000/collection/295/\n",
            "  inflating: Persons-1000/collection/295/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/295/text.txt  \n",
            "   creating: Persons-1000/collection/296/\n",
            "  inflating: Persons-1000/collection/296/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/296/text.txt  \n",
            "   creating: Persons-1000/collection/297/\n",
            "  inflating: Persons-1000/collection/297/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/297/text.txt  \n",
            "   creating: Persons-1000/collection/298/\n",
            "  inflating: Persons-1000/collection/298/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/298/text.txt  \n",
            "   creating: Persons-1000/collection/299/\n",
            "  inflating: Persons-1000/collection/299/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/299/text.txt  \n",
            "   creating: Persons-1000/collection/29_11_12a/\n",
            "  inflating: Persons-1000/collection/29_11_12a/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/29_11_12a/text.txt  \n",
            "   creating: Persons-1000/collection/29_11_12b/\n",
            "  inflating: Persons-1000/collection/29_11_12b/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/29_11_12b/text.txt  \n",
            "   creating: Persons-1000/collection/300/\n",
            "  inflating: Persons-1000/collection/300/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/300/text.txt  \n",
            "   creating: Persons-1000/collection/301/\n",
            "  inflating: Persons-1000/collection/301/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/301/text.txt  \n",
            "   creating: Persons-1000/collection/302/\n",
            "  inflating: Persons-1000/collection/302/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/302/text.txt  \n",
            "   creating: Persons-1000/collection/303/\n",
            "  inflating: Persons-1000/collection/303/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/303/text.txt  \n",
            "   creating: Persons-1000/collection/304/\n",
            "  inflating: Persons-1000/collection/304/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/304/text.txt  \n",
            "   creating: Persons-1000/collection/305/\n",
            "  inflating: Persons-1000/collection/305/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/305/text.txt  \n",
            "   creating: Persons-1000/collection/306/\n",
            "  inflating: Persons-1000/collection/306/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/306/text.txt  \n",
            "   creating: Persons-1000/collection/307/\n",
            "  inflating: Persons-1000/collection/307/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/307/text.txt  \n",
            "   creating: Persons-1000/collection/308/\n",
            "  inflating: Persons-1000/collection/308/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/308/text.txt  \n",
            "   creating: Persons-1000/collection/309/\n",
            "  inflating: Persons-1000/collection/309/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/309/text.txt  \n",
            "   creating: Persons-1000/collection/30_11_12b/\n",
            "  inflating: Persons-1000/collection/30_11_12b/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/30_11_12b/text.txt  \n",
            "   creating: Persons-1000/collection/30_11_12h/\n",
            "  inflating: Persons-1000/collection/30_11_12h/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/30_11_12h/text.txt  \n",
            "   creating: Persons-1000/collection/30_11_12i/\n",
            "  inflating: Persons-1000/collection/30_11_12i/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/30_11_12i/text.txt  \n",
            "   creating: Persons-1000/collection/310/\n",
            "  inflating: Persons-1000/collection/310/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/310/text.txt  \n",
            "   creating: Persons-1000/collection/311/\n",
            "  inflating: Persons-1000/collection/311/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/311/text.txt  \n",
            "   creating: Persons-1000/collection/312/\n",
            "  inflating: Persons-1000/collection/312/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/312/text.txt  \n",
            "   creating: Persons-1000/collection/313/\n",
            "  inflating: Persons-1000/collection/313/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/313/text.txt  \n",
            "   creating: Persons-1000/collection/314/\n",
            "  inflating: Persons-1000/collection/314/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/314/text.txt  \n",
            "   creating: Persons-1000/collection/315/\n",
            "  inflating: Persons-1000/collection/315/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/315/text.txt  \n",
            "   creating: Persons-1000/collection/316/\n",
            "  inflating: Persons-1000/collection/316/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/316/text.txt  \n",
            "   creating: Persons-1000/collection/317/\n",
            "  inflating: Persons-1000/collection/317/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/317/text.txt  \n",
            "   creating: Persons-1000/collection/318/\n",
            "  inflating: Persons-1000/collection/318/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/318/text.txt  \n",
            "   creating: Persons-1000/collection/319/\n",
            "  inflating: Persons-1000/collection/319/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/319/text.txt  \n",
            "   creating: Persons-1000/collection/320/\n",
            "  inflating: Persons-1000/collection/320/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/320/text.txt  \n",
            "   creating: Persons-1000/collection/321/\n",
            "  inflating: Persons-1000/collection/321/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/321/text.txt  \n",
            "   creating: Persons-1000/collection/322/\n",
            "  inflating: Persons-1000/collection/322/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/322/text.txt  \n",
            "   creating: Persons-1000/collection/323/\n",
            "  inflating: Persons-1000/collection/323/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/323/text.txt  \n",
            "   creating: Persons-1000/collection/324/\n",
            "  inflating: Persons-1000/collection/324/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/324/text.txt  \n",
            "   creating: Persons-1000/collection/325/\n",
            "  inflating: Persons-1000/collection/325/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/325/text.txt  \n",
            "   creating: Persons-1000/collection/326/\n",
            "  inflating: Persons-1000/collection/326/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/326/text.txt  \n",
            "   creating: Persons-1000/collection/327/\n",
            "  inflating: Persons-1000/collection/327/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/327/text.txt  \n",
            "   creating: Persons-1000/collection/328/\n",
            "  inflating: Persons-1000/collection/328/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/328/text.txt  \n",
            "   creating: Persons-1000/collection/329/\n",
            "  inflating: Persons-1000/collection/329/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/329/text.txt  \n",
            "   creating: Persons-1000/collection/330/\n",
            "  inflating: Persons-1000/collection/330/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/330/text.txt  \n",
            "   creating: Persons-1000/collection/331/\n",
            "  inflating: Persons-1000/collection/331/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/331/text.txt  \n",
            "   creating: Persons-1000/collection/332/\n",
            "  inflating: Persons-1000/collection/332/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/332/text.txt  \n",
            "   creating: Persons-1000/collection/333/\n",
            "  inflating: Persons-1000/collection/333/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/333/text.txt  \n",
            "   creating: Persons-1000/collection/334/\n",
            "  inflating: Persons-1000/collection/334/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/334/text.txt  \n",
            "   creating: Persons-1000/collection/335/\n",
            "  inflating: Persons-1000/collection/335/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/335/text.txt  \n",
            "   creating: Persons-1000/collection/336/\n",
            "  inflating: Persons-1000/collection/336/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/336/text.txt  \n",
            "   creating: Persons-1000/collection/337/\n",
            "  inflating: Persons-1000/collection/337/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/337/text.txt  \n",
            "   creating: Persons-1000/collection/338/\n",
            "  inflating: Persons-1000/collection/338/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/338/text.txt  \n",
            "   creating: Persons-1000/collection/339/\n",
            "  inflating: Persons-1000/collection/339/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/339/text.txt  \n",
            "   creating: Persons-1000/collection/340/\n",
            "  inflating: Persons-1000/collection/340/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/340/text.txt  \n",
            "   creating: Persons-1000/collection/341/\n",
            "  inflating: Persons-1000/collection/341/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/341/text.txt  \n",
            "   creating: Persons-1000/collection/342/\n",
            "  inflating: Persons-1000/collection/342/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/342/text.txt  \n",
            "   creating: Persons-1000/collection/343/\n",
            "  inflating: Persons-1000/collection/343/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/343/text.txt  \n",
            "   creating: Persons-1000/collection/344/\n",
            "  inflating: Persons-1000/collection/344/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/344/text.txt  \n",
            "   creating: Persons-1000/collection/345/\n",
            "  inflating: Persons-1000/collection/345/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/345/text.txt  \n",
            "   creating: Persons-1000/collection/346/\n",
            "  inflating: Persons-1000/collection/346/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/346/text.txt  \n",
            "   creating: Persons-1000/collection/347/\n",
            "  inflating: Persons-1000/collection/347/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/347/text.txt  \n",
            "   creating: Persons-1000/collection/348/\n",
            "  inflating: Persons-1000/collection/348/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/348/text.txt  \n",
            "   creating: Persons-1000/collection/349/\n",
            "  inflating: Persons-1000/collection/349/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/349/text.txt  \n",
            "   creating: Persons-1000/collection/350/\n",
            "  inflating: Persons-1000/collection/350/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/350/text.txt  \n",
            "   creating: Persons-1000/collection/351/\n",
            "  inflating: Persons-1000/collection/351/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/351/text.txt  \n",
            "   creating: Persons-1000/collection/352/\n",
            "  inflating: Persons-1000/collection/352/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/352/text.txt  \n",
            "   creating: Persons-1000/collection/353/\n",
            "  inflating: Persons-1000/collection/353/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/353/text.txt  \n",
            "   creating: Persons-1000/collection/354/\n",
            "  inflating: Persons-1000/collection/354/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/354/text.txt  \n",
            "   creating: Persons-1000/collection/355/\n",
            "  inflating: Persons-1000/collection/355/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/355/text.txt  \n",
            "   creating: Persons-1000/collection/356/\n",
            "  inflating: Persons-1000/collection/356/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/356/text.txt  \n",
            "   creating: Persons-1000/collection/357/\n",
            "  inflating: Persons-1000/collection/357/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/357/text.txt  \n",
            "   creating: Persons-1000/collection/358/\n",
            "  inflating: Persons-1000/collection/358/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/358/text.txt  \n",
            "   creating: Persons-1000/collection/359/\n",
            "  inflating: Persons-1000/collection/359/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/359/text.txt  \n",
            "   creating: Persons-1000/collection/360/\n",
            "  inflating: Persons-1000/collection/360/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/360/text.txt  \n",
            "   creating: Persons-1000/collection/361/\n",
            "  inflating: Persons-1000/collection/361/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/361/text.txt  \n",
            "   creating: Persons-1000/collection/362/\n",
            "  inflating: Persons-1000/collection/362/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/362/text.txt  \n",
            "   creating: Persons-1000/collection/363/\n",
            "  inflating: Persons-1000/collection/363/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/363/text.txt  \n",
            "   creating: Persons-1000/collection/364/\n",
            "  inflating: Persons-1000/collection/364/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/364/text.txt  \n",
            "   creating: Persons-1000/collection/365/\n",
            "  inflating: Persons-1000/collection/365/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/365/text.txt  \n",
            "   creating: Persons-1000/collection/366/\n",
            "  inflating: Persons-1000/collection/366/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/366/text.txt  \n",
            "   creating: Persons-1000/collection/367/\n",
            "  inflating: Persons-1000/collection/367/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/367/text.txt  \n",
            "   creating: Persons-1000/collection/368/\n",
            "  inflating: Persons-1000/collection/368/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/368/text.txt  \n",
            "   creating: Persons-1000/collection/369/\n",
            "  inflating: Persons-1000/collection/369/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/369/text.txt  \n",
            "   creating: Persons-1000/collection/370/\n",
            "  inflating: Persons-1000/collection/370/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/370/text.txt  \n",
            "   creating: Persons-1000/collection/371/\n",
            "  inflating: Persons-1000/collection/371/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/371/text.txt  \n",
            "   creating: Persons-1000/collection/372/\n",
            "  inflating: Persons-1000/collection/372/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/372/text.txt  \n",
            "   creating: Persons-1000/collection/373/\n",
            "  inflating: Persons-1000/collection/373/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/373/text.txt  \n",
            "   creating: Persons-1000/collection/374/\n",
            "  inflating: Persons-1000/collection/374/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/374/text.txt  \n",
            "   creating: Persons-1000/collection/375/\n",
            "  inflating: Persons-1000/collection/375/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/375/text.txt  \n",
            "   creating: Persons-1000/collection/376/\n",
            "  inflating: Persons-1000/collection/376/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/376/text.txt  \n",
            "   creating: Persons-1000/collection/377/\n",
            "  inflating: Persons-1000/collection/377/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/377/text.txt  \n",
            "   creating: Persons-1000/collection/378/\n",
            "  inflating: Persons-1000/collection/378/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/378/text.txt  \n",
            "   creating: Persons-1000/collection/379/\n",
            "  inflating: Persons-1000/collection/379/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/379/text.txt  \n",
            "   creating: Persons-1000/collection/380/\n",
            "  inflating: Persons-1000/collection/380/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/380/text.txt  \n",
            "   creating: Persons-1000/collection/381/\n",
            "  inflating: Persons-1000/collection/381/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/381/text.txt  \n",
            "   creating: Persons-1000/collection/382/\n",
            "  inflating: Persons-1000/collection/382/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/382/text.txt  \n",
            "   creating: Persons-1000/collection/383/\n",
            "  inflating: Persons-1000/collection/383/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/383/text.txt  \n",
            "   creating: Persons-1000/collection/384/\n",
            "  inflating: Persons-1000/collection/384/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/384/text.txt  \n",
            "   creating: Persons-1000/collection/385/\n",
            "  inflating: Persons-1000/collection/385/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/385/text.txt  \n",
            "   creating: Persons-1000/collection/386/\n",
            "  inflating: Persons-1000/collection/386/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/386/text.txt  \n",
            "   creating: Persons-1000/collection/387/\n",
            "  inflating: Persons-1000/collection/387/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/387/text.txt  \n",
            "   creating: Persons-1000/collection/388/\n",
            "  inflating: Persons-1000/collection/388/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/388/text.txt  \n",
            "   creating: Persons-1000/collection/389/\n",
            "  inflating: Persons-1000/collection/389/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/389/text.txt  \n",
            "   creating: Persons-1000/collection/390/\n",
            " extracting: Persons-1000/collection/390/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/390/text.txt  \n",
            "   creating: Persons-1000/collection/391/\n",
            " extracting: Persons-1000/collection/391/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/391/text.txt  \n",
            "   creating: Persons-1000/collection/392/\n",
            "  inflating: Persons-1000/collection/392/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/392/text.txt  \n",
            "   creating: Persons-1000/collection/393/\n",
            "  inflating: Persons-1000/collection/393/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/393/text.txt  \n",
            "   creating: Persons-1000/collection/394/\n",
            "  inflating: Persons-1000/collection/394/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/394/text.txt  \n",
            "   creating: Persons-1000/collection/395/\n",
            "  inflating: Persons-1000/collection/395/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/395/text.txt  \n",
            "   creating: Persons-1000/collection/396/\n",
            "  inflating: Persons-1000/collection/396/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/396/text.txt  \n",
            "   creating: Persons-1000/collection/397/\n",
            "  inflating: Persons-1000/collection/397/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/397/text.txt  \n",
            "   creating: Persons-1000/collection/398/\n",
            "  inflating: Persons-1000/collection/398/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/398/text.txt  \n",
            "   creating: Persons-1000/collection/399/\n",
            "  inflating: Persons-1000/collection/399/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/399/text.txt  \n",
            "   creating: Persons-1000/collection/400/\n",
            "  inflating: Persons-1000/collection/400/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/400/text.txt  \n",
            "   creating: Persons-1000/collection/401/\n",
            "  inflating: Persons-1000/collection/401/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/401/text.txt  \n",
            "   creating: Persons-1000/collection/402/\n",
            "  inflating: Persons-1000/collection/402/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/402/text.txt  \n",
            "   creating: Persons-1000/collection/403/\n",
            "  inflating: Persons-1000/collection/403/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/403/text.txt  \n",
            "   creating: Persons-1000/collection/404/\n",
            "  inflating: Persons-1000/collection/404/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/404/text.txt  \n",
            "   creating: Persons-1000/collection/405/\n",
            "  inflating: Persons-1000/collection/405/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/405/text.txt  \n",
            "   creating: Persons-1000/collection/406/\n",
            "  inflating: Persons-1000/collection/406/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/406/text.txt  \n",
            "   creating: Persons-1000/collection/407/\n",
            "  inflating: Persons-1000/collection/407/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/407/text.txt  \n",
            "   creating: Persons-1000/collection/408/\n",
            "  inflating: Persons-1000/collection/408/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/408/text.txt  \n",
            "   creating: Persons-1000/collection/409/\n",
            "  inflating: Persons-1000/collection/409/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/409/text.txt  \n",
            "   creating: Persons-1000/collection/410/\n",
            "  inflating: Persons-1000/collection/410/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/410/text.txt  \n",
            "   creating: Persons-1000/collection/411/\n",
            "  inflating: Persons-1000/collection/411/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/411/text.txt  \n",
            "   creating: Persons-1000/collection/412/\n",
            "  inflating: Persons-1000/collection/412/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/412/text.txt  \n",
            "   creating: Persons-1000/collection/413/\n",
            "  inflating: Persons-1000/collection/413/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/413/text.txt  \n",
            "   creating: Persons-1000/collection/414/\n",
            "  inflating: Persons-1000/collection/414/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/414/text.txt  \n",
            "   creating: Persons-1000/collection/415/\n",
            "  inflating: Persons-1000/collection/415/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/415/text.txt  \n",
            "   creating: Persons-1000/collection/416/\n",
            "  inflating: Persons-1000/collection/416/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/416/text.txt  \n",
            "   creating: Persons-1000/collection/417/\n",
            "  inflating: Persons-1000/collection/417/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/417/text.txt  \n",
            "   creating: Persons-1000/collection/418/\n",
            "  inflating: Persons-1000/collection/418/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/418/text.txt  \n",
            "   creating: Persons-1000/collection/419/\n",
            "  inflating: Persons-1000/collection/419/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/419/text.txt  \n",
            "   creating: Persons-1000/collection/420/\n",
            "  inflating: Persons-1000/collection/420/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/420/text.txt  \n",
            "   creating: Persons-1000/collection/421/\n",
            "  inflating: Persons-1000/collection/421/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/421/text.txt  \n",
            "   creating: Persons-1000/collection/422/\n",
            "  inflating: Persons-1000/collection/422/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/422/text.txt  \n",
            "   creating: Persons-1000/collection/423/\n",
            "  inflating: Persons-1000/collection/423/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/423/text.txt  \n",
            "   creating: Persons-1000/collection/424/\n",
            "  inflating: Persons-1000/collection/424/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/424/text.txt  \n",
            "   creating: Persons-1000/collection/425/\n",
            "  inflating: Persons-1000/collection/425/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/425/text.txt  \n",
            "   creating: Persons-1000/collection/426/\n",
            "  inflating: Persons-1000/collection/426/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/426/text.txt  \n",
            "   creating: Persons-1000/collection/427/\n",
            "  inflating: Persons-1000/collection/427/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/427/text.txt  \n",
            "   creating: Persons-1000/collection/428/\n",
            "  inflating: Persons-1000/collection/428/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/428/text.txt  \n",
            "   creating: Persons-1000/collection/429/\n",
            "  inflating: Persons-1000/collection/429/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/429/text.txt  \n",
            "   creating: Persons-1000/collection/430/\n",
            "  inflating: Persons-1000/collection/430/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/430/text.txt  \n",
            "   creating: Persons-1000/collection/431/\n",
            "  inflating: Persons-1000/collection/431/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/431/text.txt  \n",
            "   creating: Persons-1000/collection/432/\n",
            "  inflating: Persons-1000/collection/432/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/432/text.txt  \n",
            "   creating: Persons-1000/collection/433/\n",
            "  inflating: Persons-1000/collection/433/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/433/text.txt  \n",
            "   creating: Persons-1000/collection/434/\n",
            "  inflating: Persons-1000/collection/434/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/434/text.txt  \n",
            "   creating: Persons-1000/collection/435/\n",
            "  inflating: Persons-1000/collection/435/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/435/text.txt  \n",
            "   creating: Persons-1000/collection/436/\n",
            "  inflating: Persons-1000/collection/436/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/436/text.txt  \n",
            "   creating: Persons-1000/collection/437/\n",
            "  inflating: Persons-1000/collection/437/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/437/text.txt  \n",
            "   creating: Persons-1000/collection/438/\n",
            "  inflating: Persons-1000/collection/438/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/438/text.txt  \n",
            "   creating: Persons-1000/collection/439/\n",
            "  inflating: Persons-1000/collection/439/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/439/text.txt  \n",
            "   creating: Persons-1000/collection/440/\n",
            "  inflating: Persons-1000/collection/440/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/440/text.txt  \n",
            "   creating: Persons-1000/collection/441/\n",
            "  inflating: Persons-1000/collection/441/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/441/text.txt  \n",
            "   creating: Persons-1000/collection/442/\n",
            "  inflating: Persons-1000/collection/442/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/442/text.txt  \n",
            "   creating: Persons-1000/collection/443/\n",
            "  inflating: Persons-1000/collection/443/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/443/text.txt  \n",
            "   creating: Persons-1000/collection/444/\n",
            "  inflating: Persons-1000/collection/444/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/444/text.txt  \n",
            "   creating: Persons-1000/collection/445/\n",
            "  inflating: Persons-1000/collection/445/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/445/text.txt  \n",
            "   creating: Persons-1000/collection/446/\n",
            "  inflating: Persons-1000/collection/446/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/446/text.txt  \n",
            "   creating: Persons-1000/collection/447/\n",
            "  inflating: Persons-1000/collection/447/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/447/text.txt  \n",
            "   creating: Persons-1000/collection/448/\n",
            "  inflating: Persons-1000/collection/448/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/448/text.txt  \n",
            "   creating: Persons-1000/collection/449/\n",
            "  inflating: Persons-1000/collection/449/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/449/text.txt  \n",
            "   creating: Persons-1000/collection/450/\n",
            "  inflating: Persons-1000/collection/450/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/450/text.txt  \n",
            "   creating: Persons-1000/collection/451/\n",
            "  inflating: Persons-1000/collection/451/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/451/text.txt  \n",
            "   creating: Persons-1000/collection/452/\n",
            "  inflating: Persons-1000/collection/452/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/452/text.txt  \n",
            "   creating: Persons-1000/collection/453/\n",
            "  inflating: Persons-1000/collection/453/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/453/text.txt  \n",
            "   creating: Persons-1000/collection/454/\n",
            "  inflating: Persons-1000/collection/454/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/454/text.txt  \n",
            "   creating: Persons-1000/collection/455/\n",
            "  inflating: Persons-1000/collection/455/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/455/text.txt  \n",
            "   creating: Persons-1000/collection/457/\n",
            "  inflating: Persons-1000/collection/457/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/457/text.txt  \n",
            "   creating: Persons-1000/collection/458/\n",
            "  inflating: Persons-1000/collection/458/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/458/text.txt  \n",
            "   creating: Persons-1000/collection/459/\n",
            "  inflating: Persons-1000/collection/459/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/459/text.txt  \n",
            "   creating: Persons-1000/collection/460/\n",
            "  inflating: Persons-1000/collection/460/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/460/text.txt  \n",
            "   creating: Persons-1000/collection/461/\n",
            "  inflating: Persons-1000/collection/461/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/461/text.txt  \n",
            "   creating: Persons-1000/collection/462/\n",
            "  inflating: Persons-1000/collection/462/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/462/text.txt  \n",
            "   creating: Persons-1000/collection/463/\n",
            "  inflating: Persons-1000/collection/463/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/463/text.txt  \n",
            "   creating: Persons-1000/collection/464/\n",
            "  inflating: Persons-1000/collection/464/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/464/text.txt  \n",
            "   creating: Persons-1000/collection/465/\n",
            "  inflating: Persons-1000/collection/465/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/465/text.txt  \n",
            "   creating: Persons-1000/collection/466/\n",
            "  inflating: Persons-1000/collection/466/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/466/text.txt  \n",
            "   creating: Persons-1000/collection/467/\n",
            "  inflating: Persons-1000/collection/467/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/467/text.txt  \n",
            "   creating: Persons-1000/collection/468/\n",
            "  inflating: Persons-1000/collection/468/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/468/text.txt  \n",
            "   creating: Persons-1000/collection/469/\n",
            "  inflating: Persons-1000/collection/469/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/469/text.txt  \n",
            "   creating: Persons-1000/collection/470/\n",
            "  inflating: Persons-1000/collection/470/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/470/text.txt  \n",
            "   creating: Persons-1000/collection/471/\n",
            "  inflating: Persons-1000/collection/471/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/471/text.txt  \n",
            "   creating: Persons-1000/collection/472/\n",
            "  inflating: Persons-1000/collection/472/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/472/text.txt  \n",
            "   creating: Persons-1000/collection/473/\n",
            "  inflating: Persons-1000/collection/473/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/473/text.txt  \n",
            "   creating: Persons-1000/collection/474/\n",
            "  inflating: Persons-1000/collection/474/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/474/text.txt  \n",
            "   creating: Persons-1000/collection/475/\n",
            "  inflating: Persons-1000/collection/475/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/475/text.txt  \n",
            "   creating: Persons-1000/collection/476/\n",
            "  inflating: Persons-1000/collection/476/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/476/text.txt  \n",
            "   creating: Persons-1000/collection/477/\n",
            "  inflating: Persons-1000/collection/477/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/477/text.txt  \n",
            "   creating: Persons-1000/collection/478/\n",
            "  inflating: Persons-1000/collection/478/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/478/text.txt  \n",
            "   creating: Persons-1000/collection/479/\n",
            "  inflating: Persons-1000/collection/479/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/479/text.txt  \n",
            "   creating: Persons-1000/collection/480/\n",
            "  inflating: Persons-1000/collection/480/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/480/text.txt  \n",
            "   creating: Persons-1000/collection/481/\n",
            "  inflating: Persons-1000/collection/481/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/481/text.txt  \n",
            "   creating: Persons-1000/collection/482/\n",
            "  inflating: Persons-1000/collection/482/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/482/text.txt  \n",
            "   creating: Persons-1000/collection/483/\n",
            "  inflating: Persons-1000/collection/483/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/483/text.txt  \n",
            "   creating: Persons-1000/collection/484/\n",
            "  inflating: Persons-1000/collection/484/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/484/text.txt  \n",
            "   creating: Persons-1000/collection/485/\n",
            "  inflating: Persons-1000/collection/485/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/485/text.txt  \n",
            "   creating: Persons-1000/collection/486/\n",
            "  inflating: Persons-1000/collection/486/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/486/text.txt  \n",
            "   creating: Persons-1000/collection/487/\n",
            "  inflating: Persons-1000/collection/487/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/487/text.txt  \n",
            "   creating: Persons-1000/collection/488/\n",
            "  inflating: Persons-1000/collection/488/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/488/text.txt  \n",
            "   creating: Persons-1000/collection/489/\n",
            "  inflating: Persons-1000/collection/489/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/489/text.txt  \n",
            "   creating: Persons-1000/collection/490/\n",
            "  inflating: Persons-1000/collection/490/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/490/text.txt  \n",
            "   creating: Persons-1000/collection/491/\n",
            "  inflating: Persons-1000/collection/491/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/491/text.txt  \n",
            "   creating: Persons-1000/collection/492/\n",
            "  inflating: Persons-1000/collection/492/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/492/text.txt  \n",
            "   creating: Persons-1000/collection/493/\n",
            "  inflating: Persons-1000/collection/493/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/493/text.txt  \n",
            "   creating: Persons-1000/collection/494/\n",
            "  inflating: Persons-1000/collection/494/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/494/text.txt  \n",
            "   creating: Persons-1000/collection/495/\n",
            "  inflating: Persons-1000/collection/495/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/495/text.txt  \n",
            "   creating: Persons-1000/collection/496/\n",
            "  inflating: Persons-1000/collection/496/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/496/text.txt  \n",
            "   creating: Persons-1000/collection/497/\n",
            "  inflating: Persons-1000/collection/497/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/497/text.txt  \n",
            "   creating: Persons-1000/collection/498/\n",
            "  inflating: Persons-1000/collection/498/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/498/text.txt  \n",
            "   creating: Persons-1000/collection/499/\n",
            "  inflating: Persons-1000/collection/499/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/499/text.txt  \n",
            "   creating: Persons-1000/collection/500/\n",
            "  inflating: Persons-1000/collection/500/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/500/text.txt  \n",
            "   creating: Persons-1000/collection/501/\n",
            "  inflating: Persons-1000/collection/501/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/501/text.txt  \n",
            "   creating: Persons-1000/collection/502/\n",
            "  inflating: Persons-1000/collection/502/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/502/text.txt  \n",
            "   creating: Persons-1000/collection/503/\n",
            "  inflating: Persons-1000/collection/503/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/503/text.txt  \n",
            "   creating: Persons-1000/collection/504/\n",
            "  inflating: Persons-1000/collection/504/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/504/text.txt  \n",
            "   creating: Persons-1000/collection/505/\n",
            "  inflating: Persons-1000/collection/505/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/505/text.txt  \n",
            "   creating: Persons-1000/collection/506/\n",
            "  inflating: Persons-1000/collection/506/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/506/text.txt  \n",
            "   creating: Persons-1000/collection/507/\n",
            "  inflating: Persons-1000/collection/507/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/507/text.txt  \n",
            "   creating: Persons-1000/collection/508/\n",
            "  inflating: Persons-1000/collection/508/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/508/text.txt  \n",
            "   creating: Persons-1000/collection/509/\n",
            "  inflating: Persons-1000/collection/509/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/509/text.txt  \n",
            "   creating: Persons-1000/collection/510/\n",
            "  inflating: Persons-1000/collection/510/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/510/text.txt  \n",
            "   creating: Persons-1000/collection/511/\n",
            "  inflating: Persons-1000/collection/511/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/511/text.txt  \n",
            "   creating: Persons-1000/collection/512/\n",
            "  inflating: Persons-1000/collection/512/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/512/text.txt  \n",
            "   creating: Persons-1000/collection/513/\n",
            "  inflating: Persons-1000/collection/513/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/513/text.txt  \n",
            "   creating: Persons-1000/collection/514/\n",
            "  inflating: Persons-1000/collection/514/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/514/text.txt  \n",
            "   creating: Persons-1000/collection/515/\n",
            "  inflating: Persons-1000/collection/515/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/515/text.txt  \n",
            "   creating: Persons-1000/collection/516/\n",
            "  inflating: Persons-1000/collection/516/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/516/text.txt  \n",
            "   creating: Persons-1000/collection/517/\n",
            "  inflating: Persons-1000/collection/517/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/517/text.txt  \n",
            "   creating: Persons-1000/collection/518/\n",
            "  inflating: Persons-1000/collection/518/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/518/text.txt  \n",
            "   creating: Persons-1000/collection/519/\n",
            "  inflating: Persons-1000/collection/519/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/519/text.txt  \n",
            "   creating: Persons-1000/collection/520/\n",
            "  inflating: Persons-1000/collection/520/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/520/text.txt  \n",
            "   creating: Persons-1000/collection/521/\n",
            "  inflating: Persons-1000/collection/521/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/521/text.txt  \n",
            "   creating: Persons-1000/collection/522/\n",
            "  inflating: Persons-1000/collection/522/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/522/text.txt  \n",
            "   creating: Persons-1000/collection/523/\n",
            "  inflating: Persons-1000/collection/523/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/523/text.txt  \n",
            "   creating: Persons-1000/collection/524/\n",
            "  inflating: Persons-1000/collection/524/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/524/text.txt  \n",
            "   creating: Persons-1000/collection/525/\n",
            "  inflating: Persons-1000/collection/525/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/525/text.txt  \n",
            "   creating: Persons-1000/collection/526/\n",
            "  inflating: Persons-1000/collection/526/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/526/text.txt  \n",
            "   creating: Persons-1000/collection/527/\n",
            "  inflating: Persons-1000/collection/527/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/527/text.txt  \n",
            "   creating: Persons-1000/collection/528/\n",
            "  inflating: Persons-1000/collection/528/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/528/text.txt  \n",
            "   creating: Persons-1000/collection/529/\n",
            "  inflating: Persons-1000/collection/529/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/529/text.txt  \n",
            "   creating: Persons-1000/collection/530/\n",
            "  inflating: Persons-1000/collection/530/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/530/text.txt  \n",
            "   creating: Persons-1000/collection/531/\n",
            "  inflating: Persons-1000/collection/531/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/531/text.txt  \n",
            "   creating: Persons-1000/collection/532/\n",
            "  inflating: Persons-1000/collection/532/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/532/text.txt  \n",
            "   creating: Persons-1000/collection/533 (!)/\n",
            "  inflating: Persons-1000/collection/533 (!)/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/533 (!)/text.txt  \n",
            "   creating: Persons-1000/collection/534/\n",
            "  inflating: Persons-1000/collection/534/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/534/text.txt  \n",
            "   creating: Persons-1000/collection/535/\n",
            "  inflating: Persons-1000/collection/535/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/535/text.txt  \n",
            "   creating: Persons-1000/collection/536/\n",
            "  inflating: Persons-1000/collection/536/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/536/text.txt  \n",
            "   creating: Persons-1000/collection/537/\n",
            "  inflating: Persons-1000/collection/537/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/537/text.txt  \n",
            "   creating: Persons-1000/collection/538/\n",
            "  inflating: Persons-1000/collection/538/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/538/text.txt  \n",
            "   creating: Persons-1000/collection/539/\n",
            "  inflating: Persons-1000/collection/539/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/539/text.txt  \n",
            "   creating: Persons-1000/collection/540/\n",
            "  inflating: Persons-1000/collection/540/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/540/text.txt  \n",
            "   creating: Persons-1000/collection/541/\n",
            "  inflating: Persons-1000/collection/541/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/541/text.txt  \n",
            "   creating: Persons-1000/collection/542/\n",
            "  inflating: Persons-1000/collection/542/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/542/text.txt  \n",
            "   creating: Persons-1000/collection/543/\n",
            "  inflating: Persons-1000/collection/543/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/543/text.txt  \n",
            "   creating: Persons-1000/collection/544/\n",
            "  inflating: Persons-1000/collection/544/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/544/text.txt  \n",
            "   creating: Persons-1000/collection/545/\n",
            "  inflating: Persons-1000/collection/545/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/545/text.txt  \n",
            "   creating: Persons-1000/collection/546/\n",
            "  inflating: Persons-1000/collection/546/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/546/text.txt  \n",
            "   creating: Persons-1000/collection/547/\n",
            "  inflating: Persons-1000/collection/547/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/547/text.txt  \n",
            "   creating: Persons-1000/collection/548/\n",
            "  inflating: Persons-1000/collection/548/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/548/text.txt  \n",
            "   creating: Persons-1000/collection/549/\n",
            "  inflating: Persons-1000/collection/549/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/549/text.txt  \n",
            "   creating: Persons-1000/collection/550/\n",
            "  inflating: Persons-1000/collection/550/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/550/text.txt  \n",
            "   creating: Persons-1000/collection/551/\n",
            "  inflating: Persons-1000/collection/551/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/551/text.txt  \n",
            "   creating: Persons-1000/collection/552/\n",
            "  inflating: Persons-1000/collection/552/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/552/text.txt  \n",
            "   creating: Persons-1000/collection/553/\n",
            "  inflating: Persons-1000/collection/553/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/553/text.txt  \n",
            "   creating: Persons-1000/collection/554/\n",
            "  inflating: Persons-1000/collection/554/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/554/text.txt  \n",
            "   creating: Persons-1000/collection/555 (!)/\n",
            "  inflating: Persons-1000/collection/555 (!)/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/555 (!)/text.txt  \n",
            "   creating: Persons-1000/collection/556/\n",
            "  inflating: Persons-1000/collection/556/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/556/text.txt  \n",
            "   creating: Persons-1000/collection/557/\n",
            "  inflating: Persons-1000/collection/557/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/557/text.txt  \n",
            "   creating: Persons-1000/collection/558/\n",
            "  inflating: Persons-1000/collection/558/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/558/text.txt  \n",
            "   creating: Persons-1000/collection/559/\n",
            "  inflating: Persons-1000/collection/559/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/559/text.txt  \n",
            "   creating: Persons-1000/collection/560/\n",
            "  inflating: Persons-1000/collection/560/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/560/text.txt  \n",
            "   creating: Persons-1000/collection/561/\n",
            "  inflating: Persons-1000/collection/561/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/561/text.txt  \n",
            "   creating: Persons-1000/collection/562/\n",
            "  inflating: Persons-1000/collection/562/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/562/text.txt  \n",
            "   creating: Persons-1000/collection/563/\n",
            "  inflating: Persons-1000/collection/563/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/563/text.txt  \n",
            "   creating: Persons-1000/collection/564/\n",
            "  inflating: Persons-1000/collection/564/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/564/text.txt  \n",
            "   creating: Persons-1000/collection/565/\n",
            "  inflating: Persons-1000/collection/565/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/565/text.txt  \n",
            "   creating: Persons-1000/collection/567/\n",
            "  inflating: Persons-1000/collection/567/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/567/text.txt  \n",
            "   creating: Persons-1000/collection/568/\n",
            "  inflating: Persons-1000/collection/568/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/568/text.txt  \n",
            "   creating: Persons-1000/collection/569/\n",
            "  inflating: Persons-1000/collection/569/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/569/text.txt  \n",
            "   creating: Persons-1000/collection/570/\n",
            "  inflating: Persons-1000/collection/570/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/570/text.txt  \n",
            "   creating: Persons-1000/collection/571/\n",
            "  inflating: Persons-1000/collection/571/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/571/text.txt  \n",
            "   creating: Persons-1000/collection/572/\n",
            "  inflating: Persons-1000/collection/572/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/572/text.txt  \n",
            "   creating: Persons-1000/collection/574/\n",
            "  inflating: Persons-1000/collection/574/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/574/text.txt  \n",
            "   creating: Persons-1000/collection/575/\n",
            "  inflating: Persons-1000/collection/575/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/575/text.txt  \n",
            "   creating: Persons-1000/collection/576/\n",
            "  inflating: Persons-1000/collection/576/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/576/text.txt  \n",
            "   creating: Persons-1000/collection/577/\n",
            "  inflating: Persons-1000/collection/577/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/577/text.txt  \n",
            "   creating: Persons-1000/collection/578/\n",
            "  inflating: Persons-1000/collection/578/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/578/text.txt  \n",
            "   creating: Persons-1000/collection/579/\n",
            "  inflating: Persons-1000/collection/579/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/579/text.txt  \n",
            "   creating: Persons-1000/collection/581/\n",
            "  inflating: Persons-1000/collection/581/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/581/text.txt  \n",
            "   creating: Persons-1000/collection/582/\n",
            "  inflating: Persons-1000/collection/582/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/582/text.txt  \n",
            "   creating: Persons-1000/collection/583/\n",
            "  inflating: Persons-1000/collection/583/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/583/text.txt  \n",
            "   creating: Persons-1000/collection/584 (!)/\n",
            "  inflating: Persons-1000/collection/584 (!)/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/584 (!)/text.txt  \n",
            "   creating: Persons-1000/collection/585/\n",
            "  inflating: Persons-1000/collection/585/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/585/text.txt  \n",
            "   creating: Persons-1000/collection/586/\n",
            "  inflating: Persons-1000/collection/586/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/586/text.txt  \n",
            "   creating: Persons-1000/collection/587/\n",
            "  inflating: Persons-1000/collection/587/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/587/text.txt  \n",
            "   creating: Persons-1000/collection/588/\n",
            "  inflating: Persons-1000/collection/588/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/588/text.txt  \n",
            "   creating: Persons-1000/collection/589/\n",
            "  inflating: Persons-1000/collection/589/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/589/text.txt  \n",
            "   creating: Persons-1000/collection/590/\n",
            "  inflating: Persons-1000/collection/590/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/590/text.txt  \n",
            "   creating: Persons-1000/collection/591/\n",
            "  inflating: Persons-1000/collection/591/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/591/text.txt  \n",
            "   creating: Persons-1000/collection/592/\n",
            "  inflating: Persons-1000/collection/592/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/592/text.txt  \n",
            "   creating: Persons-1000/collection/593/\n",
            "  inflating: Persons-1000/collection/593/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/593/text.txt  \n",
            "   creating: Persons-1000/collection/594/\n",
            "  inflating: Persons-1000/collection/594/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/594/text.txt  \n",
            "   creating: Persons-1000/collection/595/\n",
            "  inflating: Persons-1000/collection/595/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/595/text.txt  \n",
            "   creating: Persons-1000/collection/596/\n",
            "  inflating: Persons-1000/collection/596/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/596/text.txt  \n",
            "   creating: Persons-1000/collection/597/\n",
            "  inflating: Persons-1000/collection/597/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/597/text.txt  \n",
            "   creating: Persons-1000/collection/598 (!)/\n",
            "  inflating: Persons-1000/collection/598 (!)/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/598 (!)/text.txt  \n",
            "   creating: Persons-1000/collection/599/\n",
            "  inflating: Persons-1000/collection/599/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/599/text.txt  \n",
            "   creating: Persons-1000/collection/600/\n",
            "  inflating: Persons-1000/collection/600/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/600/text.txt  \n",
            "   creating: Persons-1000/collection/601/\n",
            "  inflating: Persons-1000/collection/601/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/601/text.txt  \n",
            "   creating: Persons-1000/collection/602/\n",
            "  inflating: Persons-1000/collection/602/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/602/text.txt  \n",
            "   creating: Persons-1000/collection/610/\n",
            "  inflating: Persons-1000/collection/610/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/610/text.txt  \n",
            "   creating: Persons-1000/collection/611/\n",
            "  inflating: Persons-1000/collection/611/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/611/text.txt  \n",
            "   creating: Persons-1000/collection/612/\n",
            "  inflating: Persons-1000/collection/612/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/612/text.txt  \n",
            "   creating: Persons-1000/collection/613/\n",
            "  inflating: Persons-1000/collection/613/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/613/text.txt  \n",
            "   creating: Persons-1000/collection/614/\n",
            "  inflating: Persons-1000/collection/614/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/614/text.txt  \n",
            "   creating: Persons-1000/collection/615/\n",
            "  inflating: Persons-1000/collection/615/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/615/text.txt  \n",
            "   creating: Persons-1000/collection/616/\n",
            "  inflating: Persons-1000/collection/616/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/616/text.txt  \n",
            "   creating: Persons-1000/collection/617/\n",
            "  inflating: Persons-1000/collection/617/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/617/text.txt  \n",
            "   creating: Persons-1000/collection/618/\n",
            "  inflating: Persons-1000/collection/618/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/618/text.txt  \n",
            "   creating: Persons-1000/collection/619/\n",
            "  inflating: Persons-1000/collection/619/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/619/text.txt  \n",
            "   creating: Persons-1000/collection/620/\n",
            "  inflating: Persons-1000/collection/620/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/620/text.txt  \n",
            "   creating: Persons-1000/collection/621/\n",
            "  inflating: Persons-1000/collection/621/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/621/text.txt  \n",
            "   creating: Persons-1000/collection/622/\n",
            "  inflating: Persons-1000/collection/622/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/622/text.txt  \n",
            "   creating: Persons-1000/collection/623/\n",
            "  inflating: Persons-1000/collection/623/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/623/text.txt  \n",
            "   creating: Persons-1000/collection/624/\n",
            "  inflating: Persons-1000/collection/624/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/624/text.txt  \n",
            "   creating: Persons-1000/collection/625/\n",
            "  inflating: Persons-1000/collection/625/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/625/text.txt  \n",
            "   creating: Persons-1000/collection/626/\n",
            "  inflating: Persons-1000/collection/626/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/626/text.txt  \n",
            "   creating: Persons-1000/collection/627/\n",
            "  inflating: Persons-1000/collection/627/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/627/text.txt  \n",
            "   creating: Persons-1000/collection/628/\n",
            "  inflating: Persons-1000/collection/628/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/628/text.txt  \n",
            "   creating: Persons-1000/collection/629/\n",
            "  inflating: Persons-1000/collection/629/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/629/text.txt  \n",
            "   creating: Persons-1000/collection/630/\n",
            "  inflating: Persons-1000/collection/630/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/630/text.txt  \n",
            "   creating: Persons-1000/collection/631/\n",
            "  inflating: Persons-1000/collection/631/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/631/text.txt  \n",
            "   creating: Persons-1000/collection/632/\n",
            "  inflating: Persons-1000/collection/632/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/632/text.txt  \n",
            "   creating: Persons-1000/collection/633/\n",
            "  inflating: Persons-1000/collection/633/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/633/text.txt  \n",
            "   creating: Persons-1000/collection/abdulatipov/\n",
            "  inflating: Persons-1000/collection/abdulatipov/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/abdulatipov/text.txt  \n",
            "   creating: Persons-1000/collection/artjakov/\n",
            "  inflating: Persons-1000/collection/artjakov/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/artjakov/text.txt  \n",
            "   creating: Persons-1000/collection/Avtovaz/\n",
            "  inflating: Persons-1000/collection/Avtovaz/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/Avtovaz/text.txt  \n",
            "   creating: Persons-1000/collection/blokhin/\n",
            "  inflating: Persons-1000/collection/blokhin/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/blokhin/text.txt  \n",
            "   creating: Persons-1000/collection/chaves/\n",
            "  inflating: Persons-1000/collection/chaves/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/chaves/text.txt  \n",
            "   creating: Persons-1000/collection/chirkunov/\n",
            "  inflating: Persons-1000/collection/chirkunov/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/chirkunov/text.txt  \n",
            "   creating: Persons-1000/collection/kamchatka/\n",
            "  inflating: Persons-1000/collection/kamchatka/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/kamchatka/text.txt  \n",
            "   creating: Persons-1000/collection/klinton/\n",
            "  inflating: Persons-1000/collection/klinton/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/klinton/text.txt  \n",
            "   creating: Persons-1000/collection/kuleshov/\n",
            "  inflating: Persons-1000/collection/kuleshov/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/kuleshov/text.txt  \n",
            "   creating: Persons-1000/collection/last_01/\n",
            "  inflating: Persons-1000/collection/last_01/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_01/text.txt  \n",
            "   creating: Persons-1000/collection/last_02/\n",
            "  inflating: Persons-1000/collection/last_02/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_02/text.txt  \n",
            "   creating: Persons-1000/collection/last_03/\n",
            "  inflating: Persons-1000/collection/last_03/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_03/text.txt  \n",
            "   creating: Persons-1000/collection/last_04/\n",
            "  inflating: Persons-1000/collection/last_04/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_04/text.txt  \n",
            "   creating: Persons-1000/collection/last_05/\n",
            "  inflating: Persons-1000/collection/last_05/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_05/text.txt  \n",
            "   creating: Persons-1000/collection/last_06/\n",
            "  inflating: Persons-1000/collection/last_06/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_06/text.txt  \n",
            "   creating: Persons-1000/collection/last_07_new/\n",
            "  inflating: Persons-1000/collection/last_07_new/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_07_new/text.txt  \n",
            "   creating: Persons-1000/collection/last_08/\n",
            "  inflating: Persons-1000/collection/last_08/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_08/text.txt  \n",
            "   creating: Persons-1000/collection/last_09/\n",
            "  inflating: Persons-1000/collection/last_09/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_09/text.txt  \n",
            "   creating: Persons-1000/collection/last_10/\n",
            "  inflating: Persons-1000/collection/last_10/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_10/text.txt  \n",
            "   creating: Persons-1000/collection/last_11/\n",
            "  inflating: Persons-1000/collection/last_11/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_11/text.txt  \n",
            "   creating: Persons-1000/collection/last_12/\n",
            "  inflating: Persons-1000/collection/last_12/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_12/text.txt  \n",
            "   creating: Persons-1000/collection/last_13/\n",
            "  inflating: Persons-1000/collection/last_13/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_13/text.txt  \n",
            "   creating: Persons-1000/collection/last_14/\n",
            "  inflating: Persons-1000/collection/last_14/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_14/text.txt  \n",
            "   creating: Persons-1000/collection/last_15/\n",
            "  inflating: Persons-1000/collection/last_15/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_15/text.txt  \n",
            "   creating: Persons-1000/collection/last_16/\n",
            "  inflating: Persons-1000/collection/last_16/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_16/text.txt  \n",
            "   creating: Persons-1000/collection/last_17/\n",
            "  inflating: Persons-1000/collection/last_17/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_17/text.txt  \n",
            "   creating: Persons-1000/collection/last_18/\n",
            "  inflating: Persons-1000/collection/last_18/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_18/text.txt  \n",
            "   creating: Persons-1000/collection/last_19/\n",
            "  inflating: Persons-1000/collection/last_19/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_19/text.txt  \n",
            "   creating: Persons-1000/collection/last_20/\n",
            "  inflating: Persons-1000/collection/last_20/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_20/text.txt  \n",
            "   creating: Persons-1000/collection/last_21/\n",
            "  inflating: Persons-1000/collection/last_21/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_21/text.txt  \n",
            "   creating: Persons-1000/collection/last_22/\n",
            "  inflating: Persons-1000/collection/last_22/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_22/text.txt  \n",
            "   creating: Persons-1000/collection/last_23/\n",
            "  inflating: Persons-1000/collection/last_23/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_23/text.txt  \n",
            "   creating: Persons-1000/collection/last_24/\n",
            "  inflating: Persons-1000/collection/last_24/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_24/text.txt  \n",
            "   creating: Persons-1000/collection/last_25/\n",
            "  inflating: Persons-1000/collection/last_25/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_25/text.txt  \n",
            "   creating: Persons-1000/collection/last_26/\n",
            "  inflating: Persons-1000/collection/last_26/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_26/text.txt  \n",
            "   creating: Persons-1000/collection/last_27/\n",
            "  inflating: Persons-1000/collection/last_27/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_27/text.txt  \n",
            "   creating: Persons-1000/collection/last_28/\n",
            "  inflating: Persons-1000/collection/last_28/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_28/text.txt  \n",
            "   creating: Persons-1000/collection/last_29/\n",
            "  inflating: Persons-1000/collection/last_29/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_29/text.txt  \n",
            "   creating: Persons-1000/collection/last_30_new/\n",
            "  inflating: Persons-1000/collection/last_30_new/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_30_new/text.txt  \n",
            "   creating: Persons-1000/collection/last_31/\n",
            "  inflating: Persons-1000/collection/last_31/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_31/text.txt  \n",
            "   creating: Persons-1000/collection/last_32/\n",
            "  inflating: Persons-1000/collection/last_32/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_32/text.txt  \n",
            "   creating: Persons-1000/collection/last_33/\n",
            "  inflating: Persons-1000/collection/last_33/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_33/text.txt  \n",
            "   creating: Persons-1000/collection/last_34/\n",
            "  inflating: Persons-1000/collection/last_34/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_34/text.txt  \n",
            "   creating: Persons-1000/collection/last_35/\n",
            "  inflating: Persons-1000/collection/last_35/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_35/text.txt  \n",
            "   creating: Persons-1000/collection/last_36/\n",
            "  inflating: Persons-1000/collection/last_36/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_36/text.txt  \n",
            "   creating: Persons-1000/collection/last_37/\n",
            "  inflating: Persons-1000/collection/last_37/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_37/text.txt  \n",
            "   creating: Persons-1000/collection/last_38/\n",
            "  inflating: Persons-1000/collection/last_38/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_38/text.txt  \n",
            "   creating: Persons-1000/collection/last_39/\n",
            "  inflating: Persons-1000/collection/last_39/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_39/text.txt  \n",
            "   creating: Persons-1000/collection/last_40/\n",
            "  inflating: Persons-1000/collection/last_40/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_40/text.txt  \n",
            "   creating: Persons-1000/collection/last_41/\n",
            "  inflating: Persons-1000/collection/last_41/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_41/text.txt  \n",
            "   creating: Persons-1000/collection/last_42/\n",
            "  inflating: Persons-1000/collection/last_42/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_42/text.txt  \n",
            "   creating: Persons-1000/collection/last_43/\n",
            "  inflating: Persons-1000/collection/last_43/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_43/text.txt  \n",
            "   creating: Persons-1000/collection/last_44/\n",
            "  inflating: Persons-1000/collection/last_44/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_44/text.txt  \n",
            "   creating: Persons-1000/collection/last_45/\n",
            "  inflating: Persons-1000/collection/last_45/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_45/text.txt  \n",
            "   creating: Persons-1000/collection/last_46/\n",
            "  inflating: Persons-1000/collection/last_46/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_46/text.txt  \n",
            "   creating: Persons-1000/collection/last_47/\n",
            "  inflating: Persons-1000/collection/last_47/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_47/text.txt  \n",
            "   creating: Persons-1000/collection/last_48/\n",
            "  inflating: Persons-1000/collection/last_48/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_48/text.txt  \n",
            "   creating: Persons-1000/collection/last_49/\n",
            "  inflating: Persons-1000/collection/last_49/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_49/text.txt  \n",
            "   creating: Persons-1000/collection/last_50/\n",
            "  inflating: Persons-1000/collection/last_50/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_50/text.txt  \n",
            "   creating: Persons-1000/collection/last_51/\n",
            "  inflating: Persons-1000/collection/last_51/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_51/text.txt  \n",
            "   creating: Persons-1000/collection/last_52/\n",
            "  inflating: Persons-1000/collection/last_52/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_52/text.txt  \n",
            "   creating: Persons-1000/collection/last_53/\n",
            "  inflating: Persons-1000/collection/last_53/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_53/text.txt  \n",
            "   creating: Persons-1000/collection/last_54/\n",
            "  inflating: Persons-1000/collection/last_54/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_54/text.txt  \n",
            "   creating: Persons-1000/collection/last_55/\n",
            "  inflating: Persons-1000/collection/last_55/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_55/text.txt  \n",
            "   creating: Persons-1000/collection/last_56/\n",
            "  inflating: Persons-1000/collection/last_56/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_56/text.txt  \n",
            "   creating: Persons-1000/collection/last_57/\n",
            "  inflating: Persons-1000/collection/last_57/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_57/text.txt  \n",
            "   creating: Persons-1000/collection/last_58/\n",
            "  inflating: Persons-1000/collection/last_58/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_58/text.txt  \n",
            "   creating: Persons-1000/collection/last_59/\n",
            "  inflating: Persons-1000/collection/last_59/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_59/text.txt  \n",
            "   creating: Persons-1000/collection/last_60/\n",
            "  inflating: Persons-1000/collection/last_60/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_60/text.txt  \n",
            "   creating: Persons-1000/collection/last_61/\n",
            "  inflating: Persons-1000/collection/last_61/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_61/text.txt  \n",
            "   creating: Persons-1000/collection/last_62/\n",
            "  inflating: Persons-1000/collection/last_62/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_62/text.txt  \n",
            "   creating: Persons-1000/collection/last_63/\n",
            "  inflating: Persons-1000/collection/last_63/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_63/text.txt  \n",
            "   creating: Persons-1000/collection/last_64/\n",
            "  inflating: Persons-1000/collection/last_64/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_64/text.txt  \n",
            "   creating: Persons-1000/collection/last_65/\n",
            "  inflating: Persons-1000/collection/last_65/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_65/text.txt  \n",
            "   creating: Persons-1000/collection/last_66/\n",
            "  inflating: Persons-1000/collection/last_66/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_66/text.txt  \n",
            "   creating: Persons-1000/collection/last_67/\n",
            "  inflating: Persons-1000/collection/last_67/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_67/text.txt  \n",
            "   creating: Persons-1000/collection/last_68/\n",
            "  inflating: Persons-1000/collection/last_68/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_68/text.txt  \n",
            "   creating: Persons-1000/collection/last_69/\n",
            "  inflating: Persons-1000/collection/last_69/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_69/text.txt  \n",
            "   creating: Persons-1000/collection/last_70/\n",
            "  inflating: Persons-1000/collection/last_70/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_70/text.txt  \n",
            "   creating: Persons-1000/collection/last_71/\n",
            "  inflating: Persons-1000/collection/last_71/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_71/text.txt  \n",
            "   creating: Persons-1000/collection/last_72/\n",
            "  inflating: Persons-1000/collection/last_72/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_72/text.txt  \n",
            "   creating: Persons-1000/collection/last_73/\n",
            "  inflating: Persons-1000/collection/last_73/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_73/text.txt  \n",
            "   creating: Persons-1000/collection/last_74/\n",
            "  inflating: Persons-1000/collection/last_74/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_74/text.txt  \n",
            "   creating: Persons-1000/collection/last_75/\n",
            "  inflating: Persons-1000/collection/last_75/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/last_75/text.txt  \n",
            "   creating: Persons-1000/collection/lenoblast/\n",
            "  inflating: Persons-1000/collection/lenoblast/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/lenoblast/text.txt  \n",
            "   creating: Persons-1000/collection/mvd/\n",
            "  inflating: Persons-1000/collection/mvd/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/mvd/text.txt  \n",
            "   creating: Persons-1000/collection/mvd2/\n",
            "  inflating: Persons-1000/collection/mvd2/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/mvd2/text.txt  \n",
            "   creating: Persons-1000/collection/rosobrnadzor/\n",
            "  inflating: Persons-1000/collection/rosobrnadzor/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/rosobrnadzor/text.txt  \n",
            "   creating: Persons-1000/collection/semenenko/\n",
            "  inflating: Persons-1000/collection/semenenko/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/semenenko/text.txt  \n",
            "   creating: Persons-1000/collection/shojgu1/\n",
            "  inflating: Persons-1000/collection/shojgu1/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/shojgu1/text.txt  \n",
            "   creating: Persons-1000/collection/shojgu3/\n",
            "  inflating: Persons-1000/collection/shojgu3/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/shojgu3/text.txt  \n",
            "   creating: Persons-1000/collection/shojgu4/\n",
            "  inflating: Persons-1000/collection/shojgu4/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/shojgu4/text.txt  \n",
            "   creating: Persons-1000/collection/shojgu6/\n",
            "  inflating: Persons-1000/collection/shojgu6/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/shojgu6/text.txt  \n",
            "   creating: Persons-1000/collection/si_tzjanpin/\n",
            "  inflating: Persons-1000/collection/si_tzjanpin/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/si_tzjanpin/text.txt  \n",
            "   creating: Persons-1000/collection/sobjanin2/\n",
            "  inflating: Persons-1000/collection/sobjanin2/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/sobjanin2/text.txt  \n",
            "   creating: Persons-1000/collection/turkmenija/\n",
            "  inflating: Persons-1000/collection/turkmenija/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/turkmenija/text.txt  \n",
            "   creating: Persons-1000/collection/uchitel/\n",
            "  inflating: Persons-1000/collection/uchitel/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/uchitel/text.txt  \n",
            "   creating: Persons-1000/collection/Майкл Джексон/\n",
            "  inflating: Persons-1000/collection/Майкл Джексон/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/Майкл Джексон/text.txt  \n",
            "   creating: Persons-1000/collection/Рядовой Челах/\n",
            "  inflating: Persons-1000/collection/Рядовой Челах/anno.markup.xml  \n",
            "  inflating: Persons-1000/collection/Рядовой Челах/text.txt  \n",
            "  inflating: Persons-1000/CollectionInfo.pdf  \n",
            "  inflating: Persons-1000/Copyright.pdf  \n",
            "  inflating: Persons-1000/Reference.pdf  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUw0n2_VPiCn",
        "colab_type": "code",
        "outputId": "a01e9123-b680-4105-d77f-007776bf8476",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!cat Persons-1000/collection/001/anno.markup.xml  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿<markup>\r\n",
            "<entry>\r\n",
            "<id>1</id>\r\n",
            "<offset>308</offset>\r\n",
            "<length>16</length>\r\n",
            "<class>AAA_Estimate_Person</class>\r\n",
            "<attribute>\r\n",
            "<name>Canonical</name>\r\n",
            "<value>ГРИГОРИЙ КАРАСИН</value>\r\n",
            "</attribute>\r\n",
            "</entry>\r\n",
            "<entry>\r\n",
            "<id>2</id>\r\n",
            "<offset>387</offset>\r\n",
            "<length>15</length>\r\n",
            "<class>AAA_Estimate_Person</class>\r\n",
            "<attribute>\r\n",
            "<name>Canonical</name>\r\n",
            "<value>ДЭНИЭЛ ФРИД</value>\r\n",
            "</attribute>\r\n",
            "</entry>\r\n",
            "</markup>\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to1AyngFhO4P",
        "colab_type": "text"
      },
      "source": [
        "# NER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVj6iocPhpqN",
        "colab_type": "text"
      },
      "source": [
        "## Датасет"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxNSz3DyhWzH",
        "colab_type": "text"
      },
      "source": [
        "Named Entity Recognition - распознавание именных сущностей. Выделяем в тексте спаны PER, LOC, ORG.\n",
        "\n",
        "В случае с Persons-1000 только PER. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev7wne1KQF9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "from ipymarkup import show_box_markup\n",
        "from ipymarkup.palette import palette, BLUE, RED, GREEN\n",
        "\n",
        "directory = \"Persons-1000/collection/\"\n",
        "\n",
        "def read_text_with_markup(directory):\n",
        "    markup_file_name = os.path.join(directory, \"anno.markup.xml\")\n",
        "    text_file_name = os.path.join(directory, \"text.txt\")\n",
        "    with open(text_file_name, \"r\", encoding=\"windows-1251\") as r:\n",
        "        text = r.read()\n",
        "    text = text.replace(\"\\n\", \"\\r\\n\")\n",
        "    root = ET.parse(markup_file_name).getroot()\n",
        "    spans = []\n",
        "    for entry in root.findall(\"entry\"):\n",
        "        start_pos = int(entry.find(\"offset\").text)\n",
        "        end_pos = start_pos + int(entry.find(\"length\").text)\n",
        "        tag = entry.find(\"class\").text\n",
        "        spans.append((start_pos, end_pos, \"PER\"))\n",
        "    return text, spans\n",
        "\n",
        "data = []\n",
        "for sample_name in os.listdir(directory):\n",
        "    sample_path = os.path.join(directory, sample_name)\n",
        "    data.append(read_text_with_markup(sample_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVf4thMLhw6e",
        "colab_type": "text"
      },
      "source": [
        "ipymarkup - модуль для вывода NER разметки в ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L6tXNHjhvsZ",
        "colab_type": "code",
        "outputId": "aef1cd6d-49f7-484f-f37f-edeb5bf08ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "show_box_markup(data[0][0], data[0][1], palette=palette(PER=BLUE, ORG=RED, LOC=GREEN))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">\r\n",
              "<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Марио Монти<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> подаст в отставку с должности премьер-министра Италии\r\n",
              "Фото: Reuters Фото: Reuters Фото: Reuters\r\n",
              "Фото: Reuters\r\n",
              "\r\n",
              "Премьер-министр Италии <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Марио Монти<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> подтвердил намерение подать прошение об отставке после того, как парламент одобрит закон о государственном бюджете на 2013 г. Этот и другие вопросы глава кабинета обсудил в ходе двухчасовой беседы с Президентом страны <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Джорджо Наполитано<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, передает Reuters.\r\n",
              "\r\n",
              "Отметим, что ранее входившая в парламентскую коалицию партия \"Народ свободы\" отказала <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Монти<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> в поддержке. В свою очередь 76-летний <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Сильвио Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, который является лидером указанной партии, за несколько часов до заявления <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Монти<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> сообщил прессе, что сохраняет премьерские амбиции и готов вновь бороться за пост главы правительства республики в 2013 году.\r\n",
              "\r\n",
              "В случае если бюджет будет принят \"быстро\", <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Монти<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> готов немедленно сложить с себя полномочия. Примечательно, что Президент имеет полномочия объявить о роспуске парламента и проведении досрочных выборов. Несмотря на то, что такой вариант является маловероятным, итальянские политологи рассматривают его в качестве возможного исхода ситуации.\r\n",
              "\r\n",
              "Политологи заключили, что теперь <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> обрушится с жесткой критикой на действующий кабинет министров, проводящий политику жесткой экономии.\r\n",
              "\r\n",
              "    Читайте также: <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> намерен в 2013 г. снова баллотироваться на пост премьер-министра Италии\r\n",
              "\r\n",
              "<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> ушел в отставку немногим более года назад, после чего в стране с согласия парламентского большинства было составлено правительство технократов, которому было поручено проводить непопулярную экономическую политику.\r\n",
              "\r\n",
              "Как сообщалось, 26 октября с.г. суд приговорил <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> к году тюрьмы с учетом закона об амнистии. Отмечается, что документ был принят в 2006 г., и в соответствии с ним срок тюремного заключения бывшего итальянского премьера уменьшен с четырех лет до одного года. Речь идет о скандальном деле Mediaset, в рамках которого <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> обвинялся в масштабных финансовых махинациях. <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> также отрицает обвинения в сексе с несовершеннолетней проституткой, известной под прозвищем \"Руби\".\r\n",
              "\r\n",
              "    Читайте также: Адвокаты <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> обжалуют приговор экс-премьеру\r\n",
              "\r\n",
              "Отметим также, действующий секретарь левоцентристской Демократической партии Италии <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Пьер Луиджи Берсани<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> станет кандидатом на пост премьер-министра страны. Именно его кандидатуру поддержало большинство сторонников партии на праймериз 2 декабря. На выборах <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берсани<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> обошел мэра Флоренции <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Маттео Ренци<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, считающегося одним из наиболее заметных политиков \"новой волны\" в Италии. Демократическая партия, созданная на основе коалиции \"Оливковое дерево\" бывшего премьер-министра страны <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Романо Проди<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> и включающая в себя партии \"Левые демократы\" и \"Маргерита\", занимает 217 мест в 630-местном парламенте Италии и является одной из главных оппозиционных сил страны.\r\n",
              "\r\n",
              "    По теме: В Италии тысячи людей выступили против мер бюджетной экономии правительства\r\n",
              "\r\n",
              "Итальянский политик, лидер партии \"Народ свободы\" и крупный бизнесмен, чей холдинг Fininvest владеет разнородными активами - от медиа и строительного бизнеса до футбольного клуба Milan (всего около 150 компаний) трижды избирался на пост главы правительства (абсолютный рекорд для Италии): возглавлял правительство Италии в 1994 г., в 2001-2006 гг. и в 2008-2011 г. В ноябре 2011 г., потеряв большинство в парламенте страны, добровольно ушел в отставку. По данным журнала Forbes, в марте 2011 г. состояние <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> оценивалось в 7,8 млрд долл.\r\n",
              "\r\n",
              "Скандально известная фигура в стране - <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> многократно обвинялся в финансовых аферах, коррупции, даче взяток госчиновникам, участии в сексуальных скандалах, привлекался к суду. Часть инициированных против него уголовных процессов закончились тюремными сроками, которые, впрочем, предприимчивый политик ни разу не отсидел. Каждый раз Верховный суд аннулировал приговоры судов низших инстанций.\r\n",
              "</div>"
            ],
            "text/plain": [
              "BoxMarkup('\\r\\nМарио Монти подаст в отставку с должности премьер-министра Италии\\r\\nФото: Reuters Фото: Reuters Фото: Reuters\\r\\nФото: Reuters\\r\\n\\r\\nПремьер-министр Италии Марио Монти подтвердил намерение подать прошение об отставке после того, как парламент одобрит закон о государственном бюджете на 2013 г. Этот и другие вопросы глава кабинета обсудил в ходе двухчасовой беседы с Президентом страны Джорджо Наполитано, передает Reuters.\\r\\n\\r\\nОтметим, что ранее входившая в парламентскую коалицию партия \"Народ свободы\" отказала Монти в поддержке. В свою очередь 76-летний Сильвио Берлускони, который является лидером указанной партии, за несколько часов до заявления Монти сообщил прессе, что сохраняет премьерские амбиции и готов вновь бороться за пост главы правительства республики в 2013 году.\\r\\n\\r\\nВ случае если бюджет будет принят \"быстро\", Монти готов немедленно сложить с себя полномочия. Примечательно, что Президент имеет полномочия объявить о роспуске парламента и проведении досрочных выборов. Несмотря на то, что такой вариант является маловероятным, итальянские политологи рассматривают его в качестве возможного исхода ситуации.\\r\\n\\r\\nПолитологи заключили, что теперь Берлускони обрушится с жесткой критикой на действующий кабинет министров, проводящий политику жесткой экономии.\\r\\n\\r\\n    Читайте также: Берлускони намерен в 2013 г. снова баллотироваться на пост премьер-министра Италии\\r\\n\\r\\nБерлускони ушел в отставку немногим более года назад, после чего в стране с согласия парламентского большинства было составлено правительство технократов, которому было поручено проводить непопулярную экономическую политику.\\r\\n\\r\\nКак сообщалось, 26 октября с.г. суд приговорил Берлускони к году тюрьмы с учетом закона об амнистии. Отмечается, что документ был принят в 2006 г., и в соответствии с ним срок тюремного заключения бывшего итальянского премьера уменьшен с четырех лет до одного года. Речь идет о скандальном деле Mediaset, в рамках которого Берлускони обвинялся в масштабных финансовых махинациях. Берлускони также отрицает обвинения в сексе с несовершеннолетней проституткой, известной под прозвищем \"Руби\".\\r\\n\\r\\n    Читайте также: Адвокаты Берлускони обжалуют приговор экс-премьеру\\r\\n\\r\\nОтметим также, действующий секретарь левоцентристской Демократической партии Италии Пьер Луиджи Берсани станет кандидатом на пост премьер-министра страны. Именно его кандидатуру поддержало большинство сторонников партии на праймериз 2 декабря. На выборах Берсани обошел мэра Флоренции Маттео Ренци, считающегося одним из наиболее заметных политиков \"новой волны\" в Италии. Демократическая партия, созданная на основе коалиции \"Оливковое дерево\" бывшего премьер-министра страны Романо Проди и включающая в себя партии \"Левые демократы\" и \"Маргерита\", занимает 217 мест в 630-местном парламенте Италии и является одной из главных оппозиционных сил страны.\\r\\n\\r\\n    По теме: В Италии тысячи людей выступили против мер бюджетной экономии правительства\\r\\n\\r\\nИтальянский политик, лидер партии \"Народ свободы\" и крупный бизнесмен, чей холдинг Fininvest владеет разнородными активами - от медиа и строительного бизнеса до футбольного клуба Milan (всего около 150 компаний) трижды избирался на пост главы правительства (абсолютный рекорд для Италии): возглавлял правительство Италии в 1994 г., в 2001-2006 гг. и в 2008-2011 г. В ноябре 2011 г., потеряв большинство в парламенте страны, добровольно ушел в отставку. По данным журнала Forbes, в марте 2011 г. состояние Берлускони оценивалось в 7,8 млрд долл.\\r\\n\\r\\nСкандально известная фигура в стране - Берлускони многократно обвинялся в финансовых аферах, коррупции, даче взяток госчиновникам, участии в сексуальных скандалах, привлекался к суду. Часть инициированных против него уголовных процессов закончились тюремными сроками, которые, впрочем, предприимчивый политик ни разу не отсидел. Каждый раз Верховный суд аннулировал приговоры судов низших инстанций.\\r\\n',\n",
              "          [Span(2, 13, 'PER'),\n",
              "           Span(152, 163, 'PER'),\n",
              "           Span(382, 400, 'PER'),\n",
              "           Span(509, 514, 'PER'),\n",
              "           Span(553, 571, 'PER'),\n",
              "           Span(648, 653, 'PER'),\n",
              "           Span(826, 831, 'PER'),\n",
              "           Span(1159, 1169, 'PER'),\n",
              "           Span(1293, 1303, 'PER'),\n",
              "           Span(1379, 1389, 'PER'),\n",
              "           Span(1654, 1664, 'PER'),\n",
              "           Span(1930, 1940, 'PER'),\n",
              "           Span(1987, 1997, 'PER'),\n",
              "           Span(2129, 2139, 'PER'),\n",
              "           Span(2258, 2277, 'PER'),\n",
              "           Span(2429, 2436, 'PER'),\n",
              "           Span(2459, 2471, 'PER'),\n",
              "           Span(2651, 2663, 'PER'),\n",
              "           Span(3428, 3438, 'PER'),\n",
              "           Span(3510, 3520, 'PER')])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt-NHuy6h3Nn",
        "colab_type": "text"
      },
      "source": [
        "## BIO\n",
        "\n",
        "BIO разметка: B - begin, I - inner, O - outer. Преобразуем задачу разметки спанов в задачу классификации каждого слова."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3fe43ebe-64ed-43a2-a165-f2cc46f06e81",
        "id": "5YL2kf97Cn9F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "from razdel import tokenize\n",
        "from collections import namedtuple\n",
        "\n",
        "Sample = namedtuple(\"Sample\", \"text,tokens,spans,labels\")\n",
        "\n",
        "samples = []\n",
        "for text, spans in data:\n",
        "    labels = []\n",
        "    tokens = list(tokenize(text))\n",
        "    for token in tokens:\n",
        "        label = 0\n",
        "        for span in spans:\n",
        "            if token.start == span[0]:\n",
        "                label = 1\n",
        "            elif token.start > span[0] and token.stop <= span[1]:\n",
        "                label = 2\n",
        "        labels.append(label)\n",
        "    sample = Sample(text, tokens, spans, labels)\n",
        "    samples.append(sample)\n",
        "\n",
        "show_box_markup(samples[0].text, samples[0].spans, palette=palette(PER=BLUE, ORG=RED, LOC=GREEN))\n",
        "print(samples[0].labels)\n",
        "print(len(samples))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">\r\n",
              "<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Марио Монти<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> подаст в отставку с должности премьер-министра Италии\r\n",
              "Фото: Reuters Фото: Reuters Фото: Reuters\r\n",
              "Фото: Reuters\r\n",
              "\r\n",
              "Премьер-министр Италии <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Марио Монти<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> подтвердил намерение подать прошение об отставке после того, как парламент одобрит закон о государственном бюджете на 2013 г. Этот и другие вопросы глава кабинета обсудил в ходе двухчасовой беседы с Президентом страны <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Джорджо Наполитано<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, передает Reuters.\r\n",
              "\r\n",
              "Отметим, что ранее входившая в парламентскую коалицию партия \"Народ свободы\" отказала <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Монти<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> в поддержке. В свою очередь 76-летний <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Сильвио Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, который является лидером указанной партии, за несколько часов до заявления <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Монти<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> сообщил прессе, что сохраняет премьерские амбиции и готов вновь бороться за пост главы правительства республики в 2013 году.\r\n",
              "\r\n",
              "В случае если бюджет будет принят \"быстро\", <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Монти<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> готов немедленно сложить с себя полномочия. Примечательно, что Президент имеет полномочия объявить о роспуске парламента и проведении досрочных выборов. Несмотря на то, что такой вариант является маловероятным, итальянские политологи рассматривают его в качестве возможного исхода ситуации.\r\n",
              "\r\n",
              "Политологи заключили, что теперь <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> обрушится с жесткой критикой на действующий кабинет министров, проводящий политику жесткой экономии.\r\n",
              "\r\n",
              "    Читайте также: <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> намерен в 2013 г. снова баллотироваться на пост премьер-министра Италии\r\n",
              "\r\n",
              "<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> ушел в отставку немногим более года назад, после чего в стране с согласия парламентского большинства было составлено правительство технократов, которому было поручено проводить непопулярную экономическую политику.\r\n",
              "\r\n",
              "Как сообщалось, 26 октября с.г. суд приговорил <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> к году тюрьмы с учетом закона об амнистии. Отмечается, что документ был принят в 2006 г., и в соответствии с ним срок тюремного заключения бывшего итальянского премьера уменьшен с четырех лет до одного года. Речь идет о скандальном деле Mediaset, в рамках которого <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> обвинялся в масштабных финансовых махинациях. <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> также отрицает обвинения в сексе с несовершеннолетней проституткой, известной под прозвищем \"Руби\".\r\n",
              "\r\n",
              "    Читайте также: Адвокаты <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> обжалуют приговор экс-премьеру\r\n",
              "\r\n",
              "Отметим также, действующий секретарь левоцентристской Демократической партии Италии <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Пьер Луиджи Берсани<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> станет кандидатом на пост премьер-министра страны. Именно его кандидатуру поддержало большинство сторонников партии на праймериз 2 декабря. На выборах <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берсани<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> обошел мэра Флоренции <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Маттео Ренци<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, считающегося одним из наиболее заметных политиков \"новой волны\" в Италии. Демократическая партия, созданная на основе коалиции \"Оливковое дерево\" бывшего премьер-министра страны <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Романо Проди<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> и включающая в себя партии \"Левые демократы\" и \"Маргерита\", занимает 217 мест в 630-местном парламенте Италии и является одной из главных оппозиционных сил страны.\r\n",
              "\r\n",
              "    По теме: В Италии тысячи людей выступили против мер бюджетной экономии правительства\r\n",
              "\r\n",
              "Итальянский политик, лидер партии \"Народ свободы\" и крупный бизнесмен, чей холдинг Fininvest владеет разнородными активами - от медиа и строительного бизнеса до футбольного клуба Milan (всего около 150 компаний) трижды избирался на пост главы правительства (абсолютный рекорд для Италии): возглавлял правительство Италии в 1994 г., в 2001-2006 гг. и в 2008-2011 г. В ноябре 2011 г., потеряв большинство в парламенте страны, добровольно ушел в отставку. По данным журнала Forbes, в марте 2011 г. состояние <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> оценивалось в 7,8 млрд долл.\r\n",
              "\r\n",
              "Скандально известная фигура в стране - <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Берлускони<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> многократно обвинялся в финансовых аферах, коррупции, даче взяток госчиновникам, участии в сексуальных скандалах, привлекался к суду. Часть инициированных против него уголовных процессов закончились тюремными сроками, которые, впрочем, предприимчивый политик ни разу не отсидел. Каждый раз Верховный суд аннулировал приговоры судов низших инстанций.\r\n",
              "</div>"
            ],
            "text/plain": [
              "BoxMarkup('\\r\\nМарио Монти подаст в отставку с должности премьер-министра Италии\\r\\nФото: Reuters Фото: Reuters Фото: Reuters\\r\\nФото: Reuters\\r\\n\\r\\nПремьер-министр Италии Марио Монти подтвердил намерение подать прошение об отставке после того, как парламент одобрит закон о государственном бюджете на 2013 г. Этот и другие вопросы глава кабинета обсудил в ходе двухчасовой беседы с Президентом страны Джорджо Наполитано, передает Reuters.\\r\\n\\r\\nОтметим, что ранее входившая в парламентскую коалицию партия \"Народ свободы\" отказала Монти в поддержке. В свою очередь 76-летний Сильвио Берлускони, который является лидером указанной партии, за несколько часов до заявления Монти сообщил прессе, что сохраняет премьерские амбиции и готов вновь бороться за пост главы правительства республики в 2013 году.\\r\\n\\r\\nВ случае если бюджет будет принят \"быстро\", Монти готов немедленно сложить с себя полномочия. Примечательно, что Президент имеет полномочия объявить о роспуске парламента и проведении досрочных выборов. Несмотря на то, что такой вариант является маловероятным, итальянские политологи рассматривают его в качестве возможного исхода ситуации.\\r\\n\\r\\nПолитологи заключили, что теперь Берлускони обрушится с жесткой критикой на действующий кабинет министров, проводящий политику жесткой экономии.\\r\\n\\r\\n    Читайте также: Берлускони намерен в 2013 г. снова баллотироваться на пост премьер-министра Италии\\r\\n\\r\\nБерлускони ушел в отставку немногим более года назад, после чего в стране с согласия парламентского большинства было составлено правительство технократов, которому было поручено проводить непопулярную экономическую политику.\\r\\n\\r\\nКак сообщалось, 26 октября с.г. суд приговорил Берлускони к году тюрьмы с учетом закона об амнистии. Отмечается, что документ был принят в 2006 г., и в соответствии с ним срок тюремного заключения бывшего итальянского премьера уменьшен с четырех лет до одного года. Речь идет о скандальном деле Mediaset, в рамках которого Берлускони обвинялся в масштабных финансовых махинациях. Берлускони также отрицает обвинения в сексе с несовершеннолетней проституткой, известной под прозвищем \"Руби\".\\r\\n\\r\\n    Читайте также: Адвокаты Берлускони обжалуют приговор экс-премьеру\\r\\n\\r\\nОтметим также, действующий секретарь левоцентристской Демократической партии Италии Пьер Луиджи Берсани станет кандидатом на пост премьер-министра страны. Именно его кандидатуру поддержало большинство сторонников партии на праймериз 2 декабря. На выборах Берсани обошел мэра Флоренции Маттео Ренци, считающегося одним из наиболее заметных политиков \"новой волны\" в Италии. Демократическая партия, созданная на основе коалиции \"Оливковое дерево\" бывшего премьер-министра страны Романо Проди и включающая в себя партии \"Левые демократы\" и \"Маргерита\", занимает 217 мест в 630-местном парламенте Италии и является одной из главных оппозиционных сил страны.\\r\\n\\r\\n    По теме: В Италии тысячи людей выступили против мер бюджетной экономии правительства\\r\\n\\r\\nИтальянский политик, лидер партии \"Народ свободы\" и крупный бизнесмен, чей холдинг Fininvest владеет разнородными активами - от медиа и строительного бизнеса до футбольного клуба Milan (всего около 150 компаний) трижды избирался на пост главы правительства (абсолютный рекорд для Италии): возглавлял правительство Италии в 1994 г., в 2001-2006 гг. и в 2008-2011 г. В ноябре 2011 г., потеряв большинство в парламенте страны, добровольно ушел в отставку. По данным журнала Forbes, в марте 2011 г. состояние Берлускони оценивалось в 7,8 млрд долл.\\r\\n\\r\\nСкандально известная фигура в стране - Берлускони многократно обвинялся в финансовых аферах, коррупции, даче взяток госчиновникам, участии в сексуальных скандалах, привлекался к суду. Часть инициированных против него уголовных процессов закончились тюремными сроками, которые, впрочем, предприимчивый политик ни разу не отсидел. Каждый раз Верховный суд аннулировал приговоры судов низших инстанций.\\r\\n',\n",
              "          [Span(2, 13, 'PER'),\n",
              "           Span(152, 163, 'PER'),\n",
              "           Span(382, 400, 'PER'),\n",
              "           Span(509, 514, 'PER'),\n",
              "           Span(553, 571, 'PER'),\n",
              "           Span(648, 653, 'PER'),\n",
              "           Span(826, 831, 'PER'),\n",
              "           Span(1159, 1169, 'PER'),\n",
              "           Span(1293, 1303, 'PER'),\n",
              "           Span(1379, 1389, 'PER'),\n",
              "           Span(1654, 1664, 'PER'),\n",
              "           Span(1930, 1940, 'PER'),\n",
              "           Span(1987, 1997, 'PER'),\n",
              "           Span(2129, 2139, 'PER'),\n",
              "           Span(2258, 2277, 'PER'),\n",
              "           Span(2429, 2436, 'PER'),\n",
              "           Span(2459, 2471, 'PER'),\n",
              "           Span(2651, 2663, 'PER'),\n",
              "           Span(3428, 3438, 'PER'),\n",
              "           Span(3510, 3520, 'PER')])"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Vhppz4iF7K",
        "colab_type": "text"
      },
      "source": [
        "Бьём на выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwyMhmAaE_CY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.shuffle(samples)\n",
        "\n",
        "train = samples[:700]\n",
        "val = samples[700:850]\n",
        "test = samples[850:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEWpoWt6CkP1",
        "colab_type": "code",
        "outputId": "cb43d805-1ffb-43ab-ae87-2ee2fae058b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "char_set = [\"<pad>\", \"<unk>\"] + list({ch for sample in samples for token in sample.tokens for ch in token.text})\n",
        "print(char_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<pad>', '<unk>', 'Т', '”', 'ё', '7', '1', 'д', '>', '©', 'c', 'k', 'м', 'Х', ',', 'Л', 'l', '…', 'А', 'F', 'U', '|', '[', 'н', 's', 'J', 'u', 'ь', 'Q', '+', 'й', 'O', 'g', 'В', 'x', 'z', 'y', '“', 'e', 'щ', ']', 'r', 'П', 't', 'm', 'У', '%', ';', 'f', 'Ф', 'ы', 'Р', 'E', '!', 'B', 'Щ', 'd', 'ъ', 'Y', '*', 'И', 'ю', '3', 'I', 'P', 'R', '»', 'з', 'э', '€', 'ж', 'p', 'v', 'N', '<', 'п', 'M', 'o', 'Ц', 'Б', '\\xad', 'ц', ':', 'Ё', '6', 'і', 'и', '\"', 'Н', 'Я', 'ф', 'G', 'H', 'C', 'Z', '–', 'к', 'О', 'Э', 'i', 'a', 'Д', 'З', 'т', 'Ж', 'b', '.', 'h', 'Г', '/', '2', 'Ч', 'а', 'у', 'в', 'е', 'D', 'T', 'г', 'K', 'L', 'о', 'q', 'С', '(', 'р', '-', 'ш', 'w', '№', 'Ы', '=', '0', '?', 'л', ')', '_', 'Ъ', 'М', 'Й', '5', 'Ю', 'Ш', '#', 'б', 'S', '4', 'A', '«', 'я', 'Е', \"'\", '8', 'j', 'V', '$', '•', 'х', 'n', 'ч', '—', 'Ь', 'W', 'с', 'К', 'X', '&', '9']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl0XXI9_iNJQ",
        "colab_type": "text"
      },
      "source": [
        "Для каждого слова сохраняем его символьный состав, а в остальном старый добрый пайплайн"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8tvvFJDEQin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "def get_next_gen_batch(samples, max_seq_len=500, max_char_seq_len=40, batch_size=32):\n",
        "    indices = np.arange(len(samples))\n",
        "    np.random.shuffle(indices)\n",
        "    batch_begin = 0\n",
        "    while batch_begin < len(samples):\n",
        "        batch_indices = indices[batch_begin: batch_begin + batch_size]\n",
        "        batch = []\n",
        "        batch_labels = []\n",
        "        batch_max_len = 0\n",
        "        for data_ind in batch_indices:\n",
        "            sample = samples[data_ind]\n",
        "            inputs = []\n",
        "            for token in sample.tokens[:max_seq_len]:\n",
        "                chars = [char_set.index(ch) if ch in char_set else char_set.index(\"<unk>\") for ch in token.text][:max_char_seq_len]\n",
        "                chars += [0] * (max_char_seq_len - len(chars))\n",
        "                inputs.append(chars)\n",
        "            batch_max_len = max(batch_max_len, len(inputs))\n",
        "            inputs += [[0]*max_char_seq_len] * (max_seq_len - len(inputs))\n",
        "            batch.append(inputs)\n",
        "            labels = sample.labels[:max_seq_len]\n",
        "            labels += [0] * (max_seq_len - len(labels))\n",
        "            batch_labels.append(labels)\n",
        "        batch_begin += batch_size\n",
        "        batch = torch.cuda.LongTensor(batch)[:, :batch_max_len]\n",
        "        labels = torch.cuda.LongTensor(batch_labels)[:, :batch_max_len]\n",
        "        yield batch_indices, batch, labels\n",
        "\n",
        "\n",
        "def train_gen_model(model, train_samples, val_samples, epochs_count=10, \n",
        "                    loss_every_nsteps=1000, lr=0.01, save_path=\"model.pt\", device_name=\"cuda\",\n",
        "                    early_stopping=True,\n",
        "                    batch_size=32,\n",
        "                    crf=False):\n",
        "    params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(\"Trainable params: {}\".format(params_count))\n",
        "    device = torch.device(device_name)\n",
        "    model = model.to(device)\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_function = nn.CrossEntropyLoss().cuda()\n",
        "    prev_avg_val_loss = None\n",
        "    for epoch in range(epochs_count):\n",
        "        model.train()\n",
        "        for step, (_, batch, batch_labels) in enumerate(get_next_gen_batch(train, batch_size=batch_size)):\n",
        "            \n",
        "            if crf:\n",
        "              loss = model(batch, batch_labels)\n",
        "            else :    \n",
        "              logits = model(batch) # Прямой проход\n",
        "              logits = logits.transpose(1, 2)\n",
        "              loss = loss_function(logits, batch_labels) # Подсчёт ошибки\n",
        "            \n",
        "            loss.backward() # Подсчёт градиентов dL/dw\n",
        "            optimizer.step() # Градиентный спуск или его модификации (в данном случае Adam)\n",
        "            optimizer.zero_grad() # Зануление градиентов, чтобы их спокойно менять на следующей итерации\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        val_total_loss = 0\n",
        "        val_batch_count = 0\n",
        "        model.eval()\n",
        "        for _, (_, batch, batch_labels) in enumerate(get_next_gen_batch(val)):\n",
        "            if crf:\n",
        "              loss = model(batch, batch_labels)\n",
        "              val_total_loss += loss\n",
        "            else :    \n",
        "              logits = model(batch) # Прямой проход\n",
        "              logits = logits.transpose(1, 2)\n",
        "              val_total_loss += loss_function(logits, batch_labels) # Подсчёт ошибки\n",
        "            val_batch_count += 1\n",
        "        avg_val_loss = val_total_loss/val_batch_count\n",
        "        print(\"Epoch = {}, Avg Train Loss = {:.4f}, Avg val loss = {:.4f}, Time = {:.2f}s\".format(epoch, total_loss / loss_every_nsteps, avg_val_loss, time.time() - start_time))\n",
        "        total_loss = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        if early_stopping and prev_avg_val_loss is not None and avg_val_loss > prev_avg_val_loss:\n",
        "            model.load_state_dict(torch.load(save_path))\n",
        "            model.eval()\n",
        "            break\n",
        "        prev_avg_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-rBnhPsiVZ2",
        "colab_type": "text"
      },
      "source": [
        "## Бесконтекстная модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcyI1PUaHScl",
        "colab_type": "code",
        "outputId": "b88ec311-b1aa-414c-a99a-09f3960da013",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class SuperSimpleModel(nn.Module):\n",
        "    def __init__(self, char_set_size, char_embedding_dim=16, classes_count=3, char_max_seq_len=40):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embeddings_layer = nn.Embedding(char_set_size, char_embedding_dim)\n",
        "        self.out_layer = nn.Linear(char_max_seq_len * char_embedding_dim, classes_count)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        projections = self.embeddings_layer.forward(inputs)\n",
        "        projections = projections.reshape(projections.size(0), projections.size(1), -1)\n",
        "        output = self.out_layer.forward(projections)\n",
        "        return output\n",
        "\n",
        "\n",
        "model = SuperSimpleModel(len(char_set))\n",
        "train_gen_model(model, train, val, epochs_count=30, early_stopping=False, lr=0.02)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable params: 4611\n",
            "Epoch = 0, Avg Train Loss = 0.0184, Avg val loss = 0.3265, Time = 4.66s\n",
            "Epoch = 1, Avg Train Loss = 0.0047, Avg val loss = 0.1220, Time = 4.57s\n",
            "Epoch = 2, Avg Train Loss = 0.0023, Avg val loss = 0.0930, Time = 4.60s\n",
            "Epoch = 3, Avg Train Loss = 0.0020, Avg val loss = 0.0846, Time = 4.58s\n",
            "Epoch = 4, Avg Train Loss = 0.0018, Avg val loss = 0.0821, Time = 4.62s\n",
            "Epoch = 5, Avg Train Loss = 0.0018, Avg val loss = 0.0774, Time = 4.59s\n",
            "Epoch = 6, Avg Train Loss = 0.0017, Avg val loss = 0.0771, Time = 4.59s\n",
            "Epoch = 7, Avg Train Loss = 0.0017, Avg val loss = 0.0736, Time = 4.49s\n",
            "Epoch = 8, Avg Train Loss = 0.0016, Avg val loss = 0.0740, Time = 4.64s\n",
            "Epoch = 9, Avg Train Loss = 0.0016, Avg val loss = 0.0729, Time = 4.53s\n",
            "Epoch = 10, Avg Train Loss = 0.0016, Avg val loss = 0.0737, Time = 4.58s\n",
            "Epoch = 11, Avg Train Loss = 0.0016, Avg val loss = 0.0730, Time = 4.60s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5fd0b1ad5cf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSuperSimpleModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrain_gen_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-0e8ac51e2560>\u001b[0m in \u001b[0;36mtrain_gen_model\u001b[0;34m(model, train_samples, val_samples, epochs_count, loss_every_nsteps, lr, save_path, device_name, early_stopping)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_next_gen_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Прямой проход\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-0e8ac51e2560>\u001b[0m in \u001b[0;36mget_next_gen_batch\u001b[0;34m(samples, max_seq_len, max_char_seq_len, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchar_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchar_set\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mchar_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_char_seq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mchars\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_char_seq_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-0e8ac51e2560>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchar_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchar_set\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mchar_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_char_seq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mchars\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_char_seq_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwqxW33cifrd",
        "colab_type": "text"
      },
      "source": [
        "## Метрики\n",
        "\n",
        "Можно использовать как классические мультиклассификационнные метрики, так и метрики специально для NER.\n",
        "\n",
        "Например, число точных и частичных совпадений спанов, пропущшенных и лишних спанов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgjCy2C6JdLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_spans(labels, tokens):\n",
        "    spans = []\n",
        "    for i, label in enumerate(labels):\n",
        "        if label == 1:\n",
        "            spans.append((tokens[i].start, tokens[i].stop, \"PER\"))\n",
        "        elif label == 2:\n",
        "            spans[-1] = (spans[-1][0], tokens[i].stop, spans[-1][-1])\n",
        "    return spans\n",
        "\n",
        "\n",
        "def calc_metrics(true_labels, predicted_labels, samples):\n",
        "    one_tp = 0\n",
        "    one_fp = 0\n",
        "    one_fn = 0\n",
        "    for true, predicted in zip(true_labels, predicted_labels):\n",
        "        for l1, l2 in zip(true, predicted):\n",
        "            if l1 == 1 and l2 == 1:\n",
        "                one_tp += 1\n",
        "            elif l1 != 1 and l2 == 1:\n",
        "                one_fp += 1\n",
        "            elif l1 == 1 and l2 !=1:\n",
        "                one_fn += 1\n",
        "    if one_tp + one_fp == 0:\n",
        "        print(\"No positives!\")\n",
        "    else:\n",
        "        print(\"1 Precision: {}, 1 Recall: {}\".format(float(one_tp)/(one_tp + one_fp), float(one_tp)/(one_tp + one_fn)))\n",
        "\n",
        "    exact = 0\n",
        "    partial = 0\n",
        "    missing = 0\n",
        "    spurius = 0\n",
        "    for (true, predicted), sample in zip(zip(true_labels, predicted_labels), samples):\n",
        "        true_spans = get_spans(true, sample.tokens)\n",
        "        predicted_spans = get_spans(predicted, sample.tokens)\n",
        "        for true_span in true_spans:\n",
        "            is_missing = True\n",
        "            for predicted_span in predicted_spans:\n",
        "                if true_span == predicted_span:\n",
        "                    exact += 1\n",
        "                    is_missing = False\n",
        "                    break\n",
        "                ts = true_span[0]\n",
        "                te = true_span[1]\n",
        "                ps = predicted_span[0]\n",
        "                pe = predicted_span[1]\n",
        "                # ts te ps pe\n",
        "                # ps pe ts te\n",
        "                if ts <= te <= ps <= pe or ps <= pe <= ts <= te:\n",
        "                    continue\n",
        "                is_missing = False\n",
        "                partial += 1\n",
        "                break\n",
        "            if is_missing:\n",
        "                missing += 1\n",
        "        for predicted_span in predicted_spans:\n",
        "            is_missing = True\n",
        "            for true_span in true_spans:\n",
        "                if true_span == predicted_span:\n",
        "                    is_missing = False\n",
        "                    break\n",
        "                ts = true_span[0]\n",
        "                te = true_span[1]\n",
        "                ps = predicted_span[0]\n",
        "                pe = predicted_span[1]\n",
        "                if ts <= te <= ps <= pe or ps <= pe <= ts <= te:\n",
        "                    continue\n",
        "                is_missing = False\n",
        "                break\n",
        "            if is_missing:\n",
        "                spurius += 1\n",
        "    print(\"Exact: {}, partial: {}, missing: {}, spurius: {}\".format(exact, partial, missing, spurius))\n",
        "            \n",
        "\n",
        "\n",
        "def predict(model, samples, crf=False):\n",
        "    model.eval()\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "    all_indices = []\n",
        "    for _, (indices, batch, batch_labels) in enumerate(get_next_gen_batch(samples)):\n",
        "        if crf:\n",
        "          em, mask = model.eval_forward(batch, batch_labels)\n",
        "          plabels = model.CRF.decode(em, mask=mask)\n",
        "        else:\n",
        "          logits = model(batch)\n",
        "          plabels = logits.max(dim=2)[1]\n",
        "        # Убираем неконсистентность\n",
        "        for sample_num, sample in enumerate(plabels):\n",
        "            for word_num, label in enumerate(sample):\n",
        "                if label != 2:\n",
        "                    continue\n",
        "                if word_num == 0:\n",
        "                    plabels[sample_num][word_num] = 0\n",
        "                    continue\n",
        "                if sample[word_num - 1] == 0:\n",
        "                    plabels[sample_num][word_num] = 0\n",
        "        true_labels.extend(batch_labels)\n",
        "        predicted_labels.extend(plabels)\n",
        "        all_indices.extend(indices)\n",
        "    samples = [samples[index] for index in all_indices]\n",
        "    calc_metrics(true_labels, predicted_labels, samples)\n",
        "    show_box_markup(samples[0].text, get_spans(predicted_labels[0], samples[0].tokens), palette=palette(PER=BLUE, ORG=RED, LOC=GREEN))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM0F-KrQUX4n",
        "colab_type": "code",
        "outputId": "6f281553-81ce-4500-c165-893e481bc231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "predict(model, test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Precision: 0.6365740740740741, 1 Recall: 0.527831094049904\n",
            "Exact: 420, partial: 476, missing: 667, spurius: 267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">Акционеры \"ВымпелКома\" на внеочередном собрании досрочно изберут новый совет директоров.\r\n",
              "\r\n",
              "Акционеры ОАО \"ВымпелКом\" (торговая марка \"Билайн\") сегодня на внеочередном общем собрании, как планируется, рассмотрят вопрос о досрочном прекращении полномочий членов совета директоров и избрании его нового состава. Также планируется утвердить \"Эрнст энд Янг\" в качестве аудитора финансовой отчетности компании по US GAAP, обсудить вступление компании в Союз операторов связи LTE, рассмотреть вопрос о вознаграждении членов совета директоров.\r\n",
              "\r\n",
              "Напомним, сейчас в совет директоров \"ВымпелКома\" входят президент и генеральный директор VimpelCom Ltd. <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Александр<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Изосимов<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, главный финансовый директор VimpelCom Ltd. Хендрик ван <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Дален<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, вице-президент департамента управления активами Altimo <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Алексей Гаврилов<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, главный управляющий директор Telenor Serbia <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Къелл<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> Мортен <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Йонсен<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, главный юрисконсульт компании <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Джеффри<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Дэвид<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> Мак-Ги.\r\n",
              "\r\n",
              "Как сообщалось ранее, с 30 июня 2011г. <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">А<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>.<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Изосимов<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> должен покинуть компанию.\r\n",
              "\r\n",
              "ОАО \"ВымпелКом\" - российская компания, предоставляющая услуги сотовой и фиксированной связи, проводного и беспроводного высокоскоростного доступа в интернет физическим и юридическим лицам под торговой маркой \"Билайн\". Компания ведет свою деятельность на всей территории России, а также в <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Киргизии<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, Казахстане, на Украине, в Таджикистане, Узбекистане, Армении, Грузии, Камбодже и Вьетнаме. Штаб-квартира организации расположена в Москве.\r\n",
              "\r\n",
              "</div>"
            ],
            "text/plain": [
              "BoxMarkup('Акционеры \"ВымпелКома\" на внеочередном собрании досрочно изберут новый совет директоров.\\r\\n\\r\\nАкционеры ОАО \"ВымпелКом\" (торговая марка \"Билайн\") сегодня на внеочередном общем собрании, как планируется, рассмотрят вопрос о досрочном прекращении полномочий членов совета директоров и избрании его нового состава. Также планируется утвердить \"Эрнст энд Янг\" в качестве аудитора финансовой отчетности компании по US GAAP, обсудить вступление компании в Союз операторов связи LTE, рассмотреть вопрос о вознаграждении членов совета директоров.\\r\\n\\r\\nНапомним, сейчас в совет директоров \"ВымпелКома\" входят президент и генеральный директор VimpelCom Ltd. Александр Изосимов, главный финансовый директор VimpelCom Ltd. Хендрик ван Дален, вице-президент департамента управления активами Altimo Алексей Гаврилов, главный управляющий директор Telenor Serbia Къелл Мортен Йонсен, главный юрисконсульт компании Джеффри Дэвид Мак-Ги.\\r\\n\\r\\nКак сообщалось ранее, с 30 июня 2011г. А.Изосимов должен покинуть компанию.\\r\\n\\r\\nОАО \"ВымпелКом\" - российская компания, предоставляющая услуги сотовой и фиксированной связи, проводного и беспроводного высокоскоростного доступа в интернет физическим и юридическим лицам под торговой маркой \"Билайн\". Компания ведет свою деятельность на всей территории России, а также в Киргизии, Казахстане, на Украине, в Таджикистане, Узбекистане, Армении, Грузии, Камбодже и Вьетнаме. Штаб-квартира организации расположена в Москве.\\r\\n\\r\\n',\n",
              "          [Span(644, 653, 'PER'),\n",
              "           Span(654, 662, 'PER'),\n",
              "           Span(719, 724, 'PER'),\n",
              "           Span(781, 797, 'PER'),\n",
              "           Span(843, 848, 'PER'),\n",
              "           Span(856, 862, 'PER'),\n",
              "           Span(894, 901, 'PER'),\n",
              "           Span(902, 907, 'PER'),\n",
              "           Span(958, 959, 'PER'),\n",
              "           Span(960, 968, 'PER'),\n",
              "           Span(1286, 1294, 'PER')])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qtZdRbsi7e8",
        "colab_type": "text"
      },
      "source": [
        "## Контекстная модель: LSTM над конкатенацией"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aJ4m4FIMKB7",
        "colab_type": "code",
        "outputId": "48188b0a-d754-4862-bc38-5121a29ae776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        }
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class LstmModel(nn.Module):\n",
        "    def __init__(self, char_set_size, char_embedding_dim=4, classes_count=3, lstm_embedding_dim=8, char_max_seq_len=40):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embeddings_layer = nn.Embedding(char_set_size, char_embedding_dim)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.lstm_layer = nn.LSTM(char_embedding_dim * char_max_seq_len, lstm_embedding_dim // 2, batch_first=True, bidirectional=True)\n",
        "        self.out_layer = nn.Linear(lstm_embedding_dim, classes_count)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size = inputs.size(0)\n",
        "        seq_len = inputs.size(1)\n",
        "        projections = self.embeddings_layer.forward(inputs)\n",
        "        projections = projections.reshape(projections.size(0), projections.size(1), -1)\n",
        "        output, _= self.lstm_layer(projections)\n",
        "        output = self.dropout(output)\n",
        "        output = self.out_layer.forward(output)\n",
        "        return output\n",
        "\n",
        "model = LstmModel(len(char_set))\n",
        "train_gen_model(model, train, val, epochs_count=50, early_stopping=False, lr=0.05, batch_size=70)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable params: 6011\n",
            "Epoch = 0, Avg Train Loss = 0.0078, Avg val loss = 0.5260, Time = 5.75s\n",
            "Epoch = 1, Avg Train Loss = 0.0042, Avg val loss = 0.3311, Time = 5.70s\n",
            "Epoch = 2, Avg Train Loss = 0.0030, Avg val loss = 0.2592, Time = 5.82s\n",
            "Epoch = 3, Avg Train Loss = 0.0026, Avg val loss = 0.2312, Time = 5.75s\n",
            "Epoch = 4, Avg Train Loss = 0.0024, Avg val loss = 0.2170, Time = 5.75s\n",
            "Epoch = 5, Avg Train Loss = 0.0023, Avg val loss = 0.2081, Time = 5.67s\n",
            "Epoch = 6, Avg Train Loss = 0.0022, Avg val loss = 0.2029, Time = 5.89s\n",
            "Epoch = 7, Avg Train Loss = 0.0022, Avg val loss = 0.1962, Time = 5.73s\n",
            "Epoch = 8, Avg Train Loss = 0.0021, Avg val loss = 0.1952, Time = 5.71s\n",
            "Epoch = 9, Avg Train Loss = 0.0021, Avg val loss = 0.1952, Time = 5.79s\n",
            "Epoch = 10, Avg Train Loss = 0.0021, Avg val loss = 0.2023, Time = 5.78s\n",
            "Epoch = 11, Avg Train Loss = 0.0021, Avg val loss = 0.1940, Time = 5.68s\n",
            "Epoch = 12, Avg Train Loss = 0.0020, Avg val loss = 0.1901, Time = 5.82s\n",
            "Epoch = 13, Avg Train Loss = 0.0020, Avg val loss = 0.1898, Time = 5.77s\n",
            "Epoch = 14, Avg Train Loss = 0.0020, Avg val loss = 0.1877, Time = 5.75s\n",
            "Epoch = 15, Avg Train Loss = 0.0020, Avg val loss = 0.1895, Time = 5.81s\n",
            "Epoch = 16, Avg Train Loss = 0.0020, Avg val loss = 0.1872, Time = 5.78s\n",
            "Epoch = 17, Avg Train Loss = 0.0020, Avg val loss = 0.1858, Time = 5.81s\n",
            "Epoch = 18, Avg Train Loss = 0.0020, Avg val loss = 0.1830, Time = 5.70s\n",
            "Epoch = 19, Avg Train Loss = 0.0020, Avg val loss = 0.1863, Time = 5.73s\n",
            "Epoch = 20, Avg Train Loss = 0.0020, Avg val loss = 0.1868, Time = 5.83s\n",
            "Epoch = 21, Avg Train Loss = 0.0020, Avg val loss = 0.1830, Time = 5.73s\n",
            "Epoch = 22, Avg Train Loss = 0.0020, Avg val loss = 0.1837, Time = 5.72s\n",
            "Epoch = 23, Avg Train Loss = 0.0020, Avg val loss = 0.1854, Time = 5.74s\n",
            "Epoch = 24, Avg Train Loss = 0.0019, Avg val loss = 0.1847, Time = 5.73s\n",
            "Epoch = 25, Avg Train Loss = 0.0020, Avg val loss = 0.1813, Time = 5.80s\n",
            "Epoch = 26, Avg Train Loss = 0.0019, Avg val loss = 0.1813, Time = 5.75s\n",
            "Epoch = 27, Avg Train Loss = 0.0019, Avg val loss = 0.1830, Time = 5.73s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-9cd47c56f386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLstmModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrain_gen_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-d8e0cec34937>\u001b[0m in \u001b[0;36mtrain_gen_model\u001b[0;34m(model, train_samples, val_samples, epochs_count, loss_every_nsteps, lr, save_path, device_name, early_stopping, batch_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Подсчёт ошибки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Подсчёт градиентов dL/dw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Градиентный спуск или его модификации (в данном случае Adam)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Зануление градиентов, чтобы их спокойно менять на следующей итерации\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifCu8FlKHvBT",
        "colab_type": "code",
        "outputId": "d11532ef-e8cf-461b-cc25-24f2f9d70007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "predict(model, test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No positives!\n",
            "Exact: 0, partial: 0, missing: 1563, spurius: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">Новым директором по качеству АВТОВАЗа назначили Л.Фофана\r\n",
              "\r\n",
              "Бывший директор программы легких грузовых автомобилей Лоран Фофана сменил Паскаля Фелтена на посту директора по качеству ОАО \"АВТОВАЗ\", сообщили в пресс-службе компании. Приказ о назначении Л.Фофана подписал президент АВТОВАЗа Игорь Комаров.\r\n",
              "\r\n",
              "Возглавлявший ранее дирекцию по качеству П.Фелтен завершает свою работу на АВТОВАЗе в связи с истечением срока контракта. Он возглавит предприятие по производству крупногабаритных автомобилей в компании Renault.\r\n",
              "\r\n",
              "Л.Фофана с 1994г. работал в Renault. С 1994г. по 2000г. был заместителем директора по производству силовых агрегатов; в 2000-2005гг. занимал пост директора проекта двигателей (занимался улучшением качества существующих двигателей в сотрудничестве со службами проектирования и производства, а также работал с поставщиками). В 2005-2011гг. стал директором программы легких грузовых автомобилей.\r\n",
              "\r\n",
              "ОАО \"АВТОВАЗ\" (Тольятти) зарегистрировано 5 января 1993г. Автоконцерн выпускает автомобили семейств Lada Priora, Kalina, Samara, а также \"классику\".\r\n",
              "\r\n",
              "В настоящее время доли между основными акционерами АВТОВАЗа распределяются следующим образом: ГК \"Ростехнологии\" - 25%, ИК \"Тройка Диалог\" - 25% и Renault - 25%.\r\n",
              "\r\n",
              "</div>"
            ],
            "text/plain": [
              "BoxMarkup('Новым директором по качеству АВТОВАЗа назначили Л.Фофана\\r\\n\\r\\nБывший директор программы легких грузовых автомобилей Лоран Фофана сменил Паскаля Фелтена на посту директора по качеству ОАО \"АВТОВАЗ\", сообщили в пресс-службе компании. Приказ о назначении Л.Фофана подписал президент АВТОВАЗа Игорь Комаров.\\r\\n\\r\\nВозглавлявший ранее дирекцию по качеству П.Фелтен завершает свою работу на АВТОВАЗе в связи с истечением срока контракта. Он возглавит предприятие по производству крупногабаритных автомобилей в компании Renault.\\r\\n\\r\\nЛ.Фофана с 1994г. работал в Renault. С 1994г. по 2000г. был заместителем директора по производству силовых агрегатов; в 2000-2005гг. занимал пост директора проекта двигателей (занимался улучшением качества существующих двигателей в сотрудничестве со службами проектирования и производства, а также работал с поставщиками). В 2005-2011гг. стал директором программы легких грузовых автомобилей.\\r\\n\\r\\nОАО \"АВТОВАЗ\" (Тольятти) зарегистрировано 5 января 1993г. Автоконцерн выпускает автомобили семейств Lada Priora, Kalina, Samara, а также \"классику\".\\r\\n\\r\\nВ настоящее время доли между основными акционерами АВТОВАЗа распределяются следующим образом: ГК \"Ростехнологии\" - 25%, ИК \"Тройка Диалог\" - 25% и Renault - 25%.\\r\\n\\r\\n',\n",
              "          [])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olMklIKEjCR7",
        "colab_type": "text"
      },
      "source": [
        "## Контекстная модель: LSTM над CharFF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTgm-B_eldMm",
        "colab_type": "text"
      },
      "source": [
        "## Задание 0\n",
        "Сделайте полносвзяный слой с активацией над конкатенацией символьных эмбедов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2ujztBqZYXT",
        "colab_type": "code",
        "outputId": "b73db25f-84e9-485c-a73a-e93534fa8826",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class CharFFLstmModel(nn.Module):\n",
        "    def __init__(self, char_set_size, char_embedding_dim=4, classes_count=3, word_embedding_dim=16, lstm_embedding_dim=16, char_max_seq_len=40):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embeddings_layer = nn.Embedding(char_set_size, char_embedding_dim)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.char_activation = nn.Linear(char_embedding_dim * char_max_seq_len, word_embedding_dim)\n",
        "        self.lstm_layer = nn.LSTM(word_embedding_dim, lstm_embedding_dim // 2, batch_first=True, bidirectional=True)\n",
        "        self.out_layer = nn.Linear(lstm_embedding_dim, classes_count)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size = inputs.size(0)\n",
        "        seq_len = inputs.size(1)\n",
        "        projections = self.embeddings_layer.forward(inputs)\n",
        "        projections = projections.reshape(projections.size(0), projections.size(1), -1)\n",
        "        projections = self.relu(self.char_activation(projections))\n",
        "        projections = self.dropout(projections)\n",
        "        output, _= self.lstm_layer(projections)\n",
        "        output = self.dropout(output)\n",
        "        output = self.out_layer.forward(output)\n",
        "        return output\n",
        "\n",
        "model = CharFFLstmModel(len(char_set))\n",
        "train_gen_model(model, train, val, epochs_count=50, early_stopping=False, lr=0.02)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable params: 4963\n",
            "Epoch = 0, Avg Train Loss = 0.0072, Avg val loss = 0.2086, Time = 4.89s\n",
            "Epoch = 1, Avg Train Loss = 0.0049, Avg val loss = 0.1947, Time = 4.94s\n",
            "Epoch = 2, Avg Train Loss = 0.0048, Avg val loss = 0.1906, Time = 5.18s\n",
            "Epoch = 3, Avg Train Loss = 0.0048, Avg val loss = 0.1893, Time = 5.01s\n",
            "Epoch = 4, Avg Train Loss = 0.0047, Avg val loss = 0.1878, Time = 4.97s\n",
            "Epoch = 5, Avg Train Loss = 0.0046, Avg val loss = 0.1881, Time = 5.05s\n",
            "Epoch = 6, Avg Train Loss = 0.0046, Avg val loss = 0.1739, Time = 5.19s\n",
            "Epoch = 7, Avg Train Loss = 0.0044, Avg val loss = 0.1515, Time = 5.21s\n",
            "Epoch = 8, Avg Train Loss = 0.0038, Avg val loss = 0.1266, Time = 5.08s\n",
            "Epoch = 9, Avg Train Loss = 0.0033, Avg val loss = 0.1200, Time = 5.12s\n",
            "Epoch = 10, Avg Train Loss = 0.0029, Avg val loss = 0.1040, Time = 4.87s\n",
            "Epoch = 11, Avg Train Loss = 0.0026, Avg val loss = 0.0993, Time = 4.83s\n",
            "Epoch = 12, Avg Train Loss = 0.0024, Avg val loss = 0.1168, Time = 4.87s\n",
            "Epoch = 13, Avg Train Loss = 0.0023, Avg val loss = 0.1422, Time = 4.90s\n",
            "Epoch = 14, Avg Train Loss = 0.0021, Avg val loss = 0.1313, Time = 4.88s\n",
            "Epoch = 15, Avg Train Loss = 0.0020, Avg val loss = 0.1338, Time = 4.88s\n",
            "Epoch = 16, Avg Train Loss = 0.0019, Avg val loss = 0.1436, Time = 4.79s\n",
            "Epoch = 17, Avg Train Loss = 0.0018, Avg val loss = 0.1504, Time = 4.85s\n",
            "Epoch = 18, Avg Train Loss = 0.0018, Avg val loss = 0.1499, Time = 5.05s\n",
            "Epoch = 19, Avg Train Loss = 0.0017, Avg val loss = 0.1193, Time = 5.07s\n",
            "Epoch = 20, Avg Train Loss = 0.0017, Avg val loss = 0.1411, Time = 4.92s\n",
            "Epoch = 21, Avg Train Loss = 0.0016, Avg val loss = 0.1299, Time = 4.90s\n",
            "Epoch = 22, Avg Train Loss = 0.0016, Avg val loss = 0.1209, Time = 4.89s\n",
            "Epoch = 23, Avg Train Loss = 0.0016, Avg val loss = 0.1485, Time = 4.87s\n",
            "Epoch = 24, Avg Train Loss = 0.0015, Avg val loss = 0.1445, Time = 4.88s\n",
            "Epoch = 25, Avg Train Loss = 0.0015, Avg val loss = 0.1407, Time = 4.94s\n",
            "Epoch = 26, Avg Train Loss = 0.0014, Avg val loss = 0.1569, Time = 4.89s\n",
            "Epoch = 27, Avg Train Loss = 0.0014, Avg val loss = 0.1495, Time = 5.02s\n",
            "Epoch = 28, Avg Train Loss = 0.0014, Avg val loss = 0.1487, Time = 4.92s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-593a3530af4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCharFFLstmModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrain_gen_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-b0529fa01354>\u001b[0m in \u001b[0;36mtrain_gen_model\u001b[0;34m(model, train_samples, val_samples, epochs_count, loss_every_nsteps, lr, save_path, device_name, early_stopping, batch_size)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_next_gen_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Прямой проход\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-b0529fa01354>\u001b[0m in \u001b[0;36mget_next_gen_batch\u001b[0;34m(samples, max_seq_len, max_char_seq_len, batch_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchar_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchar_set\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mchar_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_char_seq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mchars\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_char_seq_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-b0529fa01354>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                 \u001b[0mchars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchar_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchar_set\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mchar_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_char_seq_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m                 \u001b[0mchars\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_char_seq_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2zXKkvFbeQo",
        "colab_type": "code",
        "outputId": "25883f10-0384-4aec-c166-be9ef055ccdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "predict(model, test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Precision: 0.8921568627450981, 1 Recall: 0.06066666666666667\n",
            "Exact: 62, partial: 40, missing: 1398, spurius: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">Медведев пообещал новые отставки в связи с терактом в \"Домодедово\"\r\n",
              "\r\n",
              "Президент РФ Дмитрий Медведев заявил на совещании по безопасности на транспорте, что отставки чиновников в связи с терактом в \"Домодедово\" будут продолжены. Об этом 26 января сообщает РИА Новости.\r\n",
              "\r\n",
              "Глава МВД РФ Рашид Нургалиев на совещании объявил об увольнении начальника линейного отдела внутренних дел \"Домодедово\" и двух его заместителей. Сам Медведев сказал, что подписал указ об отставке начальника управления на транспорте МВД по Центральному федеральному округу <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Андрея Алексеева<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>. После этого Медведев заявил: \"На этом все закончиться не должно, это как бы верхние начальники\".\r\n",
              "\r\n",
              "В ходе совещания Медведев напомнил, что в марте 2010 года подписал указ по обеспечению безопасности на транспорте. \"Я хотел бы, чтобы мне сейчас доложили, как идет работа по указу, что уже сделано и в чем проблема\", - сказал президент.\r\n",
              "\r\n",
              "Как сообщалось ранее, в начале совещания Медведев поручил Нургалиеву \"тряхнуть\" транспортную милицию с целью обеспечения безопасности.\r\n",
              "\r\n",
              "Взрыв в зоне прилета \"Домодедово\" произошел в 16:30 24 января. Бомбу подорвал террорист-смертник. Погибли 35 человек, более ста человек получили ранения. Возбуждены два уголовных дела - непосредственно о теракте и о необеспечении безопасности в аэропорту. 26 января в Москве и Московской области объявлен траур в память о жертвах теракта. </div>"
            ],
            "text/plain": [
              "BoxMarkup('Медведев пообещал новые отставки в связи с терактом в \"Домодедово\"\\r\\n\\r\\nПрезидент РФ Дмитрий Медведев заявил на совещании по безопасности на транспорте, что отставки чиновников в связи с терактом в \"Домодедово\" будут продолжены. Об этом 26 января сообщает РИА Новости.\\r\\n\\r\\nГлава МВД РФ Рашид Нургалиев на совещании объявил об увольнении начальника линейного отдела внутренних дел \"Домодедово\" и двух его заместителей. Сам Медведев сказал, что подписал указ об отставке начальника управления на транспорте МВД по Центральному федеральному округу Андрея Алексеева. После этого Медведев заявил: \"На этом все закончиться не должно, это как бы верхние начальники\".\\r\\n\\r\\nВ ходе совещания Медведев напомнил, что в марте 2010 года подписал указ по обеспечению безопасности на транспорте. \"Я хотел бы, чтобы мне сейчас доложили, как идет работа по указу, что уже сделано и в чем проблема\", - сказал президент.\\r\\n\\r\\nКак сообщалось ранее, в начале совещания Медведев поручил Нургалиеву \"тряхнуть\" транспортную милицию с целью обеспечения безопасности.\\r\\n\\r\\nВзрыв в зоне прилета \"Домодедово\" произошел в 16:30 24 января. Бомбу подорвал террорист-смертник. Погибли 35 человек, более ста человек получили ранения. Возбуждены два уголовных дела - непосредственно о теракте и о необеспечении безопасности в аэропорту. 26 января в Москве и Московской области объявлен траур в память о жертвах теракта. ',\n",
              "          [Span(542, 558, 'PER')])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAkoasnvgogl",
        "colab_type": "text"
      },
      "source": [
        "## Задание 1.1\n",
        "Сделайте то же самое, но с bidirectional LSTM на уровне символов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7d27C6m4NgF",
        "colab_type": "code",
        "outputId": "8e24b395-ebf1-4ce9-9f94-8d6236e94ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class CharLstmModel(nn.Module):\n",
        "    def __init__(self, char_set_size, char_embedding_dim=4, classes_count=3, word_embedding_dim=16, lstm_embedding_dim=16, char_max_seq_len=40):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.char_embedding_dim = char_embedding_dim\n",
        "        self.embeddings_layer = nn.Embedding(char_set_size, char_embedding_dim)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        # self.char_activation = nn.Linear(char_embedding_dim * char_max_seq_len, word_embedding_dim)\n",
        "        self.lstm_layer = nn.LSTM(char_embedding_dim, lstm_embedding_dim // 2, batch_first=True, bidirectional=True)\n",
        "        self.out_layer = nn.Linear(char_max_seq_len*lstm_embedding_dim, classes_count)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size = inputs.size(0)\n",
        "        seq_len = inputs.size(1)\n",
        "        projections = self.embeddings_layer.forward(inputs)\n",
        "        wc = projections.size(1)\n",
        "        projections = projections.reshape(projections.size(0), -1, self.char_embedding_dim)\n",
        "        # print(projections.shape)\n",
        "        # projections = self.relu(self.char_activation(projections))\n",
        "        # projections = self.dropout(projections)\n",
        "        output, _= self.lstm_layer(projections)\n",
        "        output = self.dropout(output)\n",
        "        # print(output.shape)\n",
        "        output = output.reshape(output.size(0), wc, -1)\n",
        "        # print(output.shape)\n",
        "        output = self.out_layer.forward(output)\n",
        "        return output\n",
        "\n",
        "model = CharLstmModel(len(char_set))\n",
        "train_gen_model(model, train, val, epochs_count=25, early_stopping=False, lr=0.02)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable params: 3491\n",
            "Epoch = 0, Avg Train Loss = 0.0056, Avg val loss = 0.1830, Time = 27.46s\n",
            "Epoch = 1, Avg Train Loss = 0.0041, Avg val loss = 0.1535, Time = 27.61s\n",
            "Epoch = 2, Avg Train Loss = 0.0033, Avg val loss = 0.1213, Time = 27.30s\n",
            "Epoch = 3, Avg Train Loss = 0.0027, Avg val loss = 0.0963, Time = 27.31s\n",
            "Epoch = 4, Avg Train Loss = 0.0022, Avg val loss = 0.0799, Time = 27.89s\n",
            "Epoch = 5, Avg Train Loss = 0.0019, Avg val loss = 0.0800, Time = 27.77s\n",
            "Epoch = 6, Avg Train Loss = 0.0018, Avg val loss = 0.0723, Time = 27.73s\n",
            "Epoch = 7, Avg Train Loss = 0.0016, Avg val loss = 0.0683, Time = 27.94s\n",
            "Epoch = 8, Avg Train Loss = 0.0016, Avg val loss = 0.0674, Time = 27.58s\n",
            "Epoch = 9, Avg Train Loss = 0.0015, Avg val loss = 0.0610, Time = 28.43s\n",
            "Epoch = 10, Avg Train Loss = 0.0015, Avg val loss = 0.0615, Time = 27.92s\n",
            "Epoch = 11, Avg Train Loss = 0.0014, Avg val loss = 0.0600, Time = 27.86s\n",
            "Epoch = 12, Avg Train Loss = 0.0014, Avg val loss = 0.0606, Time = 28.17s\n",
            "Epoch = 13, Avg Train Loss = 0.0014, Avg val loss = 0.0573, Time = 27.41s\n",
            "Epoch = 14, Avg Train Loss = 0.0013, Avg val loss = 0.0568, Time = 28.11s\n",
            "Epoch = 15, Avg Train Loss = 0.0013, Avg val loss = 0.0547, Time = 27.57s\n",
            "Epoch = 16, Avg Train Loss = 0.0013, Avg val loss = 0.0550, Time = 27.19s\n",
            "Epoch = 17, Avg Train Loss = 0.0013, Avg val loss = 0.0542, Time = 27.34s\n",
            "Epoch = 18, Avg Train Loss = 0.0012, Avg val loss = 0.0544, Time = 27.48s\n",
            "Epoch = 19, Avg Train Loss = 0.0012, Avg val loss = 0.0536, Time = 27.18s\n",
            "Epoch = 20, Avg Train Loss = 0.0012, Avg val loss = 0.0526, Time = 27.40s\n",
            "Epoch = 21, Avg Train Loss = 0.0011, Avg val loss = 0.0524, Time = 28.29s\n",
            "Epoch = 22, Avg Train Loss = 0.0011, Avg val loss = 0.0537, Time = 28.11s\n",
            "Epoch = 23, Avg Train Loss = 0.0012, Avg val loss = 0.0513, Time = 28.09s\n",
            "Epoch = 24, Avg Train Loss = 0.0011, Avg val loss = 0.0502, Time = 27.94s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfFQ_TB7_pGs",
        "colab_type": "code",
        "outputId": "eeaadde5-ebac-4209-9410-de9927569c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "predict(model, test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Precision: 0.8161512027491409, 1 Recall: 0.6333333333333333\n",
            "Exact: 683, partial: 319, missing: 498, spurius: 101\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">С.Собянин<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> уволил начальника московского здравоохранения\r\n",
              "\r\n",
              "<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Мэр<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> Москвы <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Сергей Собянин<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> сегодня провел ряд перестановок в столичном руководстве. Интересно, что кадровые решения коснулись не только чиновников, назначенных при прежнем градоначальнике <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Юрии Лужкове<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, но и членов новой команды.\r\n",
              "\r\n",
              "<span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">С.Собянин<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> сообщил сегодня на заседании правительства столицы об отставке главы Департамента здравоохранения <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Сергея Полякова<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> в связи с переходом на новую должность. На какую работу ушел <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">С.Поляков<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, пока не сообщается. Новым руководителем Департамента здравоохранения Москвы назначен <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Леонид<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Михайлович Печатников<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>. Представляя нового главу департамента чиновникам, мэр отметил, что <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Л.Печатников<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> - \"профессор, с 2004г. и по настоящее время работает руководителем Европейского медицинского центра и возглавляет подразделение, связанное с подготовкой к Олимпийским играм в Сочи\".\r\n",
              "\r\n",
              "\"Надеюсь, с его приходом департамент заработает по-новому, с новой энергией\", - добавил мэр. Он поручил <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Л.Печатникову<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> сделать в своей работе упор на развитие детской медицины, \"у которой больше всего проблем\" и разобраться с тендерами на закупку лекарств и медицинского оборудования.\r\n",
              "\r\n",
              "Напомним, <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">С.Собянин<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> назначил ранее занимавшего должность первого заместителя руководителя <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Сергея Полякова<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> главой Департамента здравоохранения Москвы 26 октября, он сменил на этом посту <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Андрея Сельцовского<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>.\r\n",
              "\r\n",
              "Отметим, что 3 декабря <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">С.Собянин<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> вывел Департамент здравоохранения из сфер курируемых заместителем мэра <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Людмилой<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> Швецовой и назначил <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Ольгу<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> Голодец своим новым заместителем, контролирующим сферы образования и здравоохранения.\r\n",
              "\r\n",
              "Среди других сегодняшних кадровых решений мэра - увольнение зампреда Контрольного комитета Москвы <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Вячеслава Урюпина<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>. Он освобожден от должности \"по собственной инициативе\".\r\n",
              "\r\n",
              "На должность заместителя руководителя Департамента транспорта и связи Москвы назначен <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Юрий Мазикин<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>. Заместителями руководителя Департамента имущества Москвы утверждены <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Сергей Шогуров<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Вероника<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> Бобровская и <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Валерий Ануприенко<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>. Назначены четыре заместителя руководителя Департамента земельных ресурсов Москвы: <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Татьяна Найденова<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Полина Афоничева<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>, <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Ирина Ткачева<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> и <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Людмила Останкова<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>. Кроме того, на должность заместителя префекта Западного административного округа столицы назначен <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Владимир Говердовский<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>.\r\n",
              "\r\n",
              "Пост замглавы аппарата мэра и правительства Москвы и начальника управления референтуры мэрии занял <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Павел Чинилин<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>.\r\n",
              "\r\n",
              "</div>"
            ],
            "text/plain": [
              "BoxMarkup('С.Собянин уволил начальника московского здравоохранения\\r\\n\\r\\nМэр Москвы Сергей Собянин сегодня провел ряд перестановок в столичном руководстве. Интересно, что кадровые решения коснулись не только чиновников, назначенных при прежнем градоначальнике Юрии Лужкове, но и членов новой команды.\\r\\n\\r\\nС.Собянин сообщил сегодня на заседании правительства столицы об отставке главы Департамента здравоохранения Сергея Полякова в связи с переходом на новую должность. На какую работу ушел С.Поляков, пока не сообщается. Новым руководителем Департамента здравоохранения Москвы назначен Леонид Михайлович Печатников. Представляя нового главу департамента чиновникам, мэр отметил, что Л.Печатников - \"профессор, с 2004г. и по настоящее время работает руководителем Европейского медицинского центра и возглавляет подразделение, связанное с подготовкой к Олимпийским играм в Сочи\".\\r\\n\\r\\n\"Надеюсь, с его приходом департамент заработает по-новому, с новой энергией\", - добавил мэр. Он поручил Л.Печатникову сделать в своей работе упор на развитие детской медицины, \"у которой больше всего проблем\" и разобраться с тендерами на закупку лекарств и медицинского оборудования.\\r\\n\\r\\nНапомним, С.Собянин назначил ранее занимавшего должность первого заместителя руководителя Сергея Полякова главой Департамента здравоохранения Москвы 26 октября, он сменил на этом посту Андрея Сельцовского.\\r\\n\\r\\nОтметим, что 3 декабря С.Собянин вывел Департамент здравоохранения из сфер курируемых заместителем мэра Людмилой Швецовой и назначил Ольгу Голодец своим новым заместителем, контролирующим сферы образования и здравоохранения.\\r\\n\\r\\nСреди других сегодняшних кадровых решений мэра - увольнение зампреда Контрольного комитета Москвы Вячеслава Урюпина. Он освобожден от должности \"по собственной инициативе\".\\r\\n\\r\\nНа должность заместителя руководителя Департамента транспорта и связи Москвы назначен Юрий Мазикин. Заместителями руководителя Департамента имущества Москвы утверждены Сергей Шогуров, Вероника Бобровская и Валерий Ануприенко. Назначены четыре заместителя руководителя Департамента земельных ресурсов Москвы: Татьяна Найденова, Полина Афоничева, Ирина Ткачева и Людмила Останкова. Кроме того, на должность заместителя префекта Западного административного округа столицы назначен Владимир Говердовский.\\r\\n\\r\\nПост замглавы аппарата мэра и правительства Москвы и начальника управления референтуры мэрии занял Павел Чинилин.\\r\\n\\r\\n',\n",
              "          [Span(0, 9, 'PER'),\n",
              "           Span(59, 62, 'PER'),\n",
              "           Span(70, 84, 'PER'),\n",
              "           Span(246, 258, 'PER'),\n",
              "           Span(290, 299, 'PER'),\n",
              "           Span(398, 413, 'PER'),\n",
              "           Span(475, 484, 'PER'),\n",
              "           Span(571, 577, 'PER'),\n",
              "           Span(578, 599, 'PER'),\n",
              "           Span(668, 680, 'PER'),\n",
              "           Span(970, 983, 'PER'),\n",
              "           Span(1163, 1172, 'PER'),\n",
              "           Span(1243, 1258, 'PER'),\n",
              "           Span(1338, 1357, 'PER'),\n",
              "           Span(1385, 1394, 'PER'),\n",
              "           Span(1466, 1474, 'PER'),\n",
              "           Span(1495, 1500, 'PER'),\n",
              "           Span(1688, 1705, 'PER'),\n",
              "           Span(1852, 1864, 'PER'),\n",
              "           Span(1934, 1948, 'PER'),\n",
              "           Span(1950, 1958, 'PER'),\n",
              "           Span(1972, 1990, 'PER'),\n",
              "           Span(2074, 2091, 'PER'),\n",
              "           Span(2093, 2109, 'PER'),\n",
              "           Span(2111, 2124, 'PER'),\n",
              "           Span(2127, 2144, 'PER'),\n",
              "           Span(2244, 2265, 'PER'),\n",
              "           Span(2369, 2382, 'PER')])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeEj6drggzhK",
        "colab_type": "text"
      },
      "source": [
        "## Задание 1.2\n",
        "Сделайте то же самое, но со свёртками на уровне символов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIQ_0obe5RYs",
        "colab_type": "code",
        "outputId": "db32bf27-70b0-44ae-cd65-04d2fc6247b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class CharCNNBiLstmModel(nn.Module):\n",
        "    def __init__(self, char_set_size, char_embedding_dim=4, classes_count=3, word_embedding_dim=16, lstm_embedding_dim=16, char_max_seq_len=40):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.char_embedding_dim = char_embedding_dim\n",
        "        self.embeddings_layer = nn.Embedding(char_set_size, char_embedding_dim)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.char_activation = nn.Conv2d(1, word_embedding_dim, kernel_size=(1, char_embedding_dim), padding=1)\n",
        "        self.lstm_layer = nn.LSTM(48, lstm_embedding_dim // 2, batch_first=True, bidirectional=True)\n",
        "        self.out_layer = nn.Linear(lstm_embedding_dim, classes_count)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        batch_size = inputs.size(0)\n",
        "        seq_len = inputs.size(1)\n",
        "        projections = self.embeddings_layer.forward(inputs)\n",
        "        bs = projections.size(0)\n",
        "        wc = projections.size(1)\n",
        "        # projections = projections.reshape(projections.size(0), 1, -1, self.char_embedding_dim)\n",
        "        projections = projections.unsqueeze(2)\n",
        "        # print(projections.shape)\n",
        "        projections = projections.reshape(bs * wc, 1, 40, -1)\n",
        "        # print(projections.shape)\n",
        "        # projections = self.relu(self.char_activation(projections))\n",
        "        # projections = self.dropout(projections)\n",
        "        projections = self.char_activation(projections)\n",
        "        # print(projections.shape)\n",
        "        projections, _ = torch.max(projections, dim=2)\n",
        "        # print(projections.shape)\n",
        "        output = projections.reshape(bs, wc, -1)\n",
        "        # print(output.shape)\n",
        "        output, _= self.lstm_layer(output)\n",
        "        output = self.dropout(output)\n",
        "        # print(output.shape)\n",
        "        output = self.out_layer.forward(output)\n",
        "        return output\n",
        "\n",
        "model = CharCNNBiLstmModel(len(char_set))\n",
        "train_gen_model(model, train, val, epochs_count=25, early_stopping=False, lr=0.02)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable params: 4515\n",
            "Epoch = 0, Avg Train Loss = 0.0078, Avg val loss = 0.2043, Time = 6.12s\n",
            "Epoch = 1, Avg Train Loss = 0.0047, Avg val loss = 0.1685, Time = 6.12s\n",
            "Epoch = 2, Avg Train Loss = 0.0044, Avg val loss = 0.1609, Time = 6.10s\n",
            "Epoch = 3, Avg Train Loss = 0.0040, Avg val loss = 0.1464, Time = 6.12s\n",
            "Epoch = 4, Avg Train Loss = 0.0033, Avg val loss = 0.1095, Time = 6.09s\n",
            "Epoch = 5, Avg Train Loss = 0.0026, Avg val loss = 0.0948, Time = 6.06s\n",
            "Epoch = 6, Avg Train Loss = 0.0024, Avg val loss = 0.0909, Time = 6.14s\n",
            "Epoch = 7, Avg Train Loss = 0.0023, Avg val loss = 0.0866, Time = 6.11s\n",
            "Epoch = 8, Avg Train Loss = 0.0022, Avg val loss = 0.0865, Time = 6.04s\n",
            "Epoch = 9, Avg Train Loss = 0.0022, Avg val loss = 0.0920, Time = 6.11s\n",
            "Epoch = 10, Avg Train Loss = 0.0021, Avg val loss = 0.0828, Time = 6.18s\n",
            "Epoch = 11, Avg Train Loss = 0.0019, Avg val loss = 0.0733, Time = 6.08s\n",
            "Epoch = 12, Avg Train Loss = 0.0018, Avg val loss = 0.0634, Time = 6.11s\n",
            "Epoch = 13, Avg Train Loss = 0.0016, Avg val loss = 0.0603, Time = 6.11s\n",
            "Epoch = 14, Avg Train Loss = 0.0016, Avg val loss = 0.0616, Time = 6.11s\n",
            "Epoch = 15, Avg Train Loss = 0.0015, Avg val loss = 0.0555, Time = 6.08s\n",
            "Epoch = 16, Avg Train Loss = 0.0015, Avg val loss = 0.0524, Time = 6.16s\n",
            "Epoch = 17, Avg Train Loss = 0.0014, Avg val loss = 0.0505, Time = 6.11s\n",
            "Epoch = 18, Avg Train Loss = 0.0014, Avg val loss = 0.0492, Time = 6.10s\n",
            "Epoch = 19, Avg Train Loss = 0.0014, Avg val loss = 0.0484, Time = 6.11s\n",
            "Epoch = 20, Avg Train Loss = 0.0013, Avg val loss = 0.0476, Time = 6.08s\n",
            "Epoch = 21, Avg Train Loss = 0.0013, Avg val loss = 0.0441, Time = 6.04s\n",
            "Epoch = 22, Avg Train Loss = 0.0012, Avg val loss = 0.0418, Time = 6.10s\n",
            "Epoch = 23, Avg Train Loss = 0.0012, Avg val loss = 0.0422, Time = 6.05s\n",
            "Epoch = 24, Avg Train Loss = 0.0011, Avg val loss = 0.0406, Time = 5.94s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCbB8YN-GwLj",
        "colab_type": "code",
        "outputId": "fb67f515-93ff-4e06-cedf-f3934a217524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "predict(model, test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Precision: 0.7871591908531222, 1 Recall: 0.5966666666666667\n",
            "Exact: 851, partial: 137, missing: 512, spurius: 151\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\">Избирательной кампанией \"Единой России\" займется <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Сергей Нарышкин\r\n",
              "\r\n",
              "Руководить<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> избирательной кампанией \"Единой России\" будет глава администрации президента <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Сергей Нарышкин<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>. Как пишет \"Коммерсантъ\", такое решение было принято в связи с тем, что список \"ЕР\" на выборах в Госдуму возглавил <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Дмитрий Медведев<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>.\r\n",
              "\r\n",
              "По данным издания, Нарышкин уже провел два совещания по поводу кампании. В частности, ему доложили о партийцах, которые будут участвовать в предвыборных дебатах.\r\n",
              "\r\n",
              "Пресс-секретарь лидера \"ЕР\" <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Владимира Путина Дмитрий Песков<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> подтвердил \"Коммерсанту\", что \"основной акцент теперь\" на президенте. Тем не менее, штаб Общероссийского народного фронта продолжает работать под руководством главы аппарата правительства <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Вячеслава Володина<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>.\r\n",
              "\r\n",
              "Кроме того, существует штаб \"Единой России\", который возглавляет секретарь генсовета партии <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Сергей Неверов<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>. Сам Неверов отказался сказать, какую роль теперь выполняет его структура. \"Ему нечего сказать\", - заявили \"Коммерсанту\" в пресс-службе функционера.\r\n",
              "\r\n",
              "Как отмечает издание, о том, что вести кампанию \"Единой России\" будет именно администрация президента, свидетельствует включение в генсовет партии главы управления внутренней политики <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Константина Костина<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>. В СМИ его называли человеком первого заместителя главы администрации <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Владислава Суркова<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>.\r\n",
              "\r\n",
              "Между тем \"РБК daily\" стали известны подробности финансирования кампании \"Единой России\". По сведениям издания, регионы практически не будут получать помощи из центра. Региональные кампании, как пишет издание, будут спонсировать бизнесмены, попавшие на проходные места. В среднем, по информации \"РБК daily\", предприниматели заплатили по пять миллионов евро.\r\n",
              "\r\n",
              "Выборы в Госдуму состоятся 4 декабря. То, что список \"Единой России\" на выборах возглавит президент <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Дмитрий Медведев<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> стало известно на съезде партии 24 сентября. По словам главы государства, \"ЕР\" является наиболее близкой ему политической силой, несмотря на то, что он ее неоднократно критиковал. </div>"
            ],
            "text/plain": [
              "BoxMarkup('Избирательной кампанией \"Единой России\" займется Сергей Нарышкин\\r\\n\\r\\nРуководить избирательной кампанией \"Единой России\" будет глава администрации президента Сергей Нарышкин. Как пишет \"Коммерсантъ\", такое решение было принято в связи с тем, что список \"ЕР\" на выборах в Госдуму возглавил Дмитрий Медведев.\\r\\n\\r\\nПо данным издания, Нарышкин уже провел два совещания по поводу кампании. В частности, ему доложили о партийцах, которые будут участвовать в предвыборных дебатах.\\r\\n\\r\\nПресс-секретарь лидера \"ЕР\" Владимира Путина Дмитрий Песков подтвердил \"Коммерсанту\", что \"основной акцент теперь\" на президенте. Тем не менее, штаб Общероссийского народного фронта продолжает работать под руководством главы аппарата правительства Вячеслава Володина.\\r\\n\\r\\nКроме того, существует штаб \"Единой России\", который возглавляет секретарь генсовета партии Сергей Неверов. Сам Неверов отказался сказать, какую роль теперь выполняет его структура. \"Ему нечего сказать\", - заявили \"Коммерсанту\" в пресс-службе функционера.\\r\\n\\r\\nКак отмечает издание, о том, что вести кампанию \"Единой России\" будет именно администрация президента, свидетельствует включение в генсовет партии главы управления внутренней политики Константина Костина. В СМИ его называли человеком первого заместителя главы администрации Владислава Суркова.\\r\\n\\r\\nМежду тем \"РБК daily\" стали известны подробности финансирования кампании \"Единой России\". По сведениям издания, регионы практически не будут получать помощи из центра. Региональные кампании, как пишет издание, будут спонсировать бизнесмены, попавшие на проходные места. В среднем, по информации \"РБК daily\", предприниматели заплатили по пять миллионов евро.\\r\\n\\r\\nВыборы в Госдуму состоятся 4 декабря. То, что список \"Единой России\" на выборах возглавит президент Дмитрий Медведев стало известно на съезде партии 24 сентября. По словам главы государства, \"ЕР\" является наиболее близкой ему политической силой, несмотря на то, что он ее неоднократно критиковал. ',\n",
              "          [Span(49, 78, 'PER'),\n",
              "           Span(156, 171, 'PER'),\n",
              "           Span(287, 303, 'PER'),\n",
              "           Span(501, 532, 'PER'),\n",
              "           Span(721, 739, 'PER'),\n",
              "           Span(836, 850, 'PER'),\n",
              "           Span(1187, 1206, 'PER'),\n",
              "           Span(1277, 1295, 'PER'),\n",
              "           Span(1761, 1777, 'PER')])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It8YcUElg4Zh",
        "colab_type": "text"
      },
      "source": [
        "## Задание 1.3\n",
        "Сделайте то же самое, но с CRF над головой"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ume2ilJ29Jzm",
        "colab_type": "code",
        "outputId": "5cba3567-cc82-4856-9afb-2c2481128ca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install pytorch-crf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gxQ9YU1HIxC",
        "colab_type": "code",
        "outputId": "8c227d38-76d3-4d47-bff7-92a7b4edafae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "from torch import nn\n",
        "from torchcrf import CRF\n",
        "\n",
        "class CharCNNBiLstmModel(nn.Module):\n",
        "    def __init__(self, char_set_size, char_embedding_dim=4, classes_count=3, word_embedding_dim=16, lstm_embedding_dim=16, char_max_seq_len=40):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.char_embedding_dim = char_embedding_dim\n",
        "        self.embeddings_layer = nn.Embedding(char_set_size, char_embedding_dim)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.char_activation = nn.Conv2d(1, word_embedding_dim, kernel_size=(1, char_embedding_dim), padding=1)\n",
        "        self.lstm_layer = nn.LSTM(48, lstm_embedding_dim // 2, batch_first=True, bidirectional=True)\n",
        "        self.out_layer = nn.Linear(lstm_embedding_dim, classes_count)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.CRF = CRF(classes_count, batch_first=True)\n",
        "\n",
        "    def forward(self, inputs, tags):\n",
        "        \n",
        "        batch_size = inputs.size(0)\n",
        "        seq_len = inputs.size(1)\n",
        "        projections = self.embeddings_layer.forward(inputs)\n",
        "        bs = projections.size(0)\n",
        "        wc = projections.size(1)\n",
        "        # projections = projections.reshape(projections.size(0), 1, -1, self.char_embedding_dim)\n",
        "        projections = projections.unsqueeze(2)\n",
        "        # print(projections.shape)\n",
        "        projections = projections.reshape(bs * wc, 1, 40, -1)\n",
        "        # print(projections.shape)\n",
        "        # projections = self.relu(self.char_activation(projections))\n",
        "        # projections = self.dropout(projections)\n",
        "        projections = self.char_activation(projections)\n",
        "        # print(projections.shape)\n",
        "        projections, _ = torch.max(projections, dim=2)\n",
        "        # print(projections.shape)\n",
        "        output = projections.reshape(bs, wc, -1)\n",
        "        # print(output.shape)\n",
        "        output, _= self.lstm_layer(output)\n",
        "        output = self.dropout(output)\n",
        "        # print(output.shape)\n",
        "        output = self.out_layer.forward(output)\n",
        "\n",
        "        mask = torch.zeros((inputs.shape[0], inputs.shape[1]), dtype = torch.uint8)\n",
        "        for i in range(mask.shape[0]):\n",
        "          for j in range(mask.shape[1]):\n",
        "            if inputs[i][j].sum() >= 1:\n",
        "              mask[i, j] = 1\n",
        "\n",
        "        device = torch.device(\"cuda\")\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        output = -self.CRF(output, tags, reduction='mean', mask=mask)\n",
        "        return output\n",
        "\n",
        "    def eval_forward(self, inputs, tags):\n",
        "        batch_size = inputs.size(0)\n",
        "        seq_len = inputs.size(1)\n",
        "        projections = self.embeddings_layer.forward(inputs)\n",
        "        bs = projections.size(0)\n",
        "        wc = projections.size(1)\n",
        "        # projections = projections.reshape(projections.size(0), 1, -1, self.char_embedding_dim)\n",
        "        projections = projections.unsqueeze(2)\n",
        "        # print(projections.shape)\n",
        "        projections = projections.reshape(bs * wc, 1, 40, -1)\n",
        "        # print(projections.shape)\n",
        "        # projections = self.relu(self.char_activation(projections))\n",
        "        # projections = self.dropout(projections)\n",
        "        projections = self.char_activation(projections)\n",
        "        # print(projections.shape)\n",
        "        projections, _ = torch.max(projections, dim=2)\n",
        "        # print(projections.shape)\n",
        "        output = projections.reshape(bs, wc, -1)\n",
        "        # print(output.shape)\n",
        "        output, _= self.lstm_layer(output)\n",
        "        output = self.dropout(output)\n",
        "        # print(output.shape)\n",
        "        output = self.out_layer.forward(output)\n",
        "\n",
        "\n",
        "        \n",
        "        mask = torch.zeros((inputs.shape[0], inputs.shape[1]), dtype = torch.uint8)\n",
        "        for i in range(mask.shape[0]):\n",
        "          for j in range(mask.shape[1]):\n",
        "            if inputs[i][j].sum() >= 1:\n",
        "              mask[i, j] = 1\n",
        "\n",
        "        device = torch.device(\"cuda\")\n",
        "        mask = mask.to(device)\n",
        "        \n",
        "\n",
        "\n",
        "        return output, mask\n",
        "\n",
        "model = CharCNNBiLstmModel(len(char_set))\n",
        "train_gen_model(model, train, val, epochs_count=50, early_stopping=False, lr=0.02, crf=True)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable params: 4530\n",
            "Epoch = 0, Avg Train Loss = 2.3713, Avg val loss = 75.3236, Time = 38.51s\n",
            "Epoch = 1, Avg Train Loss = 1.7133, Avg val loss = 67.8249, Time = 37.46s\n",
            "Epoch = 2, Avg Train Loss = 1.5143, Avg val loss = 63.2991, Time = 38.28s\n",
            "Epoch = 3, Avg Train Loss = 1.3912, Avg val loss = 59.1591, Time = 37.77s\n",
            "Epoch = 4, Avg Train Loss = 1.3199, Avg val loss = 57.2932, Time = 36.64s\n",
            "Epoch = 5, Avg Train Loss = 1.2824, Avg val loss = 55.6300, Time = 38.02s\n",
            "Epoch = 6, Avg Train Loss = 1.2564, Avg val loss = 55.7411, Time = 38.03s\n",
            "Epoch = 7, Avg Train Loss = 1.2337, Avg val loss = 54.3748, Time = 37.79s\n",
            "Epoch = 8, Avg Train Loss = 1.2142, Avg val loss = 53.4952, Time = 38.12s\n",
            "Epoch = 9, Avg Train Loss = 1.1730, Avg val loss = 50.4621, Time = 38.24s\n",
            "Epoch = 10, Avg Train Loss = 1.0949, Avg val loss = 48.3805, Time = 38.07s\n",
            "Epoch = 11, Avg Train Loss = 1.0498, Avg val loss = 45.6042, Time = 38.31s\n",
            "Epoch = 12, Avg Train Loss = 1.0162, Avg val loss = 43.9468, Time = 37.71s\n",
            "Epoch = 13, Avg Train Loss = 0.9968, Avg val loss = 42.5009, Time = 37.81s\n",
            "Epoch = 14, Avg Train Loss = 0.9699, Avg val loss = 40.0887, Time = 38.27s\n",
            "Epoch = 15, Avg Train Loss = 0.9040, Avg val loss = 36.1798, Time = 37.47s\n",
            "Epoch = 16, Avg Train Loss = 0.7881, Avg val loss = 26.1629, Time = 37.86s\n",
            "Epoch = 17, Avg Train Loss = 0.6478, Avg val loss = 21.5163, Time = 38.09s\n",
            "Epoch = 18, Avg Train Loss = 0.5744, Avg val loss = 20.0370, Time = 38.24s\n",
            "Epoch = 19, Avg Train Loss = 0.5249, Avg val loss = 17.8648, Time = 37.95s\n",
            "Epoch = 20, Avg Train Loss = 0.4837, Avg val loss = 17.4257, Time = 38.06s\n",
            "Epoch = 21, Avg Train Loss = 0.4528, Avg val loss = 16.4647, Time = 37.82s\n",
            "Epoch = 22, Avg Train Loss = 0.4235, Avg val loss = 16.3241, Time = 37.50s\n",
            "Epoch = 23, Avg Train Loss = 0.4036, Avg val loss = 15.0714, Time = 38.18s\n",
            "Epoch = 24, Avg Train Loss = 0.3787, Avg val loss = 14.6878, Time = 37.83s\n",
            "Epoch = 25, Avg Train Loss = 0.3634, Avg val loss = 13.9394, Time = 37.78s\n",
            "Epoch = 26, Avg Train Loss = 0.3544, Avg val loss = 13.9793, Time = 37.96s\n",
            "Epoch = 27, Avg Train Loss = 0.3439, Avg val loss = 13.4769, Time = 38.60s\n",
            "Epoch = 28, Avg Train Loss = 0.3323, Avg val loss = 13.0678, Time = 38.02s\n",
            "Epoch = 29, Avg Train Loss = 0.3224, Avg val loss = 12.7531, Time = 38.29s\n",
            "Epoch = 30, Avg Train Loss = 0.3166, Avg val loss = 12.5251, Time = 38.00s\n",
            "Epoch = 31, Avg Train Loss = 0.3172, Avg val loss = 12.6406, Time = 38.26s\n",
            "Epoch = 32, Avg Train Loss = 0.3100, Avg val loss = 12.5830, Time = 38.51s\n",
            "Epoch = 33, Avg Train Loss = 0.3027, Avg val loss = 12.1633, Time = 38.58s\n",
            "Epoch = 34, Avg Train Loss = 0.2964, Avg val loss = 12.3547, Time = 38.49s\n",
            "Epoch = 35, Avg Train Loss = 0.2915, Avg val loss = 11.9578, Time = 38.57s\n",
            "Epoch = 36, Avg Train Loss = 0.2851, Avg val loss = 11.7649, Time = 38.27s\n",
            "Epoch = 37, Avg Train Loss = 0.2801, Avg val loss = 11.9316, Time = 38.34s\n",
            "Epoch = 38, Avg Train Loss = 0.2732, Avg val loss = 12.0564, Time = 38.22s\n",
            "Epoch = 39, Avg Train Loss = 0.2736, Avg val loss = 11.5055, Time = 38.20s\n",
            "Epoch = 40, Avg Train Loss = 0.2734, Avg val loss = 11.0166, Time = 38.54s\n",
            "Epoch = 41, Avg Train Loss = 0.2675, Avg val loss = 11.4106, Time = 38.54s\n",
            "Epoch = 42, Avg Train Loss = 0.2652, Avg val loss = 11.8208, Time = 37.98s\n",
            "Epoch = 43, Avg Train Loss = 0.2579, Avg val loss = 11.1923, Time = 38.68s\n",
            "Epoch = 44, Avg Train Loss = 0.2517, Avg val loss = 11.2394, Time = 38.22s\n",
            "Epoch = 45, Avg Train Loss = 0.2505, Avg val loss = 11.0982, Time = 38.40s\n",
            "Epoch = 46, Avg Train Loss = 0.2520, Avg val loss = 11.0903, Time = 38.06s\n",
            "Epoch = 47, Avg Train Loss = 0.2500, Avg val loss = 11.7539, Time = 38.35s\n",
            "Epoch = 48, Avg Train Loss = 0.2517, Avg val loss = 10.7145, Time = 38.42s\n",
            "Epoch = 49, Avg Train Loss = 0.2430, Avg val loss = 10.8461, Time = 38.19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxRyrVEPaetm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "88e12682-d4ac-4d64-cbcf-6b01e623157a"
      },
      "source": [
        "train_gen_model(model, train, val, epochs_count=50, early_stopping=False, lr=0.02, crf=True)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trainable params: 4530\n",
            "Epoch = 0, Avg Train Loss = 0.2492, Avg val loss = 11.2964, Time = 37.84s\n",
            "Epoch = 1, Avg Train Loss = 0.2350, Avg val loss = 10.6377, Time = 37.66s\n",
            "Epoch = 2, Avg Train Loss = 0.2294, Avg val loss = 10.8173, Time = 38.03s\n",
            "Epoch = 3, Avg Train Loss = 0.2266, Avg val loss = 10.0112, Time = 37.86s\n",
            "Epoch = 4, Avg Train Loss = 0.2228, Avg val loss = 9.8630, Time = 37.81s\n",
            "Epoch = 5, Avg Train Loss = 0.2176, Avg val loss = 9.8484, Time = 36.95s\n",
            "Epoch = 6, Avg Train Loss = 0.2174, Avg val loss = 9.7550, Time = 37.27s\n",
            "Epoch = 7, Avg Train Loss = 0.2144, Avg val loss = 10.1669, Time = 37.33s\n",
            "Epoch = 8, Avg Train Loss = 0.2119, Avg val loss = 9.6427, Time = 37.89s\n",
            "Epoch = 9, Avg Train Loss = 0.2107, Avg val loss = 10.0398, Time = 37.72s\n",
            "Epoch = 10, Avg Train Loss = 0.2145, Avg val loss = 9.4291, Time = 37.89s\n",
            "Epoch = 11, Avg Train Loss = 0.2106, Avg val loss = 9.3550, Time = 37.78s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-c666fefcf0df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_gen_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-6926c5eb91b4>\u001b[0m in \u001b[0;36mtrain_gen_model\u001b[0;34m(model, train_samples, val_samples, epochs_count, loss_every_nsteps, lr, save_path, device_name, early_stopping, batch_size, crf)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcrf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m               \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Прямой проход\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-4251d4438b1d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, tags)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m               \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtYTh3I9J3Ht",
        "colab_type": "code",
        "outputId": "cb1d4f29-8961-45fb-d573-fee8307cb4b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "predict(model, test, crf=True)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Precision: 0.8773055332798717, 1 Recall: 0.7293333333333333\n",
            "Exact: 1069, partial: 98, missing: 333, spurius: 85\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"tex2jax_ignore\" style=\"white-space: pre-wrap\"><span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Медведев<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> пообещал новые отставки в связи с терактом в \"Домодедово\"\r\n",
              "\r\n",
              "Президент РФ <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Дмитрий Медведев<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> заявил на совещании по безопасности на транспорте, что отставки чиновников в связи с терактом в \"Домодедово\" будут продолжены. Об этом 26 января сообщает РИА Новости.\r\n",
              "\r\n",
              "Глава МВД РФ <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Рашид Нургалиев<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> на совещании объявил об увольнении начальника линейного отдела внутренних дел \"Домодедово\" и двух его заместителей. <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Сам Медведев<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> сказал, что подписал указ об отставке начальника управления на транспорте МВД по Центральному федеральному округу <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Андрея Алексеева<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span>. После этого <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Медведев<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> заявил: \"На этом все закончиться не должно, это как бы верхние начальники\".\r\n",
              "\r\n",
              "В ходе совещания <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Медведев<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> напомнил, что в марте 2010 года подписал указ по обеспечению безопасности на транспорте. \"Я хотел бы, чтобы мне сейчас доложили, как идет работа по указу, что уже сделано и в чем проблема\", - сказал президент.\r\n",
              "\r\n",
              "Как сообщалось ранее, в начале совещания <span style=\"padding: 2px; border-radius: 4px; border: 1px solid #bbdefb; background: #e3f2fd\">Медведев<span style=\"vertical-align: middle; margin-left: 2px; font-size: 0.7em; color: #64b5f6;\">PER</span></span> поручил Нургалиеву \"тряхнуть\" транспортную милицию с целью обеспечения безопасности.\r\n",
              "\r\n",
              "Взрыв в зоне прилета \"Домодедово\" произошел в 16:30 24 января. Бомбу подорвал террорист-смертник. Погибли 35 человек, более ста человек получили ранения. Возбуждены два уголовных дела - непосредственно о теракте и о необеспечении безопасности в аэропорту. 26 января в Москве и Московской области объявлен траур в память о жертвах теракта. </div>"
            ],
            "text/plain": [
              "BoxMarkup('Медведев пообещал новые отставки в связи с терактом в \"Домодедово\"\\r\\n\\r\\nПрезидент РФ Дмитрий Медведев заявил на совещании по безопасности на транспорте, что отставки чиновников в связи с терактом в \"Домодедово\" будут продолжены. Об этом 26 января сообщает РИА Новости.\\r\\n\\r\\nГлава МВД РФ Рашид Нургалиев на совещании объявил об увольнении начальника линейного отдела внутренних дел \"Домодедово\" и двух его заместителей. Сам Медведев сказал, что подписал указ об отставке начальника управления на транспорте МВД по Центральному федеральному округу Андрея Алексеева. После этого Медведев заявил: \"На этом все закончиться не должно, это как бы верхние начальники\".\\r\\n\\r\\nВ ходе совещания Медведев напомнил, что в марте 2010 года подписал указ по обеспечению безопасности на транспорте. \"Я хотел бы, чтобы мне сейчас доложили, как идет работа по указу, что уже сделано и в чем проблема\", - сказал президент.\\r\\n\\r\\nКак сообщалось ранее, в начале совещания Медведев поручил Нургалиеву \"тряхнуть\" транспортную милицию с целью обеспечения безопасности.\\r\\n\\r\\nВзрыв в зоне прилета \"Домодедово\" произошел в 16:30 24 января. Бомбу подорвал террорист-смертник. Погибли 35 человек, более ста человек получили ранения. Возбуждены два уголовных дела - непосредственно о теракте и о необеспечении безопасности в аэропорту. 26 января в Москве и Московской области объявлен траур в память о жертвах теракта. ',\n",
              "          [Span(0, 8, 'PER'),\n",
              "           Span(83, 99, 'PER'),\n",
              "           Span(283, 298, 'PER'),\n",
              "           Span(415, 427, 'PER'),\n",
              "           Span(542, 558, 'PER'),\n",
              "           Span(572, 580, 'PER'),\n",
              "           Span(677, 685, 'PER'),\n",
              "           Span(940, 948, 'PER')])"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTRY5xEskzre",
        "colab_type": "text"
      },
      "source": [
        "# NER из коробки\n",
        "\n",
        "https://github.com/natasha/natasha\n",
        "\n",
        "https://github.com/deepmipt/DeepPavlov\n",
        "\n",
        "https://pypi.org/project/polyglot/\n",
        "\n",
        "http://www.pullenti.ru/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny29Sb3fIYsN",
        "colab_type": "code",
        "outputId": "728c5820-87df-4760-baea-d9529c51044d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install natasha"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting natasha\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/9d/3330c5a8c98f45a6f090cc8bfaa1132a58ead75cedec5ac758b2999bf34c/natasha-0.10.0-py2.py3-none-any.whl (777kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 45.9MB/s \n",
            "\u001b[?25hCollecting yargy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/64/d6abf637228bed6b0249b522f588d19dca9f09ab65db13bef41096f51889/yargy-0.12.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymorphy2==0.8 in /usr/local/lib/python3.6/dist-packages (from yargy->natasha) (0.8)\n",
            "Collecting backports.functools-lru-cache==1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/40/0b1db94fdfd71353ae67ec444ff28e0a7ecc25212d1cb94c291b6cd226f9/backports.functools_lru_cache-1.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->yargy->natasha) (0.6.2)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->yargy->natasha) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->yargy->natasha) (2.4.393442.3710985)\n",
            "Installing collected packages: backports.functools-lru-cache, yargy, natasha\n",
            "Successfully installed backports.functools-lru-cache-1.3 natasha-0.10.0 yargy-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkT2hBmilOf3",
        "colab_type": "text"
      },
      "source": [
        "## Задание 2\n",
        "Оцените готовые модели из natasha и deeppavlov-ner на нашем тестовом датасете"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz1gV3OTIpGH",
        "colab_type": "code",
        "outputId": "8b08b638-24ff-45ce-e663-740501243cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from natasha import NamesExtractor\n",
        "\t\n",
        "\n",
        "text = '''\n",
        "Простите, еще несколько цитат из приговора. «…Отрицал существование\n",
        "Иисуса и пророка Мухаммеда», «наделял Иисуса Христа качествами\n",
        "ожившего мертвеца — зомби» [и] «качествами покемонов —\n",
        "представителей бестиария японской мифологии, тем самым совершил\n",
        "преступление, предусмотренное статьей 148 УК РФ\n",
        "'''\n",
        "extractor = NamesExtractor()\n",
        "matches = extractor(text)\n",
        "for match in matches:\n",
        "    print(match.span, match.fact)\n",
        "\n",
        "# (69, 75) Name(first='иисус', last=None, middle=None, nick=None)\n",
        "# (86, 95) Name(first='мухаммед', last=None, middle=None, nick=None)\n",
        "# (107, 120) Name(first='иисус', last='христос', middle=None, nick=None)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[69, 75) Name(first='иисус', middle=None, last=None, nick=None)\n",
            "[86, 95) Name(first='мухаммед', middle=None, last=None, nick=None)\n",
            "[107, 120) Name(first='иисус', middle=None, last='христос', nick=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlbz1890Ipg6",
        "colab_type": "code",
        "outputId": "b9419d4f-fc91-45ed-c5fc-495bc21cb0db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "true_labels = []\n",
        "predicted_labels = []\n",
        "all_indices = []\n",
        "\n",
        "def compare_spans(spans_pred, spans_true):\n",
        "  one_tp = 0\n",
        "  one_fp = 0\n",
        "  one_fn = 0\n",
        "\n",
        "  exact = 0\n",
        "  partial = 0\n",
        "  missing = 0\n",
        "  spurius = 0\n",
        "  for (predicted_spans, true_spans) in zip(spans_pred, spans_true):\n",
        "      for true_span in true_spans:\n",
        "          is_missing = True\n",
        "          for predicted_span in predicted_spans:\n",
        "              if true_span == predicted_span:\n",
        "                  exact += 1\n",
        "                  is_missing = False\n",
        "                  break\n",
        "              ts = true_span[0]\n",
        "              te = true_span[1]\n",
        "              ps = predicted_span[0]\n",
        "              pe = predicted_span[1]\n",
        "              # ts te ps pe\n",
        "              # ps pe ts te\n",
        "              if ts <= te <= ps <= pe or ps <= pe <= ts <= te:\n",
        "                  continue\n",
        "              is_missing = False\n",
        "              partial += 1\n",
        "              break\n",
        "          if is_missing:\n",
        "              missing += 1\n",
        "      for predicted_span in predicted_spans:\n",
        "          is_missing = True\n",
        "          for true_span in true_spans:\n",
        "              if true_span == predicted_span:\n",
        "                  is_missing = False\n",
        "                  break\n",
        "              ts = true_span[0]\n",
        "              te = true_span[1]\n",
        "              ps = predicted_span[0]\n",
        "              pe = predicted_span[1]\n",
        "              if ts <= te <= ps <= pe or ps <= pe <= ts <= te:\n",
        "                  continue\n",
        "              is_missing = False\n",
        "              break\n",
        "          if is_missing:\n",
        "              spurius += 1\n",
        "  print(\"Exact: {}, partial: {}, missing: {}, spurius: {}\".format(exact, partial, missing, spurius))\n",
        "    \n",
        "\n",
        "pred_spans = []\n",
        "true_spans = []\n",
        "for exmpl in test:\n",
        "    pred_spans.append([(s.span[0], s.span[1], \"PER\") for s in extractor(exmpl.text)])\n",
        "    true_spans.append(exmpl.spans)\n",
        "\n",
        "compare_spans(pred_spans, true_spans)\n",
        "\n",
        "\n",
        "\n",
        "# samples = [samples[index] for index in all_indices]\n",
        "# calc_metrics(true_labels, predicted_labels, samples)\n",
        "# show_box_markup(samples[0].text, get_spans(predicted_labels[0], samples[0].tokens), palette=palette(PER=BLUE, ORG=RED, LOC=GREEN))\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exact: 1019, partial: 218, missing: 294, spurius: 57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP-avZAyNT5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "992fbaaf-ca23-4d84-ede6-bb0988e90925"
      },
      "source": [
        "!wget http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v2.tar.gz\n",
        "!tar -xzvf rubert_cased_L-12_H-768_A-12_v2.tar.gz"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-17 10:41:11--  http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v2.tar.gz\n",
            "Resolving files.deeppavlov.ai (files.deeppavlov.ai)... 93.175.29.74\n",
            "Connecting to files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662018287 (631M) [application/octet-stream]\n",
            "Saving to: ‘rubert_cased_L-12_H-768_A-12_v2.tar.gz’\n",
            "\n",
            "rubert_cased_L-12_H 100%[===================>] 631.35M  6.57MB/s    in 90s     \n",
            "\n",
            "2019-12-17 10:42:43 (7.05 MB/s) - ‘rubert_cased_L-12_H-768_A-12_v2.tar.gz’ saved [662018287/662018287]\n",
            "\n",
            "rubert_cased_L-12_H-768_A-12_v2/\n",
            "rubert_cased_L-12_H-768_A-12_v2/bert_config.json\n",
            "rubert_cased_L-12_H-768_A-12_v2/vocab.txt\n",
            "rubert_cased_L-12_H-768_A-12_v2/bert_model.ckpt.data-00000-of-00001\n",
            "rubert_cased_L-12_H-768_A-12_v2/bert_model.ckpt.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x118-UKeVa4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "12d61e6a-1ae8-4a47-9e51-905f1da5d3fa"
      },
      "source": [
        "!pip install deeppavlov"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deeppavlov\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/9d/453d101981b293441be889ba91d6983abdeeb2b3abc070b47a4044f6a64b/deeppavlov-0.7.1-py3-none-any.whl (735kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 48.7MB/s \n",
            "\u001b[?25hCollecting tqdm==4.32.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/3d/7a6b68b631d2ab54975f3a4863f3c4e9b26445353264ef01f465dc9b0208/tqdm-4.32.2-py2.py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Collecting h5py==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 42.1MB/s \n",
            "\u001b[?25hCollecting scipy==1.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2MB 389kB/s \n",
            "\u001b[?25hCollecting fuzzywuzzy==0.17.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n",
            "\u001b[K     |████████████████████████████████| 8.0MB 67.4MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5a/a9/2ab492155d9b76cf109c2370e201822ba3c7f4aed85f5a1b4d22907e7206/uvicorn-0.9.0.tar.gz\n",
            "Collecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk==3.2.5 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (3.2.5)\n",
            "Collecting pandas==0.24.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/74/e50234bc82c553fecdbd566d8650801e3fe2d6d8c8d940638e3d8a7c5522/pandas-0.24.2-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 55.1MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 61.8MB/s \n",
            "\u001b[?25hCollecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 57.6MB/s \n",
            "\u001b[?25hCollecting pyopenssl==19.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/c8/ceb170d81bd3941cbeb9940fc6cc2ef2ca4288d0ca8929ea4db5905d904d/pyOpenSSL-19.0.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.6MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/5e/9711642455c4e17b1202d4f6403ede0fef37fc145038aee7193f3b24445e/pyTelegramBotAPI-3.6.6.tar.gz (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/2f/b08ad77c639040baafc891621f0cfdb209e2266404ca13c3167970a6f6d6/Cython-0.29.12-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 52.0MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n",
            "\u001b[?25hCollecting fastapi==0.38.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/59/1a42dde38f1ae2a7a318947e54fabd1fc02ac423ecc91957c417065e7cc6/fastapi-0.38.1-py3-none-any.whl (160kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 61.6MB/s \n",
            "\u001b[?25hCollecting overrides==1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/de/55/3100c6d14c1ed177492fcf8f07c4a7d2d6c996c0a7fc6a9a0a41308e7eec/overrides-1.9.tar.gz\n",
            "Collecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 52.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py==2.9.0->deeppavlov) (1.12.0)\n",
            "Requirement already satisfied: click==7.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.9.0->deeppavlov) (7.0)\n",
            "Collecting h11==0.8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/f3/8e4cf5fa1a3d8bda942a0b1cf92f87815494216fd439f82eb99073141ba0/h11-0.8.1-py2.py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.3MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.9MB/s \n",
            "\u001b[?25hCollecting httptools==0.0.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/03/215969db11abe8741e9c266a4cbe803a372bd86dd35fa0084c4df6d4bd00/httptools-0.0.13.tar.gz (104kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 72.3MB/s \n",
            "\u001b[?25hCollecting uvloop==0.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/48/586225bbb02d3bdca475b17e4be5ce5b3f09da2d6979f359916c1592a687/uvloop-0.14.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 59.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 54.0MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->deeppavlov) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->deeppavlov) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov) (0.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4->deeppavlov) (3.13)\n",
            "Collecting cryptography>=2.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 53.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2019.11.28)\n",
            "Collecting pydantic<=0.32.2,>=0.32.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/78/2edcc6e65ec020403ac6ba6deb54c1cf227c49232ce9d98a1ae7ebdfa3a1/pydantic-0.32.2-cp36-cp36m-manylinux1_x86_64.whl (5.1MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1MB 51.8MB/s \n",
            "\u001b[?25hCollecting starlette<=0.12.8,>=0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/4a/90a6a8685fcbdcf544a2293d0d0211ecba3cd7f309b831499d5c895383cb/starlette-0.12.8.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.3->pyopenssl==19.0.0->deeppavlov) (1.13.2)\n",
            "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic<=0.32.2,>=0.32.2->fastapi==0.38.1->deeppavlov) (0.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3->pyopenssl==19.0.0->deeppavlov) (2.19)\n",
            "Building wheels for collected packages: uvicorn, pytelegrambotapi, overrides, httptools, starlette\n",
            "  Building wheel for uvicorn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uvicorn: filename=uvicorn-0.9.0-cp36-none-any.whl size=37118 sha256=89237ec656f1c7e6c0818197d059dcaf7ee57ef5beeb241021f74877836889c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/e5/d1/a50d405d3bb18fac538ef9606ed9b6cd5efb6e06b6de834507\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.6-cp36-none-any.whl size=44856 sha256=1f203c51cd3f8745b027f82d285592b539bf8df1194d5eaca7f12ace79b975d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/69/d7/26f1fb04ac4d4c95bff643cea765a8e91c4348da25b4744e08\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-1.9-cp36-none-any.whl size=4214 sha256=c1d5120427b4d1ab560b8dac13ed88fd030e28726e54f79dbcc7c2310a854159\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/52/86/e5a83b1797e7d263b458d2334edd2704c78508b3eea9323718\n",
            "  Building wheel for httptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for httptools: filename=httptools-0.0.13-cp36-cp36m-linux_x86_64.whl size=212539 sha256=ba8b60389eec27ec3d3265fcb487feab326f283fad3e6c04eb7e0a8eb19e8c2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/3e/2e/013f99b42efc25cf3589730cf380738e46b1e5edaf2f78d525\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.8-cp36-none-any.whl size=56910 sha256=94d7662d95c00e1e2ef35f602b8f02da585f1de43d5d5cb4705aadf94c0b77df\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a0/1d/17eb20c5742e3236799a7883e56325823d57fcd8ce2a0c9348\n",
            "Successfully built uvicorn pytelegrambotapi overrides httptools starlette\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=0.25.0; python_version >= \"3.0\", but you'll have pandas 0.24.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tqdm, rusenttokenize, numpy, h5py, scipy, fuzzywuzzy, pymorphy2-dicts-ru, h11, websockets, httptools, uvloop, uvicorn, pymorphy2-dicts, dawg-python, pymorphy2, pandas, scikit-learn, keras, cryptography, pyopenssl, requests, pytelegrambotapi, Cython, pydantic, starlette, fastapi, overrides, deeppavlov\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "  Found existing installation: numpy 1.17.4\n",
            "    Uninstalling numpy-1.17.4:\n",
            "      Successfully uninstalled numpy-1.17.4\n",
            "  Found existing installation: h5py 2.8.0\n",
            "    Uninstalling h5py-2.8.0:\n",
            "      Successfully uninstalled h5py-2.8.0\n",
            "  Found existing installation: scipy 1.3.3\n",
            "    Uninstalling scipy-1.3.3:\n",
            "      Successfully uninstalled scipy-1.3.3\n",
            "  Found existing installation: pandas 0.25.3\n",
            "    Uninstalling pandas-0.25.3:\n",
            "      Successfully uninstalled pandas-0.25.3\n",
            "  Found existing installation: scikit-learn 0.22\n",
            "    Uninstalling scikit-learn-0.22:\n",
            "      Successfully uninstalled scikit-learn-0.22\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: Cython 0.29.14\n",
            "    Uninstalling Cython-0.29.14:\n",
            "      Successfully uninstalled Cython-0.29.14\n",
            "Successfully installed Cython-0.29.12 cryptography-2.8 dawg-python-0.7.2 deeppavlov-0.7.1 fastapi-0.38.1 fuzzywuzzy-0.17.0 h11-0.8.1 h5py-2.9.0 httptools-0.0.13 keras-2.2.4 numpy-1.16.4 overrides-1.9 pandas-0.24.2 pydantic-0.32.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.404381.4453942 pyopenssl-19.0.0 pytelegrambotapi-3.6.6 requests-2.22.0 rusenttokenize-0.0.5 scikit-learn-0.21.2 scipy-1.3.0 starlette-0.12.8 tqdm-4.32.2 uvicorn-0.9.0 uvloop-0.14.0 websockets-8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas",
                  "requests",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGhMcjDmVeNJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "dd51760a-4da1-47a1-d25b-54364ea25050"
      },
      "source": [
        "!python -m deeppavlov install ner_rus_bert"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "email-validator not installed, email fields will be treated as str.\n",
            "To install, run: pip install email-validator\n",
            "2019-12-17 10:43:34.521 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'ner_rus_bert' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/ner/ner_rus_bert.json'\n",
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 134kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.11.2)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 33.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.16.4)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 64.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.33.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.1.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.9.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (42.0.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (0.16.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.1.1)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-xth_yj2b\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-xth_yj2b\n",
            "  Running command git checkout -b feat/multi_gpu --track origin/feat/multi_gpu\n",
            "  Switched to a new branch 'feat/multi_gpu'\n",
            "  Branch 'feat/multi_gpu' set up to track remote branch 'feat/multi_gpu' from 'origin'.\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-cp36-none-any.whl size=23580 sha256=5770de4681d4c3656adf0cee1373b8b005509c87ba1817f184df3af437a0418b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oryd7e6c/wheels/1e/41/94/886107eaf932532594886fd8bfc9cb9d4db632e94add49d326\n",
            "Successfully built bert-dp\n",
            "Installing collected packages: bert-dp\n",
            "Successfully installed bert-dp-1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0MpyGsOVeWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55a2bab9-085a-4d85-c139-53e7c3931e0c"
      },
      "source": [
        "from deeppavlov import configs, build_model\n",
        "\n",
        "ner_model = build_model(configs.ner.ner_rus_bert, download=True)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-17 10:44:10.322 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz to /root/.deeppavlov/downloads/rubert_cased_L-12_H-768_A-12_v1.tar.gz\n",
            "100%|██████████| 666M/666M [01:40<00:00, 6.64MB/s]\n",
            "2019-12-17 10:45:50.597 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/downloads/rubert_cased_L-12_H-768_A-12_v1.tar.gz archive into /root/.deeppavlov/downloads/bert_models\n",
            "2019-12-17 10:45:57.486 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/ner_rus_bert_v1.tar.gz to /root/.deeppavlov/ner_rus_bert_v1.tar.gz\n",
            "100%|██████████| 1.32G/1.32G [03:40<00:00, 5.97MB/s]\n",
            "2019-12-17 10:49:38.137 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/ner_rus_bert_v1.tar.gz archive into /root/.deeppavlov/models\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-17 10:49:55.67 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_rus_bert/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/crf/python/ops/crf.py:213: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-17 10:50:21.617 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_rus_bert/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_rus_bert/model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E56qkUNfvFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_metrics_bert(true_spans, predicted_spans):\n",
        "    exact = 0\n",
        "    partial = 0\n",
        "    missing = 0\n",
        "    spurius = 0\n",
        "    for true_span in true_spans:\n",
        "        is_missing = True\n",
        "        for predicted_span in predicted_spans:\n",
        "            if true_span == predicted_span:\n",
        "                exact += 1\n",
        "                is_missing = False\n",
        "                break\n",
        "            ts = true_span[0]\n",
        "            te = true_span[1]\n",
        "            ps = predicted_span[0]\n",
        "            pe = predicted_span[1]\n",
        "            # ts te ps pe\n",
        "            # ps pe ts te\n",
        "            if ts <= te <= ps <= pe or ps <= pe <= ts <= te:\n",
        "                continue\n",
        "            is_missing = False\n",
        "            partial += 1\n",
        "            break\n",
        "        if is_missing:\n",
        "            missing += 1\n",
        "    for predicted_span in predicted_spans:\n",
        "        is_missing = True\n",
        "        for true_span in true_spans:\n",
        "            if true_span == predicted_span:\n",
        "                is_missing = False\n",
        "                break\n",
        "            ts = true_span[0]\n",
        "            te = true_span[1]\n",
        "            ps = predicted_span[0]\n",
        "            pe = predicted_span[1]\n",
        "            if ts <= te <= ps <= pe or ps <= pe <= ts <= te:\n",
        "                continue\n",
        "            is_missing = False\n",
        "            break\n",
        "        if is_missing:\n",
        "            spurius += 1\n",
        "    # print(\"Exact: {}, partial: {}, missing: {}, spurius: {}\".format(exact, partial, missing, spurius))\n",
        "    return exact, partial, missing, spurius"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa2MsKpBVhnA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "fba9f742dcb84454addbb34fb0d7cddd",
            "07feea8e29c64fb2ac988e2184f0c5b3",
            "56f9e2f0b8b94bd58537e2da7576b46b",
            "0b45402a21644664871f907ad4bd57b7",
            "2f10c6c8f44344dc90ae21ef9220c2e9",
            "927dc4179a134b368da529fb0435eeaf",
            "3d2f9cdcfa2f4eda87a7e784f8183240",
            "ee5f0b0d687b41f9b09dfea1e56b79c6"
          ]
        },
        "outputId": "8fe7928b-ae86-4e95-f6cd-861a214b9ccf"
      },
      "source": [
        "from razdel import sentenize\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "aexact = 0\n",
        "apartial = 0\n",
        "amissing = 0\n",
        "aspurius = 0\n",
        "\n",
        "for sample in tqdm(test):\n",
        "    true_spans = sample.spans\n",
        "    markup = ner_model([sample.text[:1200]])\n",
        "    tokenized_text = markup[0][0]\n",
        "    tags = markup[1][0]\n",
        "    start = 0\n",
        "    predicted_spans = []\n",
        "    for token, tag in zip(tokenized_text, tags):\n",
        "        begin = sample.text.find(token, start)\n",
        "        end = begin + len(token)\n",
        "        start = end\n",
        "        if tag.endswith(\"PER\"):\n",
        "            if tag[0] == \"B\":\n",
        "                predicted_spans.append((begin, end, \"PER\"))\n",
        "            else:\n",
        "                if len(predicted_spans) == 0: continue\n",
        "                predicted_spans[-1] = (predicted_spans[-1][0], end, \"PER\")\n",
        "\n",
        "    # predicted_spans = [(match.span[0], match.span[1], \"PER\") for match in extractor(sample.text)]\n",
        "    # show_box_markup(sample.text, predicted_spans, palette=palette(PER=BLUE, ORG=RED, LOC=GREEN))\n",
        "    exact, partial, missing, spurius = calc_metrics_bert(true_spans, predicted_spans)\n",
        "    aexact += exact\n",
        "    apartial += partial\n",
        "    amissing += missing\n",
        "    aspurius += spurius\n",
        "\n",
        "print(aexact, apartial, amissing, aspurius)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fba9f742dcb84454addbb34fb0d7cddd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "1093 34 404 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0Unt63tex8V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}